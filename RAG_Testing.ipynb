{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanvircr7/meh/blob/master/RAG_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_907x3hHT-_",
        "outputId": "d33bf594-a65b-466d-b410-5bb03ac80885"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.46)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.21)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.18)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (0.3.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.20 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf -q"
      ],
      "metadata": {
        "id": "5aCWFu-O89WM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c2e1941-7d74-454e-9482-d309bbc18d9b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/302.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/302.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install doc2text -q"
      ],
      "metadata": {
        "id": "9e4LQAt3Ilhs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc46561-2fce-4241-a16b-67b7436ae3e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for doc2text (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W7mabgggInNs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_document(file):\n",
        "  import os\n",
        "  name, extension = os.path.splitext(file)\n",
        "  print(f\"{name} - {extension}\")\n",
        "\n",
        "  if extension == '.pdf':\n",
        "    from langchain.document_loaders import PyPDFLoader\n",
        "    print(f'Loading {file}')\n",
        "    loader = PyPDFLoader(file)\n",
        "  elif extension == '.docx':\n",
        "        from langchain.document_loaders import Docx2txtLoader\n",
        "        print(f'Loading {file}')\n",
        "        loader = Docx2txtLoader(file)\n",
        "  elif extension == '.txt':\n",
        "      from langchain.document_loaders import TextLoader\n",
        "      loader = TextLoader(file)\n",
        "  else:\n",
        "      print('Document format is not supported!')\n",
        "      return None\n",
        "\n",
        "  data = loader.load()\n",
        "  return data"
      ],
      "metadata": {
        "id": "pLN1VsaB9ANW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_document('/content/KR-reasoning-LLM-framework.pdf')\n",
        "print(data[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rP6OnpDGvon",
        "outputId": "caa089db-7914-44bb-ead5-7857d3e627d9",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/KR-reasoning-LLM-framework - .pdf\n",
            "Loading /content/KR-reasoning-LLM-framework.pdf\n",
            "K-Level Reasoning: Establishing Higher Order Beliefs\n",
            "in Large Language Models for Strategic Reasoning\n",
            "Yadong Zhang1,2,*, Shaoguang Mao2,†, Tao Ge2, Xun Wang2,\n",
            "Yan Xia2, Man Lan1, Furu Wei2,\n",
            "1East China Normal University, 2Microsoft Research Asia\n",
            "Abstract\n",
            "Strategic reasoning is a complex yet essential\n",
            "capability for intelligent agents. It requires\n",
            "Large Language Model (LLM) agents to adapt\n",
            "their strategies dynamically in multi-agent en-\n",
            "vironments. Unlike static reasoning tasks, suc-\n",
            "cess in these contexts depends on anticipating\n",
            "other agents’ beliefs and actions while contin-\n",
            "uously adjusting strategies to achieve individ-\n",
            "ual goals. LLMs and LLM agents often strug-\n",
            "gle with strategic reasoning due to the absence\n",
            "of a reasoning framework that enables them\n",
            "to dynamically infer others’ perspectives and\n",
            "adapt to changing environments. Inspired by\n",
            "the Level-K framework1 from game theory and\n",
            "behavioral economics, which extends reason-\n",
            "ing from simple reactions to structured strate-\n",
            "gic depth, we propose a novel framework: \"K-\n",
            "Level Reasoning with Large Language Mod-\n",
            "els (K-R).\" This framework employs recursive\n",
            "mechanisms to enable LLMs to achieve vary-\n",
            "ing levels of strategic depth, allowing agents to\n",
            "form higher order beliefs—beliefs about others’\n",
            "beliefs. We validate this framework through\n",
            "rigorous testing on four testbeds: two classi-\n",
            "cal game theory problems and two social in-\n",
            "telligence tasks. The results demonstrate the\n",
            "advantages of K-R in strategic reasoning. Our\n",
            "work presents the first recursive implementa-\n",
            "tion of strategic depth in large language models\n",
            "(LLMs). It establishes a foundation for future\n",
            "research into theory of mind and strategic rea-\n",
            "soning in LLMs.\n",
            "1 Introduction\n",
            "Strategic reasoning—decision-making in multi-\n",
            "participant environments—presents unique chal-\n",
            "lenges for Large Language Models (LLMs) and\n",
            "LLM agents(Zhang et al., 2024b). In these settings,\n",
            "*Work was done when interning at Microsoft Research\n",
            "Asia. † Correspondence to: shaoguang.mao@microsoft.com\n",
            "1According to the Level-k Framework, k-level thinking\n",
            "involves considering what opponent/partner are likely to do,\n",
            "what they think you will do, and what they believe you think\n",
            "they will do, and so on.\n",
            "First-level Thinking Second-level Thinking\n",
            "…\n",
            "Third-level Thinking\n",
            "……\n",
            "Figure 1: Level-K Framework: In first-level thinking,\n",
            "agents respond directly to the environment. In second-\n",
            "level thinking, agents consider the first-level thinking of\n",
            "others. This process continues iteratively, with agents\n",
            "forming higher order beliefs based on assumptions about\n",
            "others’ thoughts.\n",
            "agents must respond to the actions of others while\n",
            "adapting to dynamic environments. They also need\n",
            "to align their decisions with their own goals during\n",
            "these interactions. Strategic reasoning is essential\n",
            "for intelligent agents and is widely applied in real-\n",
            "world tasks, such as investment, business strategy\n",
            "making(Zhao et al., 2023), negotiation(Hua et al.,\n",
            "2023), and policy-making(Li et al., 2024).\n",
            "Effective strategic reasoning relies on under-\n",
            "standing others’ perspectives and anticipating their\n",
            "strategies. While there are some research efforts on\n",
            "LLMs’ strategic reasoning, most methods rely on\n",
            "static prompting (Fu et al., 2023; Xu et al., 2023b).\n",
            "This typically involves instructing the model to ac-\n",
            "count for others’ beliefs and decisions during its\n",
            "own decision-making process in the prompt. How-\n",
            "ever, these approaches fall short in enabling LLMs\n",
            "to form true higher order beliefs—beliefs about\n",
            "what others believe, and lack the flexibility needed\n",
            "for deeper strategic reasoning.\n",
            "K-level thinking (Figure 1) (Nagel, 1995; Cui\n",
            "et al., 2021), a classical concept in behavioral eco-\n",
            "nomics and game theory, categorizes reasoning into\n",
            "varying depths of strategic thought. It involves not\n",
            "only predicting others’ actions but also considering\n",
            "1\n",
            "arXiv:2402.01521v2  [cs.CL]  17 Oct 2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U arxiv pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aBypFMIeKoCX",
        "outputId": "bff54338-e3ac-49f5-9518-d04786101640"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arxiv\n",
            "  Downloading arxiv-2.1.3-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting feedparser~=6.0.10 (from arxiv)\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: requests~=2.32.0 in /usr/local/lib/python3.11/dist-packages (from arxiv) (2.32.3)\n",
            "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (2025.1.31)\n",
            "Downloading arxiv-2.1.3-py3-none-any.whl (11 kB)\n",
            "Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6047 sha256=694b0cb835286fc44344efe9b52c794b13d730dcbe5e3b622503c426b0df5780\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, pymupdf, feedparser, arxiv\n",
            "Successfully installed arxiv-2.1.3 feedparser-6.0.11 pymupdf-1.25.4 sgmllib3k-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_from_arxiv(query):\n",
        "  from langchain_community.document_loaders import ArxivLoader\n",
        "\n",
        "  loader = ArxivLoader(query=query, load_max_doc=2)\n",
        "  # docs = loader.load()\n",
        "  docs = loader.get_summaries_as_docs()\n",
        "  # print(docs[0].page_content[:100])\n",
        "  print(docs[0].page_content)\n",
        "  print(docs[0].metadata)\n"
      ],
      "metadata": {
        "id": "4-OeKfwJHOYi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_from_arxiv('reasoning')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yo_ILlH9ZlKL",
        "outputId": "d1cb55ee-754e-4e3c-b68e-5b3a834749a9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Large language models (LLMs) have demonstrated impressive reasoning\n",
            "abilities, but they still struggle with faithful reasoning due to knowledge\n",
            "gaps and hallucinations. To address these issues, knowledge graphs (KGs) have\n",
            "been utilized to enhance LLM reasoning through their structured knowledge.\n",
            "However, existing KG-enhanced methods, either retrieval-based or agent-based,\n",
            "encounter difficulties in accurately retrieving knowledge and efficiently\n",
            "traversing KGs at scale. In this work, we introduce graph-constrained reasoning\n",
            "(GCR), a novel framework that bridges structured knowledge in KGs with\n",
            "unstructured reasoning in LLMs. To eliminate hallucinations, GCR ensures\n",
            "faithful KG-grounded reasoning by integrating KG structure into the LLM\n",
            "decoding process through KG-Trie, a trie-based index that encodes KG reasoning\n",
            "paths. KG-Trie constrains the decoding process, allowing LLMs to directly\n",
            "reason on graphs and generate faithful reasoning paths grounded in KGs.\n",
            "Additionally, GCR leverages a lightweight KG-specialized LLM for\n",
            "graph-constrained reasoning alongside a powerful general LLM for inductive\n",
            "reasoning over multiple reasoning paths, resulting in accurate reasoning with\n",
            "zero reasoning hallucination. Extensive experiments on several KGQA benchmarks\n",
            "demonstrate that GCR achieves state-of-the-art performance and exhibits strong\n",
            "zero-shot generalizability to unseen KGs without additional training.\n",
            "{'Entry ID': 'http://arxiv.org/abs/2410.13080v1', 'Published': datetime.date(2024, 10, 16), 'Title': 'Graph-constrained Reasoning: Faithful Reasoning on Knowledge Graphs with Large Language Models', 'Authors': 'Linhao Luo, Zicheng Zhao, Chen Gong, Gholamreza Haffari, Shirui Pan'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eiZ2WXmZddBS",
        "outputId": "ab972678-40c7-4d60-84cd-2040879c20ab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (4.12.2)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=38b8152ed3f89fa977bbb7324c0b6b32545fa086f48bbacd9710aa5d00ad71b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wikipedia\n",
        "def load_from_wikipedia(query, lang='en', load_max_docs=2):\n",
        "    from langchain.document_loaders import WikipediaLoader\n",
        "    loader = WikipediaLoader(query=query, lang=lang, load_max_docs=load_max_docs)\n",
        "    data = loader.load()\n",
        "    return data"
      ],
      "metadata": {
        "id": "LgjgcfcxZqSr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_from_wikipedia('reasoning')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ec_E4-9Xc_Qd",
        "outputId": "10c02be4-049c-45d8-f0bf-74f8d4635caa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'title': 'Reason', 'summary': \"Reason is the capacity of consciously applying logic by drawing valid conclusions from new or existing information, with the aim of seeking the truth. It is associated with such characteristically human activities as philosophy, religion, science, language, mathematics, and art, and is normally considered to be a distinguishing ability possessed by humans. Reason is sometimes referred to as rationality.\\nReasoning involves using more-or-less rational processes of thinking and cognition to extrapolate from one's existing knowledge to generate new knowledge, and involves the use of one's intellect. The field of logic studies the ways in which humans can use formal reasoning to produce logically valid arguments and true conclusions. Reasoning may be subdivided into forms of logical reasoning, such as deductive reasoning, inductive reasoning, and abductive reasoning.\\nAristotle drew a distinction between logical discursive reasoning (reason proper), and intuitive reasoning,:\\u200aVI.7\\u200a in which the reasoning process through intuition—however valid—may tend toward the personal and the subjectively opaque. In some social and political settings logical and intuitive modes of reasoning may clash, while in other contexts intuition and formal reason are seen as complementary rather than adversarial. For example, in mathematics, intuition is often necessary for the creative processes involved with arriving at a formal proof, arguably the most difficult of formal reasoning tasks.\\nReasoning, like habit or intuition, is one of the ways by which thinking moves from one idea to a related idea. For example, reasoning is the means by which rational individuals understand the significance of sensory information from their environments, or conceptualize abstract dichotomies such as cause and effect, truth and falsehood, or good and evil. Reasoning, as a part of executive decision making, is also closely identified with the ability to self-consciously change, in terms of goals, beliefs, attitudes, traditions, and institutions, and therefore with the capacity for freedom and self-determination.\\nPsychologists and cognitive scientists have attempted to study and explain how people reason, e.g. which cognitive and neural processes are engaged, and how cultural factors affect the inferences that people draw. The field of automated reasoning studies how reasoning may or may not be modeled computationally. Animal psychology considers the question of whether animals other than humans can reason.\", 'source': 'https://en.wikipedia.org/wiki/Reason'}, page_content='Reason is the capacity of consciously applying logic by drawing valid conclusions from new or existing information, with the aim of seeking the truth. It is associated with such characteristically human activities as philosophy, religion, science, language, mathematics, and art, and is normally considered to be a distinguishing ability possessed by humans. Reason is sometimes referred to as rationality.\\nReasoning involves using more-or-less rational processes of thinking and cognition to extrapolate from one\\'s existing knowledge to generate new knowledge, and involves the use of one\\'s intellect. The field of logic studies the ways in which humans can use formal reasoning to produce logically valid arguments and true conclusions. Reasoning may be subdivided into forms of logical reasoning, such as deductive reasoning, inductive reasoning, and abductive reasoning.\\nAristotle drew a distinction between logical discursive reasoning (reason proper), and intuitive reasoning,:\\u200aVI.7\\u200a in which the reasoning process through intuition—however valid—may tend toward the personal and the subjectively opaque. In some social and political settings logical and intuitive modes of reasoning may clash, while in other contexts intuition and formal reason are seen as complementary rather than adversarial. For example, in mathematics, intuition is often necessary for the creative processes involved with arriving at a formal proof, arguably the most difficult of formal reasoning tasks.\\nReasoning, like habit or intuition, is one of the ways by which thinking moves from one idea to a related idea. For example, reasoning is the means by which rational individuals understand the significance of sensory information from their environments, or conceptualize abstract dichotomies such as cause and effect, truth and falsehood, or good and evil. Reasoning, as a part of executive decision making, is also closely identified with the ability to self-consciously change, in terms of goals, beliefs, attitudes, traditions, and institutions, and therefore with the capacity for freedom and self-determination.\\nPsychologists and cognitive scientists have attempted to study and explain how people reason, e.g. which cognitive and neural processes are engaged, and how cultural factors affect the inferences that people draw. The field of automated reasoning studies how reasoning may or may not be modeled computationally. Animal psychology considers the question of whether animals other than humans can reason.\\n\\n\\n== Etymology and related words ==\\nIn the English language and other modern European languages, \"reason\", and related words, represent words which have always been used to translate Latin and classical Greek terms in their philosophical sense.\\n\\nThe original Greek term was \"λόγος\" logos, the root of the modern English word \"logic\" but also a word that could mean for example \"speech\" or \"explanation\" or an \"account\" (of money handled).\\nAs a philosophical term logos was translated in its non-linguistic senses in Latin as ratio. This was originally not just a translation used for philosophy, but was also commonly a translation for logos in the sense of an account of money.\\nFrench raison is derived directly from Latin, and this is the direct source of the English word \"reason\".\\nThe earliest major philosophers to publish in English, such as Francis Bacon, Thomas Hobbes, and John Locke also routinely wrote in Latin and French, and compared their terms to Greek, treating the words \"logos\", \"ratio\", \"raison\" and \"reason\" as interchangeable. The meaning of the word \"reason\" in senses such as \"human reason\" also overlaps to a large extent with \"rationality\" and the adjective of \"reason\" in philosophical contexts is normally \"rational\", rather than \"reasoned\" or \"reasonable\". Some philosophers, Hobbes for example, also used the word ratiocination as a synonym for \"reasoning\".\\nIn contrast to the use of \"reason\" as an abstract noun, a reason is a consideration that either explains or'),\n",
              " Document(metadata={'title': 'Logical reasoning', 'summary': 'Logical reasoning is a mental activity that aims to arrive at a conclusion in a rigorous way. It happens in the form of inferences or arguments by starting from a set of premises and reasoning to a conclusion supported by these premises. The premises and the conclusion are propositions, i.e. true or false claims about what is the case. Together, they form an argument. Logical reasoning is norm-governed in the sense that it aims to formulate correct arguments that any rational person would find convincing. The main discipline studying logical reasoning is logic. \\nDistinct types of logical reasoning differ from each other concerning the norms they employ and the certainty of the conclusion they arrive at. Deductive reasoning offers the strongest support: the premises ensure the conclusion, meaning that it is impossible for the conclusion to be false if all the premises are true. Such an argument is called a valid argument, for example: all men are mortal; Socrates is a man; therefore, Socrates is mortal. For valid arguments, it is not important whether the premises are actually true but only that, if they were true, the conclusion could not be false. Valid arguments follow a rule of inference, such as modus ponens or modus tollens. Deductive reasoning plays a central role in formal logic and mathematics.\\nFor non-deductive logical reasoning, the premises make their conclusion rationally convincing without ensuring its truth. This is often understood in terms of probability: the premises make it more likely that the conclusion is true and strong inferences make it very likely. Some uncertainty remains because the conclusion introduces new information not already found in the premises. Non-deductive reasoning plays a central role in everyday life and in most sciences. Often-discussed types are inductive, abductive, and analogical reasoning. Inductive reasoning is a form of generalization that infers a universal law from a pattern found in many individual cases. It can be used to conclude that \"all ravens are black\" based on many individual observations of black ravens. Abductive reasoning, also known as \"inference to the best explanation\", starts from an observation and reasons to the fact explaining this observation. An example is a doctor who examines the symptoms of their patient to make a diagnosis of the underlying cause. Analogical reasoning compares two similar systems. It observes that one of them has a feature and concludes that the other one also has this feature.\\nArguments that fall short of the standards of logical reasoning are called fallacies. For formal fallacies, like affirming the consequent, the error lies in the logical form of the argument. For informal fallacies, like false dilemmas, the source of the faulty reasoning is usually found in the content or the context of the argument. Some theorists understand logical reasoning in a wide sense that is roughly equivalent to critical thinking. In this regard, it encompasses cognitive skills besides the ability to draw conclusions from premises. Examples are skills to generate and evaluate reasons and to assess the reliability of information. Further factors are to seek new information, to avoid inconsistencies, and to consider the advantages and disadvantages of different courses of action before making a decision.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Logical_reasoning'}, page_content='Logical reasoning is a mental activity that aims to arrive at a conclusion in a rigorous way. It happens in the form of inferences or arguments by starting from a set of premises and reasoning to a conclusion supported by these premises. The premises and the conclusion are propositions, i.e. true or false claims about what is the case. Together, they form an argument. Logical reasoning is norm-governed in the sense that it aims to formulate correct arguments that any rational person would find convincing. The main discipline studying logical reasoning is logic. \\nDistinct types of logical reasoning differ from each other concerning the norms they employ and the certainty of the conclusion they arrive at. Deductive reasoning offers the strongest support: the premises ensure the conclusion, meaning that it is impossible for the conclusion to be false if all the premises are true. Such an argument is called a valid argument, for example: all men are mortal; Socrates is a man; therefore, Socrates is mortal. For valid arguments, it is not important whether the premises are actually true but only that, if they were true, the conclusion could not be false. Valid arguments follow a rule of inference, such as modus ponens or modus tollens. Deductive reasoning plays a central role in formal logic and mathematics.\\nFor non-deductive logical reasoning, the premises make their conclusion rationally convincing without ensuring its truth. This is often understood in terms of probability: the premises make it more likely that the conclusion is true and strong inferences make it very likely. Some uncertainty remains because the conclusion introduces new information not already found in the premises. Non-deductive reasoning plays a central role in everyday life and in most sciences. Often-discussed types are inductive, abductive, and analogical reasoning. Inductive reasoning is a form of generalization that infers a universal law from a pattern found in many individual cases. It can be used to conclude that \"all ravens are black\" based on many individual observations of black ravens. Abductive reasoning, also known as \"inference to the best explanation\", starts from an observation and reasons to the fact explaining this observation. An example is a doctor who examines the symptoms of their patient to make a diagnosis of the underlying cause. Analogical reasoning compares two similar systems. It observes that one of them has a feature and concludes that the other one also has this feature.\\nArguments that fall short of the standards of logical reasoning are called fallacies. For formal fallacies, like affirming the consequent, the error lies in the logical form of the argument. For informal fallacies, like false dilemmas, the source of the faulty reasoning is usually found in the content or the context of the argument. Some theorists understand logical reasoning in a wide sense that is roughly equivalent to critical thinking. In this regard, it encompasses cognitive skills besides the ability to draw conclusions from premises. Examples are skills to generate and evaluate reasons and to assess the reliability of information. Further factors are to seek new information, to avoid inconsistencies, and to consider the advantages and disadvantages of different courses of action before making a decision.\\n\\n\\n== Definition ==\\nLogical reasoning is a form of thinking that is concerned with arriving at a conclusion in a rigorous way. This happens in the form of inferences by transforming the information present in a set of premises to reach a conclusion. It can be defined as \"selecting and interpreting information from a given context, making connections, and verifying and drawing conclusions based on provided and interpreted information and the associated rules and processes.\" Logical reasoning is rigorous in the sense that it does not generate any conclusion but ensures that the premises support the conclusion and act as reasons for believing it. One central ')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_data(data, chunk_size=256):\n",
        "  from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "  # Define separators for splitting (optional)\n",
        "  separators = [\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        "  text_splitter = RecursiveCharacterTextSplitter(\n",
        "      separators=separators,\n",
        "      chunk_size=chunk_size,\n",
        "      chunk_overlap=0\n",
        "  )\n",
        "  chunks = text_splitter.split_documents(data)\n",
        "  return chunks"
      ],
      "metadata": {
        "id": "E8niAbBfdJuG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_document('/content/KR-reasoning-LLM-framework.pdf')\n",
        "# print(data[0].page_content)\n",
        "\n",
        "chunks = chunk_data(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aCEQUyCvu-Wc",
        "outputId": "1d982efa-254f-4f18-eabb-fae0e12d7ccd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/KR-reasoning-LLM-framework - .pdf\n",
            "Loading /content/KR-reasoning-LLM-framework.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "pc_apikey = userdata.get('PINECONE_API_KEY')\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "EOg8-wGB1mR9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6ksfgBr2dLFc",
        "outputId": "1a011d29-7b17-4aae-de31-f402b8ade603"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.66.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.10-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.48 (from langchain_openai)\n",
            "  Downloading langchain_core-0.3.48-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting openai<2.0.0,>=1.68.2 (from langchain_openai)\n",
            "  Downloading openai-1.68.2-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (0.3.18)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (2.10.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.48->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.48->langchain_openai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.48->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.48->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.48->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.48->langchain_openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.3.0)\n",
            "Downloading langchain_openai-0.3.10-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.48-py3-none-any.whl (418 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.7/418.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.68.2-py3-none-any.whl (606 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m606.1/606.1 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, openai, langchain-core, langchain_openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.66.5\n",
            "    Uninstalling openai-1.66.5:\n",
            "      Successfully uninstalled openai-1.66.5\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.46\n",
            "    Uninstalling langchain-core-0.3.46:\n",
            "      Successfully uninstalled langchain-core-0.3.46\n",
            "Successfully installed langchain-core-0.3.48 langchain_openai-0.3.10 openai-1.68.2 tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "\n",
        "llm = OpenAI(api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "bMvf0hAt1ryg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the LLM\n",
        "llm.invoke(\"Tell me a joke\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "np2JW0FrhvDH",
        "outputId": "3b93f372-f2d4-4fef-9283-729b1e14d9c6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\nWhy couldn't the bicycle stand up by itself?\\n\\nBecause it was two-tired.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsHajanS-r4W",
        "outputId": "dd886eeb-ea33-41a5-d078-c721af0c8e81"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2025.1.31)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7g42MQu_pm9",
        "outputId": "a54e8db7-6fc7-456b-fbdc-6ebcfbcbe0e0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (0.3.10)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.48 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.48)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.68.2)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (0.3.18)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (2.10.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.48->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.48->langchain_openai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.48->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.48->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.48->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.48->langchain_openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjWY_eYk_vec",
        "outputId": "1cf649ef-ab74-4193-f669-b902494d8d1d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_pinecone\n",
            "  Downloading langchain_pinecone-0.2.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain_pinecone) (0.3.48)\n",
            "Collecting pinecone<6.0.0,>=5.4.0 (from langchain_pinecone)\n",
            "  Downloading pinecone-5.4.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting aiohttp<3.11,>=3.10 (from langchain_pinecone)\n",
            "  Downloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting numpy<2.0.0,>=1.26.4 (from langchain_pinecone)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-tests<1.0.0,>=0.3.7 (from langchain_pinecone)\n",
            "  Downloading langchain_tests-0.3.16-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (6.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (1.18.3)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (0.3.18)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (2.10.6)\n",
            "Requirement already satisfied: pytest<9,>=7 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (8.3.5)\n",
            "Collecting pytest-asyncio<1,>=0.20 (from langchain-tests<1.0.0,>=0.3.7->langchain_pinecone)\n",
            "  Downloading pytest_asyncio-0.26.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (0.28.1)\n",
            "Collecting syrupy<5,>=4 (from langchain-tests<1.0.0,>=0.3.7->langchain_pinecone)\n",
            "  Downloading syrupy-4.9.1-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting pytest-socket<1,>=0.6.0 (from langchain-tests<1.0.0,>=0.3.7->langchain_pinecone)\n",
            "  Downloading pytest_socket-0.7.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (2025.1.31)\n",
            "Collecting pinecone-plugin-inference<4.0.0,>=2.0.0 (from pinecone<6.0.0,>=5.4.0->langchain_pinecone)\n",
            "  Downloading pinecone_plugin_inference-3.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (2.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (2.27.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (1.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone<6.0.0,>=5.4.0->langchain_pinecone) (1.17.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<3.11,>=3.10->langchain_pinecone) (0.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (1.3.1)\n",
            "Downloading langchain_pinecone-0.2.3-py3-none-any.whl (11 kB)\n",
            "Downloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_tests-0.3.16-py3-none-any.whl (39 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone-5.4.2-py3-none-any.whl (427 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-3.1.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_asyncio-0.26.0-py3-none-any.whl (19 kB)\n",
            "Downloading pytest_socket-0.7.0-py3-none-any.whl (6.8 kB)\n",
            "Downloading syrupy-4.9.1-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pinecone-plugin-inference, numpy, syrupy, pytest-socket, pytest-asyncio, pinecone, aiohttp, langchain-tests, langchain_pinecone\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: pinecone\n",
            "    Found existing installation: pinecone 6.0.2\n",
            "    Uninstalling pinecone-6.0.2:\n",
            "      Successfully uninstalled pinecone-6.0.2\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.14\n",
            "    Uninstalling aiohttp-3.11.14:\n",
            "      Successfully uninstalled aiohttp-3.11.14\n",
            "Successfully installed aiohttp-3.10.11 langchain-tests-0.3.16 langchain_pinecone-0.2.3 numpy-1.26.4 pinecone-5.4.2 pinecone-plugin-inference-3.1.0 pytest-asyncio-0.26.0 pytest-socket-0.7.0 syrupy-4.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks), type(chunks)\n",
        "# chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7Z94zGjbtGi",
        "outputId": "f4ad2527-09ef-4a13-a205-ee50011654be"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(415, list)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, chunk in enumerate(chunks):\n",
        "    print(f\"Chunk {i + 1}:\")\n",
        "    print(chunk.page_content)  # Assuming chunks have a `page_content` attribute\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "S7ZmSlCocK26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e81d2195-02b1-4bad-d1d9-242122a360c2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1:\n",
            "K-Level Reasoning: Establishing Higher Order Beliefs\n",
            "in Large Language Models for Strategic Reasoning\n",
            "Yadong Zhang1,2,*, Shaoguang Mao2,†, Tao Ge2, Xun Wang2,\n",
            "Yan Xia2, Man Lan1, Furu Wei2,\n",
            "1East China Normal University, 2Microsoft Research Asia\n",
            "Abstract\n",
            "--------------------------------------------------\n",
            "Chunk 2:\n",
            "Strategic reasoning is a complex yet essential\n",
            "capability for intelligent agents. It requires\n",
            "Large Language Model (LLM) agents to adapt\n",
            "their strategies dynamically in multi-agent en-\n",
            "vironments. Unlike static reasoning tasks, suc-\n",
            "--------------------------------------------------\n",
            "Chunk 3:\n",
            "cess in these contexts depends on anticipating\n",
            "other agents’ beliefs and actions while contin-\n",
            "uously adjusting strategies to achieve individ-\n",
            "ual goals. LLMs and LLM agents often strug-\n",
            "gle with strategic reasoning due to the absence\n",
            "--------------------------------------------------\n",
            "Chunk 4:\n",
            "of a reasoning framework that enables them\n",
            "to dynamically infer others’ perspectives and\n",
            "adapt to changing environments. Inspired by\n",
            "the Level-K framework1 from game theory and\n",
            "behavioral economics, which extends reason-\n",
            "--------------------------------------------------\n",
            "Chunk 5:\n",
            "ing from simple reactions to structured strate-\n",
            "gic depth, we propose a novel framework: \"K-\n",
            "Level Reasoning with Large Language Mod-\n",
            "els (K-R).\" This framework employs recursive\n",
            "mechanisms to enable LLMs to achieve vary-\n",
            "--------------------------------------------------\n",
            "Chunk 6:\n",
            "ing levels of strategic depth, allowing agents to\n",
            "form higher order beliefs—beliefs about others’\n",
            "beliefs. We validate this framework through\n",
            "rigorous testing on four testbeds: two classi-\n",
            "cal game theory problems and two social in-\n",
            "--------------------------------------------------\n",
            "Chunk 7:\n",
            "telligence tasks. The results demonstrate the\n",
            "advantages of K-R in strategic reasoning. Our\n",
            "work presents the first recursive implementa-\n",
            "tion of strategic depth in large language models\n",
            "(LLMs). It establishes a foundation for future\n",
            "--------------------------------------------------\n",
            "Chunk 8:\n",
            "research into theory of mind and strategic rea-\n",
            "soning in LLMs.\n",
            "1 Introduction\n",
            "Strategic reasoning—decision-making in multi-\n",
            "participant environments—presents unique chal-\n",
            "lenges for Large Language Models (LLMs) and\n",
            "--------------------------------------------------\n",
            "Chunk 9:\n",
            "LLM agents(Zhang et al., 2024b). In these settings,\n",
            "*Work was done when interning at Microsoft Research\n",
            "Asia. † Correspondence to: shaoguang.mao@microsoft.com\n",
            "1According to the Level-k Framework, k-level thinking\n",
            "--------------------------------------------------\n",
            "Chunk 10:\n",
            "involves considering what opponent/partner are likely to do,\n",
            "what they think you will do, and what they believe you think\n",
            "they will do, and so on.\n",
            "First-level Thinking Second-level Thinking\n",
            "…\n",
            "Third-level Thinking\n",
            "……\n",
            "--------------------------------------------------\n",
            "Chunk 11:\n",
            "Figure 1: Level-K Framework: In first-level thinking,\n",
            "agents respond directly to the environment. In second-\n",
            "level thinking, agents consider the first-level thinking of\n",
            "others. This process continues iteratively, with agents\n",
            "--------------------------------------------------\n",
            "Chunk 12:\n",
            "forming higher order beliefs based on assumptions about\n",
            "others’ thoughts.\n",
            "agents must respond to the actions of others while\n",
            "adapting to dynamic environments. They also need\n",
            "to align their decisions with their own goals during\n",
            "--------------------------------------------------\n",
            "Chunk 13:\n",
            "these interactions. Strategic reasoning is essential\n",
            "for intelligent agents and is widely applied in real-\n",
            "world tasks, such as investment, business strategy\n",
            "making(Zhao et al., 2023), negotiation(Hua et al.,\n",
            "2023), and policy-making(Li et al., 2024).\n",
            "--------------------------------------------------\n",
            "Chunk 14:\n",
            "Effective strategic reasoning relies on under-\n",
            "standing others’ perspectives and anticipating their\n",
            "strategies. While there are some research efforts on\n",
            "LLMs’ strategic reasoning, most methods rely on\n",
            "static prompting (Fu et al., 2023; Xu et al., 2023b).\n",
            "--------------------------------------------------\n",
            "Chunk 15:\n",
            "This typically involves instructing the model to ac-\n",
            "count for others’ beliefs and decisions during its\n",
            "own decision-making process in the prompt. How-\n",
            "ever, these approaches fall short in enabling LLMs\n",
            "to form true higher order beliefs—beliefs about\n",
            "--------------------------------------------------\n",
            "Chunk 16:\n",
            "what others believe, and lack the flexibility needed\n",
            "for deeper strategic reasoning.\n",
            "K-level thinking (Figure 1) (Nagel, 1995; Cui\n",
            "et al., 2021), a classical concept in behavioral eco-\n",
            "nomics and game theory, categorizes reasoning into\n",
            "--------------------------------------------------\n",
            "Chunk 17:\n",
            "varying depths of strategic thought. It involves not\n",
            "only predicting others’ actions but also considering\n",
            "1\n",
            "arXiv:2402.01521v2  [cs.CL]  17 Oct 2024\n",
            "--------------------------------------------------\n",
            "Chunk 18:\n",
            "Please choose an integer between 1 and 100. The player \n",
            "whose chosen number is closest to 0.8 * the average of all \n",
            "chosen numbers wins the round. Let's start the 1st round.\n",
            "I think in the\n",
            "1st  round …\n",
            " …\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "--------------------------------------------------\n",
            "Chunk 19:\n",
            "(40 + 50 + 34 + 40 + 36) / 5 = 40  (Average)\n",
            "40 * 0.8 = 32 (Target) \n",
            "The daily available water can meet the needs of only one \n",
            "resident. An auction is conducted, and the highest bidder \n",
            "will obtain today's water supply.\n",
            "$55\n",
            "$100\n",
            "8 1\n",
            "$60\n",
            "$ 100\n",
            "$50\n",
            "$ 100\n",
            "--------------------------------------------------\n",
            "Chunk 20:\n",
            "$70\n",
            "$ 100\n",
            "$30\n",
            "$ 100\n",
            "In today’s bidding,        placed the highest bid of $70, \n",
            "securing the water resources for the day.        +2     and \n",
            "resets the number of days thirsty =0 . Other residents \n",
            "have their HP deducted based on the number of days they\n",
            "--------------------------------------------------\n",
            "Chunk 21:\n",
            "have been thirsty （ = - ）. \n",
            "A new day! All residents receive a daily salary of  $100. \n",
            "Today, the daily available water can meet the needs of only \n",
            "one resident ...\n",
            "Today I will bid \n",
            "$40 because …\n",
            "8 1\n",
            " 8 1\n",
            " 8 1\n",
            " 8 1\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "$90\n",
            "$200\n",
            "7 2\n",
            "$80\n",
            "$ 200\n",
            "--------------------------------------------------\n",
            "Chunk 22:\n",
            "$100\n",
            "$ 200\n",
            "$50\n",
            "$ 130\n",
            "$80\n",
            "$ 200\n",
            "In yesterday, \n",
            "  ………\n",
            "7 2\n",
            " 7 2\n",
            " 10 1\n",
            " 7 2\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "Guessing 0.8 of the Average Survival Auction Game\n",
            "40 50 34 40 36\n",
            "Let's start the 2nd round.\n",
            "In last \n",
            "round …\n",
            " …\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "31 36 24 25 21\n",
            "Closest to the target.\n",
            "--------------------------------------------------\n",
            "Chunk 23:\n",
            "40-32=8 50-32=18 34-32=2 40-32=8 36-32=4\n",
            "Private Utilities\n",
            "Private Utilities\n",
            "5\n",
            " 0 8\n",
            "We have 5         , 5       , and 5        . \n",
            "Please negotiate how to distribute \n",
            "them.\n",
            "7\n",
            " 2 1\n",
            "I want more        , as a result, I can \n",
            "accept less       , so I propose …\n",
            "--------------------------------------------------\n",
            "Chunk 24:\n",
            "I propose …\n",
            "Agreement achieved. \n",
            "      has 4      , 4        , and 0        , \n",
            "while     has 1       , 1       , and 5      . \n",
            "The total utilities:  \n",
            "     :36,      : 45.          wins!\n",
            "Negotiation\n",
            "--------------------------------------------------\n",
            "Chunk 25:\n",
            "Figure 2: The illustration of three reasoning problems in dynamic, interactive environments in this paper. Left:\n",
            "Guessing 0.8 of the Average; Middle: Survival Auction Game; Right: Negotiation.\n",
            "their beliefs about one’s actions, and even further\n",
            "--------------------------------------------------\n",
            "Chunk 26:\n",
            "layers of recursive thinking.\n",
            "Inspired by K-level thinking, we propose a novel\n",
            "strategic reasoning framework termed \"K-Level\n",
            "Reasoning with LLMs (K-R).\" K-R organizes rea-\n",
            "soning into hierarchical levels and employs a recur-\n",
            "--------------------------------------------------\n",
            "Chunk 27:\n",
            "sive mechanism to integrate varying strategic depth\n",
            "into decision-making. Specifically, it involves: 1)\n",
            "recursively anticipating others’ actions at varying\n",
            "levels of strategic depth with environmental context\n",
            "--------------------------------------------------\n",
            "Chunk 28:\n",
            "and historical public information, and 2) reason-\n",
            "ing the optimal action based on these anticipations.\n",
            "To the best of our knowledge, this is the first ap-\n",
            "proach to implementing varying levels of strategic\n",
            "depth in LLMs using a recursive mechanism and\n",
            "--------------------------------------------------\n",
            "Chunk 29:\n",
            "enables deeper reasoning in LLM agents through\n",
            "an algorithmic framework.\n",
            "We validate this framework through rigorous\n",
            "testing on four testbeds: two classical game theory\n",
            "problems and two social intelligence tasks. The\n",
            "--------------------------------------------------\n",
            "Chunk 30:\n",
            "game theory problems includes Guessing 0.8 of\n",
            "the Average (Figure 2 left) and Survival Auction\n",
            "Game (Mao et al., 2023) (Figure 2 middle). The\n",
            "social intelligence tasks includes Negotiation (Cao\n",
            "et al., 2018) (Figure 2 right) and SOTOPIA bench-\n",
            "--------------------------------------------------\n",
            "Chunk 31:\n",
            "mark(Zhou et al., 2024). These settings serve as\n",
            "microcosms of the complex decision-making pro-\n",
            "cesses involved in strategic reasoning. Through\n",
            "extensive experiments, we demonstrate that our\n",
            "framework significantly outperforms existing rea-\n",
            "--------------------------------------------------\n",
            "Chunk 32:\n",
            "soning methods and flexibly achieves varying lev-\n",
            "els of strategic depth. In addition to empirical evi-\n",
            "dence, we provide a theoretical analysis highlight-\n",
            "ing the benefits of K-R. We show that, leveraging\n",
            "the in-context learning capabilities of LLMs, K-R\n",
            "--------------------------------------------------\n",
            "Chunk 33:\n",
            "can effectively model opponents’ behavior using\n",
            "accumulated public and available opponent infor-\n",
            "mation.\n",
            "Furthermore, we align the strategic depth of\n",
            "LLMs with human participants (Nagel, 1995;\n",
            "Bosch-Domenech et al., 2002). Using human as\n",
            "--------------------------------------------------\n",
            "Chunk 34:\n",
            "anchors, we observe that the K-R significantly en-\n",
            "hances the strategic depth of LLMs from 0.25 to\n",
            "1.89. Notably, when K=3, the strategic depth (1.89)\n",
            "of the LLM closely approaches that of financial\n",
            "newspaper readers (1.91). This strongly indicates\n",
            "--------------------------------------------------\n",
            "Chunk 35:\n",
            "that K-R establishes higher order beliefs in LLMs\n",
            "for strategic reasoning.\n",
            "The contributions of this work are as follows:\n",
            "• We introduce K-R, a novel framework that\n",
            "extends k-level thinking to LLMs, enabling\n",
            "flexible strategic reasoning at varying depths\n",
            "--------------------------------------------------\n",
            "Chunk 36:\n",
            "through a recursive mechanism.\n",
            "• We conduct extensive evaluations, including\n",
            "game theory and social intelligence problems,\n",
            "demonstrating that K-R significantly outper-\n",
            "forms existing methods in terms of flexibility\n",
            "--------------------------------------------------\n",
            "Chunk 37:\n",
            "and effectiveness, across both closed-source\n",
            "and open-source models.\n",
            "• We provide an in-depth analysis of K-R, con-\n",
            "firming its ability to build higher order beliefs\n",
            "and enhance strategic reasoning. This lays\n",
            "a foundation for future research in theory of\n",
            "--------------------------------------------------\n",
            "Chunk 38:\n",
            "mind and strategic reasoning in LLMs.\n",
            "2 K-Level Reasoning with Large\n",
            "Language Models\n",
            "2.1 Methodology\n",
            "Strategic reasoning requires considering both the\n",
            "decision context and the possible actions of other\n",
            "2\n",
            "--------------------------------------------------\n",
            "Chunk 39:\n",
            "participants.We employ a multi-round normal form\n",
            "multi-participant game to introduce the proposed\n",
            "method. In this setting, an agent’s decision-making\n",
            "process is formalized as follows: each agent i se-\n",
            "lects an action at\n",
            "i from a set At\n",
            "i at timestep t. The\n",
            "--------------------------------------------------\n",
            "Chunk 40:\n",
            "payoff for agent i, resulting from the collective ac-\n",
            "tion profile At = (at\n",
            "1, at\n",
            "2, ..., at\n",
            "N ) and environment\n",
            "Et, is denoted as Ui(Et, At).\n",
            "At k = 1, agents decide based on environment\n",
            "Et without strategic anticipation:\n",
            "at,1\n",
            "i = arg max\n",
            "ai∈At\n",
            "i\n",
            "--------------------------------------------------\n",
            "Chunk 41:\n",
            "E[Ui(Et, ai)] (1)\n",
            "At higher level thinking (k ≥ 2), agent i simulates\n",
            "other agents operating at level k − 1 and adjusts\n",
            "their strategy accordingly2:\n",
            "at,k\n",
            "i = arg max\n",
            "ai∈At\n",
            "i\n",
            "E[Ui(Et, ai, ˆat,k−1\n",
            "−i )] (2)\n",
            "where ˆat,k−1\n",
            "--------------------------------------------------\n",
            "Chunk 42:\n",
            "−i are the predicted actions of other\n",
            "agents based on their k − 1 level reasoning.\n",
            "We propose a novel strategic reasoning frame-\n",
            "work with recursive mechanisms , termed “K-\n",
            "Level Reasoning with Large Language Models\n",
            "--------------------------------------------------\n",
            "Chunk 43:\n",
            "(K-R),” involving 1) recursively anticipating the\n",
            "actions ˆat,k\n",
            "−i of others at different thinking levels\n",
            "using environment contexts and historical public\n",
            "information, followed by 2) reasoning the optimal\n",
            "action at,k\n",
            "--------------------------------------------------\n",
            "Chunk 44:\n",
            "i based on anticipation of others’ actions.\n",
            "The K-Level Reasoning process is formulated as\n",
            "follows:\n",
            "1) Anticipation:\n",
            "ˆat,m\n",
            "j =\n",
            "(\n",
            "LLM(Et, Ht\n",
            "j) if m = 1\n",
            "LLM(Et, Ht\n",
            "j, ˆat,m−1\n",
            "−j ) if m >1 (3)\n",
            "where Ht\n",
            "j = {(E1, a1\n",
            "j ), (E2, a2\n",
            "j ), ...,(Et−1, at−1\n",
            "j )}\n",
            "--------------------------------------------------\n",
            "Chunk 45:\n",
            "represents public historical data of agent j, and m\n",
            "denotes the specified thinking level.\n",
            "2) Reasoning:\n",
            "at,k\n",
            "i = LLM(Et, Ht\n",
            "i , ˆat,k−1\n",
            "−i ) (4)\n",
            "Algorithm 1 outlines the implementation of K-R.\n",
            "This recursive method enables flexible and progres-\n",
            "--------------------------------------------------\n",
            "Chunk 46:\n",
            "sively deeper strategic reasoning ( 1, 2, ..., k, k+\n",
            "1, ...), thereby enhancing higher order belief in\n",
            "LLM agents.\n",
            "2 To simplify the formulation, we assume that all oppo-\n",
            "nents are in the same thinking level. In practice, varying\n",
            "--------------------------------------------------\n",
            "Chunk 47:\n",
            "thinking level can be implemented.\n",
            "Algorithm 1 K-Level Reasoning with LLMs\n",
            "Require: Et: Current decision context at time t;\n",
            "Ht\n",
            "i : Historical information up to time t for\n",
            "agent i;\n",
            "K: Depth of strategic reasoning;\n",
            "Ensure: at,K\n",
            "--------------------------------------------------\n",
            "Chunk 48:\n",
            "i : Action for agent i at time t after\n",
            "K-level reasoning.\n",
            "1: Function K_REASONING(i, k):\n",
            "2: if k == 1then\n",
            "3: return LLM(Et, Ht\n",
            "i )\n",
            "4: else\n",
            "5: for each agent j ̸= i do\n",
            "6: ˆat,k−1\n",
            "j = K_REASONING(j, k− 1)\n",
            "7: end for\n",
            "8: return LLM(Et, Ht\n",
            "i , {ˆat,k−1\n",
            "--------------------------------------------------\n",
            "Chunk 49:\n",
            "j | j ̸= i})\n",
            "9: end if\n",
            "10: at,K\n",
            "i = K_REASONING(i, K)\n",
            "11: return at,K\n",
            "i\n",
            "2.2 Theoretical Analysis\n",
            "This section discusses the benefits from K-R from\n",
            "a theoretical perspective. We utilize the in-context\n",
            "learning capabilities of LLMs to effectively model\n",
            "--------------------------------------------------\n",
            "Chunk 50:\n",
            "opponents’ behavior. Suppose agent j’s decision-\n",
            "making process follows a hidden strategy θ∗\n",
            "j . Thus,\n",
            "agent j’s decision-making can be expressed as:\n",
            "P(at\n",
            "j | Et, θ∗\n",
            "j ) (5)\n",
            "The in-context learning of LLMs can be formally\n",
            "--------------------------------------------------\n",
            "Chunk 51:\n",
            "defined as implicit Bayesian inference(Xie et al.,\n",
            "2021); therefore, given the environment Et, the\n",
            "next action prediction conditioned on Ht\n",
            "j is:\n",
            "P(at\n",
            "j | Et, Ht\n",
            "j) =\n",
            "Z\n",
            "P(at\n",
            "j | Et, θj)P(θj | Ht\n",
            "j)dθj\n",
            "(6)\n",
            "As t → ∞, by the law of large numbers and proper-\n",
            "--------------------------------------------------\n",
            "Chunk 52:\n",
            "ties of Bayesian updating, the posterior distribution\n",
            "concentrates around the true parameter θ∗\n",
            "j :\n",
            "P(θj | Ht\n",
            "j) → δ(θj − θ∗\n",
            "j ) (7)\n",
            "where δ is the Dirac delta function. Therefore,\n",
            "Z\n",
            "P(at\n",
            "j | Et, θj)P(θj | Ht\n",
            "j)dθj → P(at\n",
            "j | Et, θ∗\n",
            "j )\n",
            "(8)\n",
            "--------------------------------------------------\n",
            "Chunk 53:\n",
            "This implies that as the number of interactions\n",
            "increases, K-R can more accurately predict oppo-\n",
            "nents’ behavior.\n",
            "It is also worth noting that interaction data can-\n",
            "not be infinite, and in-context learning is related to\n",
            "3\n",
            "--------------------------------------------------\n",
            "Chunk 54:\n",
            "the performance of large language models (LLMs).\n",
            "Therefore, we empircally validate these hypotheses\n",
            "and reasoning in Section 5.2.\n",
            "3 Experiments: Game Theory\n",
            "To fairly compare the strategic reasoning capabili-\n",
            "--------------------------------------------------\n",
            "Chunk 55:\n",
            "ties of LLMs, we first adopt two widely used game\n",
            "theory settings. These controlled, well-defined\n",
            "game theory problems provide a robust assessment\n",
            "of LLMs’ performance, with detailed setups out-\n",
            "lined in Appendix B.\n",
            "3.1 Task Definition and Metrics\n",
            "--------------------------------------------------\n",
            "Chunk 56:\n",
            "3.1.1 Guessing 0.8 of the Average (G0.8A)\n",
            "G0.8A (Figure 2 Left) is a classic game theory\n",
            "problem introduced by Alain Ledoux (Ledoux,\n",
            "1981). It involves 10-round games where each\n",
            "player selects a number between 1 and 100. The\n",
            "--------------------------------------------------\n",
            "Chunk 57:\n",
            "objective is to choose a number closest to 80% of\n",
            "the group’s average choice. The key idea is to guess\n",
            "how others will estimate the average and decide the\n",
            "number to submit. This concept is also illustrated\n",
            "in the Keynesian Beauty Contest (Keynes, 1936).\n",
            "--------------------------------------------------\n",
            "Chunk 58:\n",
            "This game mirrors the challenge of anticipating\n",
            "collective behavior in financial markets, where in-\n",
            "vestors must predict not only the value of an asset\n",
            "but also how others will value it in the future.\n",
            "The performance of the agent is evaluated using\n",
            "--------------------------------------------------\n",
            "Chunk 59:\n",
            "the Win Rate. Specifically, the Win Rate is calcu-\n",
            "lated based on the wins achieved by the agent in in-\n",
            "dividual round, rather than an entire game episode.\n",
            "3.1.2 Survival Auction Game (SAG)\n",
            "SAG (Figure 2 Middle) is derived from the Wa-\n",
            "--------------------------------------------------\n",
            "Chunk 60:\n",
            "ter Allocation Challenge proposed in (Mao et al.,\n",
            "2023). Each resident’s goal is to survive a 10-day\n",
            "drought period by bidding for water resources and\n",
            "maintaining health points above zero. If a player\n",
            "successfully bids for water, they gain health points;\n",
            "--------------------------------------------------\n",
            "Chunk 61:\n",
            "otherwise, they lose health points. This integration\n",
            "of the auction system with the health points mecha-\n",
            "nism creates a dynamic environment where players\n",
            "must balance health and finances.\n",
            "We use Average Survival Roundmeasures the\n",
            "--------------------------------------------------\n",
            "Chunk 62:\n",
            "mean round in which a player remains active in the\n",
            "game.\n",
            "3.2 Base Techniques\n",
            "We adapt a variety of approaches, originally from\n",
            "traditional reasoning and agent benchmarks. These\n",
            "base techniques include:\n",
            "Standard Prompting (Direct): This is the con-\n",
            "--------------------------------------------------\n",
            "Chunk 63:\n",
            "ventional prompting method in which the LLM\n",
            "generates the final answer (Action) in response to\n",
            "the given game setting prompt.\n",
            "Chain-of-Thought (CoT) (Wei et al., 2022): We\n",
            "employ the zero-shot Chain-of-Thought reasoning\n",
            "method (Kojima et al., 2022).\n",
            "--------------------------------------------------\n",
            "Chunk 64:\n",
            "Persona Prompting (Persona) (Deshpande\n",
            "et al., 2023): This technique modifies the standard\n",
            "prompting process by incorporating a “Game Ex-\n",
            "pert” persona to enhance the reasoning capabilities\n",
            "of the LLM.\n",
            "Reflexion (Reflect) (Shinn et al., 2023): This\n",
            "--------------------------------------------------\n",
            "Chunk 65:\n",
            "method refers to language agents with verbal rein-\n",
            "forcement learning and has been adapted for dy-\n",
            "namic tasks. Detailed modifications are explained\n",
            "in K.\n",
            "Self-Refine (Refine) (Madaan et al., 2023): This\n",
            "is a multi-round iterative reasoning approach where\n",
            "--------------------------------------------------\n",
            "Chunk 66:\n",
            "an additional LLM offers comments and adjust-\n",
            "ments prior to reaching a final decision. The dis-\n",
            "tinctions between Self-Refine and Reflect are elab-\n",
            "orated upon in the Appendix I.\n",
            "Prediction Chain of Thought (PCoT) : This\n",
            "--------------------------------------------------\n",
            "Chunk 67:\n",
            "strong baseline diverges from CoT by requiring the\n",
            "LLM to explicitly predict opponents’ actions be-\n",
            "fore making decisions. Unlike K-Level Reasoning,\n",
            "which involves a recursive approach, PCoT focuses\n",
            "on direct prediction based on context.\n",
            "--------------------------------------------------\n",
            "Chunk 68:\n",
            "For implementation details and specific exam-\n",
            "ples, please refer to Appendix K.\n",
            "3.3 Experimental Settings\n",
            "We established a controllable environment and dis-\n",
            "tinguished between two roles: the player (primary\n",
            "focus) and the opponents. The player is equipped\n",
            "--------------------------------------------------\n",
            "Chunk 69:\n",
            "with a specific method, while all opponents use\n",
            "another reasoning approach. This well-defined set-\n",
            "ting allows for a clearer comparison of reasoning\n",
            "capabilities between methods.\n",
            "In G0.8A and SAG, there is one player and four\n",
            "--------------------------------------------------\n",
            "Chunk 70:\n",
            "opponents for each game. Experiments for each\n",
            "setting are repeated 10 times and have passed the\n",
            "significance test (Appendix H), and each experi-\n",
            "ment consists of a 10-round game.\n",
            "All methods in main experiments were imple-\n",
            "--------------------------------------------------\n",
            "Chunk 71:\n",
            "mented using GPT-4 (Achiam et al., 2023) (gpt4-\n",
            "32k), with the temperature set at 0.7 and the top-p\n",
            "set at 0.9. We also conducted experiments with\n",
            "open-source LLMs, Details of which are provided\n",
            "in Appendix E. Unless specified otherwise, the\n",
            "4\n",
            "--------------------------------------------------\n",
            "Chunk 72:\n",
            "level of thinking in K-Level Reasoning is set to\n",
            "K=2.\n",
            "3.4 Results\n",
            "To distinguish between “Player” and “Opponent”\n",
            "in the table, the headers for Player (bold) and Op-\n",
            "ponents (italics) are formatted accordingly.\n",
            "--------------------------------------------------\n",
            "Chunk 73:\n",
            "Table 1: Win Rate of the player against different oppo-\n",
            "nents in G0.8A game.\n",
            "Direct CoT Persona Reflect Refine PCoT K-R\n",
            "Direct 0.43 0.67 0.62 0.53 0.43 0.61 0.82\n",
            "CoT 0.07 0.32 0.35 0.14 0.22 0.45 0.63\n",
            "Persona0.05 0.37 0.29 0.05 0.37 0.11 0.46\n",
            "--------------------------------------------------\n",
            "Chunk 74:\n",
            "Reflect 0.42 0.68 0.63 0.39 0.64 0.74 0.78\n",
            "Refine 0.10 0.34 0.32 0.31 0.23 0.22 0.46\n",
            "PCoT 0.03 0.44 0.52 0.21 0.51 0.54 0.85\n",
            "K-R 0.04 0.15 0.14 0.04 0.17 0.14 0.52\n",
            "Average0.16\n",
            "± 0.18\n",
            "0.32\n",
            "± 0.19\n",
            "0.41\n",
            "± 0.18\n",
            "0.24\n",
            "± 0.18\n",
            "0.37\n",
            "± 0.17\n",
            "0.40\n",
            "± 0.25\n",
            "0.65\n",
            "± 0.17\n",
            "--------------------------------------------------\n",
            "Chunk 75:\n",
            "Table 2: Average Survival Round of the player against\n",
            "different opponents in Survival Auction Game.\n",
            "Direct CoT Persona Reflect Refine PCoT K-R\n",
            "Direct 5.90 7.00 7.50 4.70 8.70 6.60 9.40\n",
            "CoT 5.70 6.50 5.30 4.00 8.10 5.30 10.00\n",
            "--------------------------------------------------\n",
            "Chunk 76:\n",
            "Persona5.70 7.70 7.40 5.20 6.30 7.20 9.30\n",
            "Reflect 9.40 9.40 9.90 5.20 8.60 8.20 10.00\n",
            "Refine 6.30 6.40 8.10 4.30 8.20 5.30 7.90\n",
            "PCoT 8.50 9.60 9.90 6.30 8.50 6.20 9.70\n",
            "K-R 4.10 5.50 5.00 4.04 5.70 4.40 6.80\n",
            "Average6.51\n",
            "± 1.82\n",
            "7.44\n",
            "± 1.55\n",
            "7.59\n",
            "± 1.95\n",
            "4.82\n",
            "--------------------------------------------------\n",
            "Chunk 77:\n",
            "± 0.82\n",
            "7.73\n",
            "± 1.21\n",
            "6.17\n",
            "± 1.29\n",
            "9.01\n",
            "± 1.21\n",
            "Table 1 presents Win Rate of players utilizing\n",
            "different methods against various opponents in the\n",
            "G0.8A game. Notably, the K-R method demon-\n",
            "strates a superior Win Rate of 0.65, significantly\n",
            "--------------------------------------------------\n",
            "Chunk 78:\n",
            "exceeding the win rates of the other strategies. Ta-\n",
            "ble 2 provides insights into the Average Survival\n",
            "Round of players across different auction game\n",
            "strategies in SAG, with the K-R method again\n",
            "standing out. The K-R method achieves an av-\n",
            "--------------------------------------------------\n",
            "Chunk 79:\n",
            "erage survival round of 9.01, considerably higher\n",
            "than all other methods.\n",
            "The experiment result underscores the effective-\n",
            "ness of the K-R method in enhancing player strat-\n",
            "egy, suggesting its strategic superiority in the con-\n",
            "--------------------------------------------------\n",
            "Chunk 80:\n",
            "text of this game. Its effectiveness lies in its ability\n",
            "to anticipate opponent moves, outperforming other\n",
            "prompting methods.\n",
            "The performance of Reflect did not demonstrate\n",
            "the effectiveness of the reasoning method. We hy-\n",
            "--------------------------------------------------\n",
            "Chunk 81:\n",
            "pothesize that this is due to the fact that, in dynamic\n",
            "environments, Reflect on the experiences summa-\n",
            "rized from the previous round (Shinn et al., 2023)\n",
            "may not be applicable to the subsequent round of\n",
            "the game. Furthermore, in both games, Refine did\n",
            "--------------------------------------------------\n",
            "Chunk 82:\n",
            "not show an advantage over CoT and was signif-\n",
            "icantly lower than K-R. This is because Refine\n",
            "involves adjustments based on one’sown strategy.\n",
            "However, these adjustments do not explicitly con-\n",
            "sider the hidden strategies of the opponent’s behav-\n",
            "--------------------------------------------------\n",
            "Chunk 83:\n",
            "ior, rendering them inapplicable against opponents\n",
            "employing different strategies.\n",
            "4 Experiments: Social Intelligence\n",
            "We then evaluate K-R in two social intelligence\n",
            "benchmarks to assess its performance in more open-\n",
            "--------------------------------------------------\n",
            "Chunk 84:\n",
            "ended realistic scenarios. Compared to the abstract\n",
            "and theoretical settings of Game Theory, these sce-\n",
            "narios involve richer contextual backgrounds and\n",
            "complicated goal pursuits, which better demon-\n",
            "strate the value of LLM-based agents in practical\n",
            "--------------------------------------------------\n",
            "Chunk 85:\n",
            "applications, such as in chatbots and strategic deci-\n",
            "sion making.\n",
            "4.1 Task Definition and Metrics\n",
            "4.1.1 Negotiation (NEG)\n",
            "NEG (Figure 2 Right)(Cao et al., 2018; Duan et al.,\n",
            "2024) is an open-ended and realistic task. In this\n",
            "--------------------------------------------------\n",
            "Chunk 86:\n",
            "setting, two agents are presented with three types\n",
            "of items: peppers, cherries, and strawberries. Each\n",
            "agent has private utility values for these items and\n",
            "must negotiate to allocate the public item pool.\n",
            "The agent who secures more utility upon reach-\n",
            "--------------------------------------------------\n",
            "Chunk 87:\n",
            "ing an agreement wins the game, and we calculated\n",
            "the Win Rate to assess the performance of different\n",
            "agents.\n",
            "4.1.2 SOTOPIA Benchmark\n",
            "SOTOPIA (Zhou et al., 2024) is an open-ended en-\n",
            "vironment to simulate complex social interactions\n",
            "--------------------------------------------------\n",
            "Chunk 88:\n",
            "between artificial agents and evaluate their social in-\n",
            "telligence. It includes a variety of social scenarios,\n",
            "and each scenario includes a context background,\n",
            "and private social goals of each agent. Meanwhile,\n",
            "--------------------------------------------------\n",
            "Chunk 89:\n",
            "each agent has a character profiles which consists\n",
            "of name, gender, personality, occupation, etc.\n",
            "For each episode, agents are scored at the end\n",
            "of the interaction along each of seven dimensions\n",
            "in SOTOPIA-Eval, including Goal Completion\n",
            "--------------------------------------------------\n",
            "Chunk 90:\n",
            "(GOAL), Believability (BEL), Knowledge (KNO),\n",
            "Secret ( SEC), Relationship ( REL), Social Rules\n",
            "(SOC), Financial and Material Benefits (FIN).\n",
            "5\n",
            "--------------------------------------------------\n",
            "Chunk 91:\n",
            "4.2 Experimental Settings\n",
            "We employed the majority of the reasoning ap-\n",
            "proaches introduced in Section 3.2 as baseline mod-\n",
            "els for comparison.\n",
            "In NEG, the experiments followed the settings\n",
            "from (Cao et al., 2018; Duan et al., 2024). There is\n",
            "--------------------------------------------------\n",
            "Chunk 92:\n",
            "one player and one opponent for each game. We\n",
            "test the performance of the Baselines and K-Level\n",
            "Reasoning in 100 repeated independent games. To\n",
            "eliminate positional advantages, we swapped the\n",
            "positions of each player for each setting. To en-\n",
            "--------------------------------------------------\n",
            "Chunk 93:\n",
            "sure the reliability, three trials were conducted, and\n",
            "the results are reported as averages with standard\n",
            "deviation.\n",
            "Meanwhile, We adhered to the SOTOPIA-hard\n",
            "(Zhou et al., 2024) setup comprising a total of 100\n",
            "--------------------------------------------------\n",
            "Chunk 94:\n",
            "episodes, which is commonly found to be challeng-\n",
            "ing for LLMs, and utilize a fixed GPT-4o based\n",
            "agent as partner. Additionally, to evaluate the\n",
            "agents’ scores, we utilized GPT-4 as the assessment\n",
            "model, as it has been determined by SOTOPIA\n",
            "--------------------------------------------------\n",
            "Chunk 95:\n",
            "benchmark (Zhou et al., 2024) to serve as a reliable\n",
            "serves as a proxy for human judgments in evalu-\n",
            "ating model performance across most dimensions\n",
            "and for human performance on the GOAL dimen-\n",
            "sion.\n",
            "4.3 Results\n",
            "--------------------------------------------------\n",
            "Chunk 96:\n",
            "Table 3: Win Rate of the player against opponent in\n",
            "Negotiation Setting.\n",
            "Direct CoT Persona Reflect Refine PCoT K-R\n",
            "Direct 50.00 61.34 49.58 66.67 65.83 63.03 70.83\n",
            "CoT 38.66 50.00 36.67 45.83 45.76 47.27 55.36\n",
            "--------------------------------------------------\n",
            "Chunk 97:\n",
            "Persona 50.42 63.33 50.00 70.00 67.50 62.50 70.83\n",
            "Reflection33.33 54.17 30.00 50.00 57.14 55.00 55.00\n",
            "Refine 34.17 54.24 32.50 42.86 50.00 55.77 54.55\n",
            "PCoT 36.97 52.73 37.50 45.00 44.23 50.00 57.00\n",
            "K-R 29.17 44.64 29.17 45.00 45.45 43.00 50.00\n",
            "--------------------------------------------------\n",
            "Chunk 98:\n",
            "Average38.96\n",
            "±2.53\n",
            "54.35\n",
            "±0.50\n",
            "37.92\n",
            "±5.84\n",
            "52.19\n",
            "±1.73\n",
            "53.70\n",
            "±4.41\n",
            "53.80\n",
            "±4.34\n",
            "59.08\n",
            "± 2.20\n",
            "The results presented in Table 3 and Table 4 il-\n",
            "lustrate the effectiveness of the K-Level Reasoning\n",
            "in the context of NEG and SOTOPIA-hard settings,\n",
            "respectively.\n",
            "--------------------------------------------------\n",
            "Chunk 99:\n",
            "In NEG, the K-R method demonstrates a notable\n",
            "win rate of 59.08%, positioning it significantly\n",
            "above the average win rates achieved by other meth-\n",
            "ods. This indicates that, in most cases, the propos-\n",
            "als generated through K-Level Reasoning are more\n",
            "--------------------------------------------------\n",
            "Chunk 100:\n",
            "advantageous to itself, as well as suggesting a ten-\n",
            "dency to accept the opponent’s proposals when the\n",
            "Table 4: SOTOPIA-Eval of the player against opponent\n",
            "in SOTOPIA-hard.\n",
            "Direct CoT Refine K-R Direct CoT Refine K-R\n",
            "Metric [GPT-4o] [LLaMA-3.1-70B]\n",
            "--------------------------------------------------\n",
            "Chunk 101:\n",
            "BEL[0–10] 8.97 9.00 9.00 8.97 8.88 8.85 8.90 8.97\n",
            "REL[-5–5] 2.38 2.40 2.27 2.67 1.38 1.18 0.82 2.40\n",
            "KNO[0–10] 6.05 6.05 6.25 6.25 5.88 5.53 5.33 6.12\n",
            "SEC[-10-0] 0.00 -0.05 0.00 0.00 -0.28 -0.25 -0.180.00\n",
            "--------------------------------------------------\n",
            "Chunk 102:\n",
            "SOC[-10–0] -0.05 0.00 -0.05 0.00 -0.70 -0.72 -0.640.00\n",
            "FIN[-5–5] 0.90 0.78 0.80 0.72 0.38 0.35 -0.08 0.75\n",
            "GOAL[0–10] 6.356.60 6.15 6.47 5.35 5.40 4.95 6.38\n",
            "Overall 3.51\n",
            "± 0.09\n",
            "3.54\n",
            "± 0.08\n",
            "3.49\n",
            "± 0.08\n",
            "3.59\n",
            "± 0.09\n",
            "2.98\n",
            "± 0.23\n",
            "2.90\n",
            "± 0.26\n",
            "2.73\n",
            "± 0.25\n",
            "3.52\n",
            "--------------------------------------------------\n",
            "Chunk 103:\n",
            "± 0.13\n",
            "perceived benefits are substantial.\n",
            "The results from SOTOPIA reveal several in-\n",
            "triguing findings. Firstly, while K-R demonstrates\n",
            "some improvement compared to other methods, the\n",
            "results are not statistically significant. We hypothe-\n",
            "--------------------------------------------------\n",
            "Chunk 104:\n",
            "size that this may be due to the inherent tendency\n",
            "of GPT-4 based models to assign higher scores to\n",
            "responses generated by GPT-4 based agents. No-\n",
            "tably, we observed that employing agents based on\n",
            "LLaMA 3.1 70B with K-R can lead to significant\n",
            "--------------------------------------------------\n",
            "Chunk 105:\n",
            "performance enhancements. Meanwhile, the over-\n",
            "all metrics indicate that K-R achieves performance\n",
            "levels comparable to those of the GPT-4 model,\n",
            "highlighting K-R’s potential in the realm of social\n",
            "intelligence.\n",
            "5 Discussions\n",
            "--------------------------------------------------\n",
            "Chunk 106:\n",
            "5.1 Does K-R Efficiently Establish a Higher\n",
            "Order Belief in LLMs?\n",
            "Table 5: Human performance in G2/3A.\n",
            "Experiments Lab Classroom Take-home TheoristsInternetNewsgroupNewspaper\n",
            "Mean Choice 35.13 26.84 25.20 17.15 22.16 23.08\n",
            "--------------------------------------------------\n",
            "Chunk 107:\n",
            "Strategic Depth 0.87 1.53 1.682.63 2.01 1.91\n",
            "Table 6: LLM performance in G0.8A in the first round.\n",
            "Method Direct CoT Persona Refine Reflect PCoT KR[k=2] KR[k=3]\n",
            "Mean Choice 47.29 37.8 41.0 41.0 45.2 44.0 38.42 32.79\n",
            "--------------------------------------------------\n",
            "Chunk 108:\n",
            "Strategic Depth 0.25 1.25 0.89 0.89 0.45 0.57 1.181.89\n",
            "As a classic game theory issue, the G0.8A\n",
            "problem has garnered significant research interest\n",
            "across various disciplines. We reference the exper-\n",
            "imental results of the classic research among hu-\n",
            "--------------------------------------------------\n",
            "Chunk 109:\n",
            "man participants (Nagel, 1995; Bosch-Domenech\n",
            "et al., 2002) as anchor points and present the av-\n",
            "erage decisions made by the K-Level Reasoning\n",
            "method (GPT-4) in the first round. Through this\n",
            "6\n",
            "--------------------------------------------------\n",
            "Chunk 110:\n",
            "comparison, we can observe the relative relation-\n",
            "ship between human cognitive levels and LLMs\n",
            "under different reasoning methods. The specific\n",
            "calculation method on strategic depth is described\n",
            "in Appendix C. The performance of humans and\n",
            "--------------------------------------------------\n",
            "Chunk 111:\n",
            "LLMs is shown in the Table 5 and Table 6\n",
            "From these observations, we can conclude that\n",
            "even when employing SOTA models, the strategic\n",
            "depth of GPT-4 under Direct Prompt (0.25) cannot\n",
            "compete with that of lower-strategic-capability un-\n",
            "--------------------------------------------------\n",
            "Chunk 112:\n",
            "dergraduate students in laboratory settings (0.87).\n",
            "Furthermore, the K-Level reasoning approach sig-\n",
            "nificantly enhances the reasoning depth of large\n",
            "language models, increasing it from 0.25 to 1.89,\n",
            "and the strategic depth of the large language model\n",
            "--------------------------------------------------\n",
            "Chunk 113:\n",
            "(1.89) approaches that of a group of financial news-\n",
            "paper readers (1.91) when K=3.\n",
            "5.2 K-Level Reasoning Leads to More\n",
            "Accurate Predictions About Opponents\n",
            "Round 2 Round 4 Round 6 Round 8 Round 10\n",
            "0\n",
            "5\n",
            "10\n",
            "15\n",
            "20Prediction Deviation\n",
            "K-R Prediction\n",
            "--------------------------------------------------\n",
            "Chunk 114:\n",
            "PCoT Prediction\n",
            "Figure 3: The deviation in prediction during the G0.8A\n",
            "between PCoT and K-Level Reasoning.\n",
            "Since K-R involves an intermediate step of mod-\n",
            "eling the opponent’s behavior, we examine the pro-\n",
            "--------------------------------------------------\n",
            "Chunk 115:\n",
            "gression of prediction accuracy. Figure 3 illustrates\n",
            "the prediction deviation between K-R and PCoT\n",
            "in G0.8A. K-R exhibits higher prediction accuracy\n",
            "than PCoT from Round 1, starting with more pre-\n",
            "cise and less random predictions. Moreover, the\n",
            "--------------------------------------------------\n",
            "Chunk 116:\n",
            "predictions converge quickly and become highly\n",
            "accurate in the second half of the game. This trend\n",
            "highlights the LLM’s increasing proficiency in un-\n",
            "derstanding higher order belief with more game-\n",
            "play context. Essentially, K-R instantiates new\n",
            "--------------------------------------------------\n",
            "Chunk 117:\n",
            "sessions to compute the opponent’s future actions.\n",
            "This approach leverages the in-context learning ca-\n",
            "pabilities of LLMs more effectively than PCoT’s\n",
            "prediction process (as theoretically discussed in\n",
            "Section 2.2). As a result, K-R achieves better pre-\n",
            "--------------------------------------------------\n",
            "Chunk 118:\n",
            "diction accuracy.\n",
            "5.3 Better Reasoning Methodology vs.\n",
            "Stronger Foundation Model\n",
            "There is a consensus that LLMs trained with more\n",
            "data and possessing larger parameter sizes demon-\n",
            "strate stronger reasoning capabilities. We explore\n",
            "--------------------------------------------------\n",
            "Chunk 119:\n",
            "whether K-Level Reasoning can significantly en-\n",
            "hance the strategic reasoning abilities of relatively\n",
            "weaker LLMs. To investigate, we conducted ex-\n",
            "periments comparing the performance of K-R with\n",
            "GPT-3.5 (K-R[GPT-3.5]) against other reasoning\n",
            "--------------------------------------------------\n",
            "Chunk 120:\n",
            "methods based on GPT-4. All experiments were\n",
            "repeated 10 times.\n",
            "Table 7: A comparison of K-Level Reasoning with GPT-\n",
            "3.5 and other reasoning approaches with GPT-4. For\n",
            "the Guessing 0.8 of the Average, we report the win rate;\n",
            "--------------------------------------------------\n",
            "Chunk 121:\n",
            "for the Survival Auction Game, we report the average\n",
            "survival round.\n",
            "Guessing 0.8 of the Average Survival Auction Game\n",
            "OpponentDirect K-R Direct K-R Direct K-R Direct K-R\n",
            "[GPT-4][GPT-3.5] [GPT-3.5] [GPT-4] [GPT-4] [GPT-3.5] [GPT-3.5] [GPT-4] [GPT-4]\n",
            "--------------------------------------------------\n",
            "Chunk 122:\n",
            "Direct 0.18 0.18 0.43 0.82 5.00 9.40 5.90 9.40\n",
            "CoT 0.14 0.37 0.07 0.63 5.30 8.10 5.7010.00\n",
            "Persona0.10 0.23 0.05 0.46 5.00 7.50 5.70 9.30\n",
            "Reflect 0.24 0.38 0.42 0.78 5.00 8.50 9.4010.00\n",
            "Refine 0.14 0.13 0.10 0.46 5.10 6.70 6.30 7.90\n",
            "--------------------------------------------------\n",
            "Chunk 123:\n",
            "PCoT 0.19 0.46 0.03 0.85 4.10 6.80 8.50 9.70\n",
            "Average0.16 0.29 0.18 0.67 4.92 7.83 6.92 9.38\n",
            "From the results in Table 7, we observe that K-\n",
            "R[GPT-3.5] outperforms the standard prompting\n",
            "method of GPT-4 (Direct[GPT4]) from average per-\n",
            "--------------------------------------------------\n",
            "Chunk 124:\n",
            "formance. Furthermore, when competing against\n",
            "opponents using reasoning methods on GPT-4, K-\n",
            "R[GPT-3.5] demonstrates remarkable capabilities.\n",
            "K-R, with its excellent restoration of the rival’s\n",
            "perspective, enhances the LLM’s ability in compet-\n",
            "--------------------------------------------------\n",
            "Chunk 125:\n",
            "itive environments. Additionally, we compared the\n",
            "performance of the open-source model LLAMA2-\n",
            "7B with GPT-3.5/4 in Appendix E, finding that\n",
            "K-R significantly enhances reasoning in interactive\n",
            "contexts across different LLMs.\n",
            "--------------------------------------------------\n",
            "Chunk 126:\n",
            "5.4 The Deeper Thinking Level, the Better\n",
            "Strategic Performance?\n",
            "Table 8: Comparison between K-Level Reasoning[K=2]\n",
            "and K-Level Reasoning[K=3] in the two games.\n",
            "Guessing 0.8 of the Average Survival Auction Game\n",
            "--------------------------------------------------\n",
            "Chunk 127:\n",
            "OpponentDirect K-R[K=2] K-R[K=3] Direct K-R[K=2] K-R[K=3]\n",
            "Direct 0.43 0.82 0.77 (-0.05)5.90 9.40 9.40(+0.00)K-R[K=2]0.04 0.52 0.60(+0.08)4.10 6.80 8.30(+1.50)\n",
            "K-R models opponents’ thinking processes re-\n",
            "cursively. We examine how thinking level affect\n",
            "7\n",
            "--------------------------------------------------\n",
            "Chunk 128:\n",
            "reasoning outcomes by comparing K-R[K=2] and\n",
            "K-R[K=3] in two games. The results, detailed in Ta-\n",
            "ble 8, reveal the impact of increased thinking level.\n",
            "Against the Direct method (first-level thinking), K-\n",
            "R[K=3] showed a decreased win rate in G0.8A but\n",
            "--------------------------------------------------\n",
            "Chunk 129:\n",
            "maintained performance in SAG, suggesting pos-\n",
            "sible overthinking. However, K-R[K=3] improved\n",
            "significantly against K-R[K=2] in both games. It\n",
            "suggests that the key factor in K-R is the relative\n",
            "depth of thought compared to the opponent. A one-\n",
            "--------------------------------------------------\n",
            "Chunk 130:\n",
            "level deeper approach offers a strategic advantage,\n",
            "but advancing two levels may lead to diminishing\n",
            "returns due to over-anticipation. In interactive en-\n",
            "vironments, identifying opponents’ thinking levels\n",
            "--------------------------------------------------\n",
            "Chunk 131:\n",
            "is difficult. Adapting to varying levels and using K-\n",
            "Level Reasoning for deeper analysis is a valuable\n",
            "direction for future research.\n",
            "Additionally, a higher thinking level with the re-\n",
            "cursive prompting implementation increases com-\n",
            "--------------------------------------------------\n",
            "Chunk 132:\n",
            "putational cost. The computational cost of K-R is\n",
            "thoroughly discussed in Appendix G.\n",
            "6 Related Work\n",
            "6.1 Reasoning with LLMs\n",
            "Large Language Models (LLMs) excel in diverse\n",
            "complex reasoning tasks, such as mathematical\n",
            "--------------------------------------------------\n",
            "Chunk 133:\n",
            "(Miao et al., 2021; Patel et al., 2021), common\n",
            "sense (Talmor et al., 2022; Bhakthavatsalam et al.,\n",
            "2021), and symbolic reasoning (Srivastava et al.,\n",
            "2022; Suzgun et al., 2022). A notable reason-\n",
            "ing approach involves breaking down complex\n",
            "--------------------------------------------------\n",
            "Chunk 134:\n",
            "questions into a series of intermediate steps, a\n",
            "technique known as the Chain-of-Thought (CoT)\n",
            "method (Wei et al., 2022; Kojima et al., 2022).\n",
            "Subsequently, some works have emerged to ex-\n",
            "tend CoT, with innovations like Tree of Thought\n",
            "--------------------------------------------------\n",
            "Chunk 135:\n",
            "(ToT) (Yao et al., 2023), Graph of Thought (GoT)\n",
            "(Besta et al., 2023) and Skeleton-of-thought (Ning\n",
            "et al., 2023). Besides, approaches like Self-Refine\n",
            "(Madaan et al., 2023) and Reflexion (Shinn et al.,\n",
            "2023) enhance CoT’s consistency by having LLMs\n",
            "--------------------------------------------------\n",
            "Chunk 136:\n",
            "review and refine their responses. Moreover, recent\n",
            "research has revealed that integrating persona in-\n",
            "formation into LLMs significantly improves their\n",
            "reasoning processes (Deshpande et al., 2023). A\n",
            "series of studies (Fu et al., 2023; Wang et al., 2023)\n",
            "--------------------------------------------------\n",
            "Chunk 137:\n",
            "have been conducted to incorporate more persona\n",
            "information, aiming to enhance the rationality and\n",
            "knowledge ability of the LLM reasoning process.\n",
            "These methods have been applied to various static\n",
            "tasks, but have not been adequately evaluated in\n",
            "--------------------------------------------------\n",
            "Chunk 138:\n",
            "dynamic problems (multi-agent environment) to\n",
            "validate their efficacy in reasoning capabilities.\n",
            "6.2 Strategic Reasoning within Multiple\n",
            "Agent System\n",
            "Dynamic problems arise when multiple participants\n",
            "are involved in multi-round interactions. One key\n",
            "--------------------------------------------------\n",
            "Chunk 139:\n",
            "factor is the simultaneous interactions of multiple\n",
            "participants with the environment. Unlike single-\n",
            "agent systems, multiple agent system (MAS) en-\n",
            "counters a broader range of issues and challenges,\n",
            "as noted by (Wong et al., 2021), including compu-\n",
            "--------------------------------------------------\n",
            "Chunk 140:\n",
            "tational complexity (Ding and Dong, 2020), nonsta-\n",
            "tionarity (Papoudakis et al., 2019), partial observ-\n",
            "ability (Mahajan et al., 2019; Foerster et al., 2016),\n",
            "and challenges in credit assignment (Sunehag et al.,\n",
            "--------------------------------------------------\n",
            "Chunk 141:\n",
            "2017). Particularly, in the context of inference us-\n",
            "ing LLMs, the nonstationarity of the environment\n",
            "poses a distinct challenge.\n",
            "Recently, research on LLMs in strategic reason-\n",
            "ing has been conducted across various MAS includ-\n",
            "--------------------------------------------------\n",
            "Chunk 142:\n",
            "ing social behavior(Zhou et al., 2024; Hua et al.,\n",
            "2023), economic simulations(Zhao et al., 2023; Li\n",
            "et al., 2023), game theory(Duan et al., 2024; Xu\n",
            "et al., 2023a), and game playing(Ma et al., 2023;\n",
            "Xu et al., 2023b). To enhance the performance of\n",
            "--------------------------------------------------\n",
            "Chunk 143:\n",
            "LLMs in strategic reasoning scenarios, researchers\n",
            "have utilized the concepts of Theory of Mind (ToM)\n",
            "(Gandhi et al., 2023; Guo et al., 2023) and Re-\n",
            "inforcement Learning (Xu et al., 2023c; Zhang\n",
            "et al., 2024a) to optimize the reasoning processes of\n",
            "--------------------------------------------------\n",
            "Chunk 144:\n",
            "LLMs. These approaches involve prompting LLMs\n",
            "to recognize the intricacies of strategic tasks, like\n",
            "our proposed Prediction Chain-of-Thought base-\n",
            "line. However, our experimental results indicate\n",
            "that this approach fails to establish a clear cogni-\n",
            "--------------------------------------------------\n",
            "Chunk 145:\n",
            "tive hierarchy necessary for recursive and deeper\n",
            "strategic thinking.\n",
            "7 Conclusion\n",
            "This paper represents a significant stride in under-\n",
            "standing and enhancing the strategic reasoning ca-\n",
            "pabilities of LLMs. We propose “K-Level Rea-\n",
            "--------------------------------------------------\n",
            "Chunk 146:\n",
            "soning with LLMs.” This innovative approach\n",
            "leverages recursive mechanisms to achieve vary-\n",
            "ing thinking level within LLMs, enabling them\n",
            "to engage in deeper strategic thinking. Through\n",
            "extensive experiments, we validate the advantage\n",
            "--------------------------------------------------\n",
            "Chunk 147:\n",
            "offered by this method. It establishes a foundation\n",
            "for future research into theory of mind and strategic\n",
            "reasoning in LLMs.\n",
            "8\n",
            "--------------------------------------------------\n",
            "Chunk 148:\n",
            "8 Limitations\n",
            "We validate the effectiveness of the K-Level Rea-\n",
            "soning framework from two perspectives: game\n",
            "theory and social intelligence. While our exper-\n",
            "imental results provide substantial evidence sup-\n",
            "--------------------------------------------------\n",
            "Chunk 149:\n",
            "porting the framework’s validity, further research\n",
            "is necessary to explore the performance of large\n",
            "language models (LLMs) in few-shot agent model-\n",
            "ing (He et al., 2016) across various environments,\n",
            "strategic factors, and action sets.\n",
            "--------------------------------------------------\n",
            "Chunk 150:\n",
            "Additionally, K-R predicts opponents’ most\n",
            "likely behavior by initiating a new LLM inference\n",
            "session. The recursive mechanism employed to\n",
            "achieve varying levels of strategic depth inevitably\n",
            "increases computational cost. Appendix G pro-\n",
            "--------------------------------------------------\n",
            "Chunk 151:\n",
            "vides a detailed discussion on how K-R relates\n",
            "to this rise in computational cost and compares it\n",
            "across different reasoning methods. Despite the in-\n",
            "creased demands, K-R outperforms other methods\n",
            "with comparable computational costs.\n",
            "References\n",
            "--------------------------------------------------\n",
            "Chunk 152:\n",
            "Josh Achiam, Steven Adler, Sandhini Agarwal, Lama\n",
            "Ahmad, Ilge Akkaya, Florencia Leoni Aleman,\n",
            "Diogo Almeida, Janko Altenschmidt, Sam Altman,\n",
            "Shyamal Anadkat, et al. 2023. Gpt-4 technical report.\n",
            "arXiv preprint arXiv:2303.08774.\n",
            "--------------------------------------------------\n",
            "Chunk 153:\n",
            "Maciej Besta, Nils Blach, Ales Kubicek, Robert Ger-\n",
            "stenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz\n",
            "Lehmann, Michal Podstawski, Hubert Niewiadomski,\n",
            "Piotr Nyczyk, et al. 2023. Graph of thoughts: Solv-\n",
            "ing elaborate problems with large language models.\n",
            "--------------------------------------------------\n",
            "Chunk 154:\n",
            "arXiv preprint arXiv:2308.09687.\n",
            "Sumithra Bhakthavatsalam, Daniel Khashabi, Tushar\n",
            "Khot, Bhavana Dalvi Mishra, Kyle Richardson,\n",
            "Ashish Sabharwal, Carissa Schoenick, Oyvind\n",
            "Tafjord, and Peter Clark. 2021. Think you have\n",
            "--------------------------------------------------\n",
            "Chunk 155:\n",
            "solved direct-answer question answering? try arc-\n",
            "da, the direct-answer ai2 reasoning challenge. arXiv\n",
            "preprint arXiv:2102.03315.\n",
            "Antoni Bosch-Domenech, Jose G Montalvo, Rosemarie\n",
            "Nagel, and Albert Satorra. 2002. One, two,(three),\n",
            "--------------------------------------------------\n",
            "Chunk 156:\n",
            "infinity,. . . : Newspaper and lab beauty-contest ex-\n",
            "periments. American Economic Review, 92(5):1687–\n",
            "1701.\n",
            "Kris Cao, Angeliki Lazaridou, Marc Lanctot, Joel Z\n",
            "Leibo, Karl Tuyls, and Stephen Clark. 2018. Emer-\n",
            "gent communication through negotiation. arXiv\n",
            "--------------------------------------------------\n",
            "Chunk 157:\n",
            "preprint arXiv:1804.03980.\n",
            "Brandon Cui, Hengyuan Hu, Luis Pineda, and Jakob\n",
            "Foerster. 2021. K-level reasoning for zero-shot coor-\n",
            "dination in hanabi. Advances in Neural Information\n",
            "Processing Systems, 34:8215–8228.\n",
            "--------------------------------------------------\n",
            "Chunk 158:\n",
            "Ameet Deshpande, Vishvak Murahari, Tanmay Rajpuro-\n",
            "hit, Ashwin Kalyan, and Karthik Narasimhan. 2023.\n",
            "Toxicity in chatgpt: Analyzing persona-assigned lan-\n",
            "guage models. arXiv preprint arXiv:2304.05335.\n",
            "Zihan Ding and Hao Dong. 2020. Challenges of rein-\n",
            "--------------------------------------------------\n",
            "Chunk 159:\n",
            "forcement learning. Deep Reinforcement Learning:\n",
            "Fundamentals, Research and Applications , pages\n",
            "249–272.\n",
            "Jinhao Duan, Renming Zhang, James Diffenderfer,\n",
            "Bhavya Kailkhura, Lichao Sun, Elias Stengel-Eskin,\n",
            "Mohit Bansal, Tianlong Chen, and Kaidi Xu. 2024.\n",
            "--------------------------------------------------\n",
            "Chunk 160:\n",
            "Gtbench: Uncovering the strategic reasoning limita-\n",
            "tions of llms via game-theoretic evaluations. arXiv\n",
            "preprint arXiv:2402.12348.\n",
            "Jakob Foerster, Ioannis Alexandros Assael, Nando\n",
            "De Freitas, and Shimon Whiteson. 2016. Learning\n",
            "--------------------------------------------------\n",
            "Chunk 161:\n",
            "to communicate with deep multi-agent reinforcement\n",
            "learning. Advances in neural information processing\n",
            "systems, 29.\n",
            "Yao Fu, Hao Peng, Tushar Khot, and Mirella Lapata.\n",
            "2023. Improving language model negotiation with\n",
            "--------------------------------------------------\n",
            "Chunk 162:\n",
            "self-play and in-context learning from ai feedback.\n",
            "arXiv preprint arXiv:2305.10142.\n",
            "Kanishk Gandhi, Dorsa Sadigh, and Noah D Goodman.\n",
            "2023. Strategic reasoning with language models.\n",
            "arXiv preprint arXiv:2305.19165.\n",
            "--------------------------------------------------\n",
            "Chunk 163:\n",
            "Jiaxian Guo, Bo Yang, Paul Yoo, Bill Yuchen\n",
            "Lin, Yusuke Iwasawa, and Yutaka Matsuo. 2023.\n",
            "Suspicion-agent: Playing imperfect information\n",
            "games with theory of mind aware gpt-4. arXiv\n",
            "preprint arXiv:2309.17277.\n",
            "He He, Jordan Boyd-Graber, Kevin Kwok, and Hal\n",
            "--------------------------------------------------\n",
            "Chunk 164:\n",
            "Daumé III. 2016. Opponent modeling in deep rein-\n",
            "forcement learning. In International conference on\n",
            "machine learning, pages 1804–1813. PMLR.\n",
            "Wenyue Hua, Lizhou Fan, Lingyao Li, Kai Mei,\n",
            "Jianchao Ji, Yingqiang Ge, Libby Hemphill, and\n",
            "--------------------------------------------------\n",
            "Chunk 165:\n",
            "Yongfeng Zhang. 2023. War and peace (waragent):\n",
            "Large language model-based multi-agent simulation\n",
            "of world wars. arXiv preprint arXiv:2311.17227.\n",
            "John Maynard Keynes. 1936. The general theory of\n",
            "employment. The quarterly journal of economics ,\n",
            "--------------------------------------------------\n",
            "Chunk 166:\n",
            "51(2):209–223.\n",
            "Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\n",
            "taka Matsuo, and Yusuke Iwasawa. 2022. Large lan-\n",
            "guage models are zero-shot reasoners. Advances in\n",
            "neural information processing systems , 35:22199–\n",
            "22213.\n",
            "--------------------------------------------------\n",
            "Chunk 167:\n",
            "Alain Ledoux. 1981. Concours résultats complets. Les\n",
            "victimes se sont plu à jouer le, 14:10–11.\n",
            "Nian Li, Chen Gao, Mingyu Li, Yong Li, and Qing-\n",
            "min Liao. 2024. EconAgent: Large language model-\n",
            "empowered agents for simulating macroeconomic ac-\n",
            "--------------------------------------------------\n",
            "Chunk 168:\n",
            "tivities. In Proceedings of the 62nd Annual Meeting\n",
            "9\n",
            "--------------------------------------------------\n",
            "Chunk 169:\n",
            "of the Association for Computational Linguistics (Vol-\n",
            "ume 1: Long Papers), pages 15523–15536, Bangkok,\n",
            "Thailand. Association for Computational Linguistics.\n",
            "Yang Li, Yangyang Yu, Haohang Li, Zhi Chen, and\n",
            "Khaldoun Khashanah. 2023. Tradinggpt: Multi-\n",
            "--------------------------------------------------\n",
            "Chunk 170:\n",
            "agent system with layered memory and distinct char-\n",
            "acters for enhanced financial trading performance.\n",
            "arXiv preprint arXiv:2309.03736.\n",
            "Weiyu Ma, Qirui Mi, Xue Yan, Yuqiao Wu, Runji Lin,\n",
            "Haifeng Zhang, and Jun Wang. 2023. Large lan-\n",
            "--------------------------------------------------\n",
            "Chunk 171:\n",
            "guage models play starcraft ii: Benchmarks and a\n",
            "chain of summarization approach. arXiv preprint\n",
            "arXiv:2312.11865.\n",
            "Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler\n",
            "Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon,\n",
            "--------------------------------------------------\n",
            "Chunk 172:\n",
            "Nouha Dziri, Shrimai Prabhumoye, Yiming Yang,\n",
            "et al. 2023. Self-refine: Iterative refinement with\n",
            "self-feedback. arXiv preprint arXiv:2303.17651.\n",
            "Anuj Mahajan, Tabish Rashid, Mikayel Samvelyan, and\n",
            "Shimon Whiteson. 2019. Maven: Multi-agent varia-\n",
            "--------------------------------------------------\n",
            "Chunk 173:\n",
            "tional exploration. Advances in neural information\n",
            "processing systems, 32.\n",
            "Shaoguang Mao, Yuzhe Cai, Yan Xia, Wenshan Wu,\n",
            "Xun Wang, Fengyi Wang, Tao Ge, and Furu Wei.\n",
            "2023. Alympics: Language agents meet game theory.\n",
            "arXiv preprint arXiv:2311.03220.\n",
            "--------------------------------------------------\n",
            "Chunk 174:\n",
            "Shen-Yun Miao, Chao-Chun Liang, and Keh-Yih Su.\n",
            "2021. A diverse corpus for evaluating and developing\n",
            "english math word problem solvers. arXiv preprint\n",
            "arXiv:2106.15772.\n",
            "Rosemarie Nagel. 1995. Unraveling in guessing games:\n",
            "--------------------------------------------------\n",
            "Chunk 175:\n",
            "An experimental study. The American economic re-\n",
            "view, 85(5):1313–1326.\n",
            "Xuefei Ning, Zinan Lin, Zixuan Zhou, Huazhong Yang,\n",
            "and Yu Wang. 2023. Skeleton-of-thought: Large\n",
            "language models can do parallel decoding. arXiv\n",
            "preprint arXiv:2307.15337.\n",
            "--------------------------------------------------\n",
            "Chunk 176:\n",
            "Georgios Papoudakis, Filippos Christianos, Arrasy Rah-\n",
            "man, and Stefano V Albrecht. 2019. Dealing with\n",
            "non-stationarity in multi-agent deep reinforcement\n",
            "learning. arXiv preprint arXiv:1906.04737.\n",
            "Arkil Patel, Satwik Bhattamishra, and Navin Goyal.\n",
            "--------------------------------------------------\n",
            "Chunk 177:\n",
            "2021. Are nlp models really able to solve\n",
            "simple math word problems? arXiv preprint\n",
            "arXiv:2103.07191.\n",
            "Noah Shinn, Federico Cassano, Ashwin Gopinath,\n",
            "Karthik R Narasimhan, and Shunyu Yao. 2023. Re-\n",
            "flexion: Language agents with verbal reinforcement\n",
            "--------------------------------------------------\n",
            "Chunk 178:\n",
            "learning. In Thirty-seventh Conference on Neural\n",
            "Information Processing Systems.\n",
            "Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao,\n",
            "Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch,\n",
            "Adam R Brown, Adam Santoro, Aditya Gupta,\n",
            "--------------------------------------------------\n",
            "Chunk 179:\n",
            "Adrià Garriga-Alonso, et al. 2022. Beyond the\n",
            "imitation game: Quantifying and extrapolating the\n",
            "capabilities of language models. arXiv preprint\n",
            "arXiv:2206.04615.\n",
            "Dale O Stahl and Paul W Wilson. 1995. On players’\n",
            "--------------------------------------------------\n",
            "Chunk 180:\n",
            "models of other players: Theory and experimental ev-\n",
            "idence. Games and Economic Behavior, 10(1):218–\n",
            "254.\n",
            "Peter Sunehag, Guy Lever, Audrunas Gruslys, Woj-\n",
            "ciech Marian Czarnecki, Vinicius Zambaldi, Max\n",
            "Jaderberg, Marc Lanctot, Nicolas Sonnerat, Joel Z\n",
            "--------------------------------------------------\n",
            "Chunk 181:\n",
            "Leibo, Karl Tuyls, et al. 2017. Value-decomposition\n",
            "networks for cooperative multi-agent learning. arXiv\n",
            "preprint arXiv:1706.05296.\n",
            "Mirac Suzgun, Nathan Scales, Nathanael Schärli, Se-\n",
            "bastian Gehrmann, Yi Tay, Hyung Won Chung,\n",
            "--------------------------------------------------\n",
            "Chunk 182:\n",
            "Aakanksha Chowdhery, Quoc V Le, Ed H Chi, Denny\n",
            "Zhou, et al. 2022. Challenging big-bench tasks and\n",
            "whether chain-of-thought can solve them. arXiv\n",
            "preprint arXiv:2210.09261.\n",
            "Alon Talmor, Ori Yoran, Ronan Le Bras, Chandra Bha-\n",
            "--------------------------------------------------\n",
            "Chunk 183:\n",
            "gavatula, Yoav Goldberg, Yejin Choi, and Jonathan\n",
            "Berant. 2022. Commonsenseqa 2.0: Exposing the\n",
            "limits of ai through gamification. arXiv preprint\n",
            "arXiv:2201.05320.\n",
            "Zhenhailong Wang, Shaoguang Mao, Wenshan Wu,\n",
            "Tao Ge, Furu Wei, and Heng Ji. 2023. Unleash-\n",
            "--------------------------------------------------\n",
            "Chunk 184:\n",
            "ing cognitive synergy in large language models:\n",
            "A task-solving agent through multi-persona self-\n",
            "collaboration. arXiv preprint arXiv:2307.05300.\n",
            "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\n",
            "Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,\n",
            "--------------------------------------------------\n",
            "Chunk 185:\n",
            "et al. 2022. Chain-of-thought prompting elicits rea-\n",
            "soning in large language models. Advances in Neural\n",
            "Information Processing Systems, 35:24824–24837.\n",
            "Annie Wong, Thomas Bäck, Anna V Kononova, and\n",
            "Aske Plaat. 2021. Deep multiagent reinforcement\n",
            "--------------------------------------------------\n",
            "Chunk 186:\n",
            "learning: Challenges and directions. arXiv preprint\n",
            "arXiv:2106.15691.\n",
            "Sang Michael Xie, Aditi Raghunathan, Percy Liang, and\n",
            "Tengyu Ma. 2021. An explanation of in-context learn-\n",
            "ing as implicit bayesian inference. arXiv preprint\n",
            "arXiv:2111.02080.\n",
            "--------------------------------------------------\n",
            "Chunk 187:\n",
            "Lin Xu, Zhiyuan Hu, Daquan Zhou, Hongyu Ren, Zhen\n",
            "Dong, Kurt Keutzer, See-Kiong Ng, and Jiashi Feng.\n",
            "2023a. Magic: Investigation of large language model\n",
            "powered multi-agent in cognition, adaptability, ratio-\n",
            "--------------------------------------------------\n",
            "Chunk 188:\n",
            "nality and collaboration. In ICLR 2024 Workshop on\n",
            "Large Language Model (LLM) Agents.\n",
            "Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xi-\n",
            "aolong Wang, Weidong Liu, and Yang Liu. 2023b.\n",
            "Exploring large language models for communica-\n",
            "--------------------------------------------------\n",
            "Chunk 189:\n",
            "tion games: An empirical study on werewolf. arXiv\n",
            "preprint arXiv:2309.04658.\n",
            "10\n",
            "--------------------------------------------------\n",
            "Chunk 190:\n",
            "Zelai Xu, Chao Yu, Fei Fang, Yu Wang, and Yi Wu.\n",
            "2023c. Language agents with reinforcement learn-\n",
            "ing for strategic play in the werewolf game. arXiv\n",
            "preprint arXiv:2310.18940.\n",
            "Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran,\n",
            "--------------------------------------------------\n",
            "Chunk 191:\n",
            "Thomas L Griffiths, Yuan Cao, and Karthik\n",
            "Narasimhan. 2023. Tree of thoughts: Deliberate\n",
            "problem solving with large language models. arXiv\n",
            "preprint arXiv:2305.10601.\n",
            "Wenqi Zhang, Ke Tang, Hai Wu, Mengna Wang,\n",
            "--------------------------------------------------\n",
            "Chunk 192:\n",
            "Yongliang Shen, Guiyang Hou, Zeqi Tan, Peng Li,\n",
            "Yueting Zhuang, and Weiming Lu. 2024a. Agent-\n",
            "pro: Learning to evolve via policy-level reflection\n",
            "and optimization. arXiv preprint arXiv:2402.17574.\n",
            "Yadong Zhang, Shaoguang Mao, Tao Ge, Xun Wang,\n",
            "--------------------------------------------------\n",
            "Chunk 193:\n",
            "Yan Xia, Wenshan Wu, Ting Song, Man Lan, and\n",
            "Furu Wei. 2024b. LLM as a mastermind: A survey\n",
            "of strategic reasoning with large language models. In\n",
            "First Conference on Language Modeling.\n",
            "Qinlin Zhao, Jindong Wang, Yixuan Zhang, Yiqiao Jin,\n",
            "--------------------------------------------------\n",
            "Chunk 194:\n",
            "Kaijie Zhu, Hao Chen, and Xing Xie. 2023. Com-\n",
            "peteai: Understanding the competition behaviors in\n",
            "large language model-based agents. arXiv preprint\n",
            "arXiv:2310.17512.\n",
            "Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang,\n",
            "--------------------------------------------------\n",
            "Chunk 195:\n",
            "Haofei Yu, Zhengyang Qi, Louis-Philippe Morency,\n",
            "Yonatan Bisk, Daniel Fried, Graham Neubig, and\n",
            "Maarten Sap. 2024. SOTOPIA: Interactive evalua-\n",
            "tion for social intelligence in language agents. In\n",
            "The Twelfth International Conference on Learning\n",
            "--------------------------------------------------\n",
            "Chunk 196:\n",
            "Representations.\n",
            "11\n",
            "--------------------------------------------------\n",
            "Chunk 197:\n",
            "A Impact Statements\n",
            "Our research introduces the K-Level Reasoning\n",
            "framework, designed to formulate strategies in dy-\n",
            "namic, interactive and competitive scenarios by\n",
            "anticipating the reactions of adversaries, poten-\n",
            "--------------------------------------------------\n",
            "Chunk 198:\n",
            "tially users. Theoretically, this approach offers a\n",
            "novel perspective for understanding and optimizing\n",
            "decision-making processes. However, we recog-\n",
            "nize when the goal setting diverges from user inter-\n",
            "ests, the application of K-Level Reasoning could\n",
            "--------------------------------------------------\n",
            "Chunk 199:\n",
            "result in manipulative behaviors by adapting to the\n",
            "predicted user’s reactions. This risk is notably pro-\n",
            "nounced in scenarios designed to influence user\n",
            "decisions or behaviors, such as in recommenda-\n",
            "tion systems, advertising placements, and content\n",
            "--------------------------------------------------\n",
            "Chunk 200:\n",
            "distribution on social media platforms.\n",
            "Although K-Level Reasoning provides a potent\n",
            "powerful tool for strategic planning, interacting and\n",
            "reasoning, ethical considerations must be meticu-\n",
            "lously managed in its practical application. This\n",
            "--------------------------------------------------\n",
            "Chunk 201:\n",
            "ensures that the development and utilization of tech-\n",
            "nology do not detrimentally impact user and soci-\n",
            "etal interests. To this end, we advocate for height-\n",
            "ened transparency, ensuring users have a compre-\n",
            "hensive understanding and control over how their\n",
            "--------------------------------------------------\n",
            "Chunk 202:\n",
            "data is utilized.\n",
            "B Game Setting\n",
            "B.1 Guessing 0.8 of the Average\n",
            "Initial Setup: For each round, each player select\n",
            "a number between 1 and 100. The objective is to\n",
            "select a number that is closest to 80% of the group’s\n",
            "--------------------------------------------------\n",
            "Chunk 203:\n",
            "average choice. Formally, each player i chooses a\n",
            "number ni, aiming for ni ≈ 0.8 × n, where n is\n",
            "the average of all chosen numbers.\n",
            "Scoring and Continuation: A player scores a\n",
            "point if his/her chosen number is closest to 80%\n",
            "--------------------------------------------------\n",
            "Chunk 204:\n",
            "of the average number chosen by the group. If\n",
            "all players select the same number, no points are\n",
            "awarded for this round. Mathematically, the score\n",
            "for player i in in round t is given by st\n",
            "i, which is 1\n",
            "if |ni −0.8 ×n| is the minimum among all players,\n",
            "--------------------------------------------------\n",
            "Chunk 205:\n",
            "and 0 otherwise.\n",
            "B.2 Survival Auction Game\n",
            "Initial Setup: Players start with 8 health points,\n",
            "out of a maximum of 10. Every day, each player\n",
            "possesses a fixed income of $100. The daily water\n",
            "supply can only satisfy one resident’s requirement.\n",
            "--------------------------------------------------\n",
            "Chunk 206:\n",
            "Scoring and Continuation: Everyday, players\n",
            "engage in a daily auction to secure the necessary\n",
            "water resources, and the highest bidder wins. In\n",
            "case of a tie, the resources are not allocated to\n",
            "any player. If a player successfully bid the water\n",
            "--------------------------------------------------\n",
            "Chunk 207:\n",
            "resources, they will gain 2 health points; otherwise,\n",
            "they will lose health points equal to the number\n",
            "of consecutive days, denoted as n, during which\n",
            "they have not obtained water resources. Once a\n",
            "player’s health points fall to 0 or below, they will\n",
            "--------------------------------------------------\n",
            "Chunk 208:\n",
            "be eliminated. The health point of player i on day\n",
            "t, denoted as ht\n",
            "i, is crucial in determining their\n",
            "survival and bidding strategy.\n",
            "C Detailed Metric Computational\n",
            "Formulas\n",
            "Win Rate is calculated based on the number of\n",
            "--------------------------------------------------\n",
            "Chunk 209:\n",
            "wins over game going, providing a measure of the\n",
            "overall ability.\n",
            "WinRate = Num of Wins\n",
            "Total Round per Test× Num of Test(9)\n",
            "Average Survival Roundcalculates the average\n",
            "round in which the player remains in the game.\n",
            "--------------------------------------------------\n",
            "Chunk 210:\n",
            "It’s an effective way to assess performance in\n",
            "elimination-based game, like SAG.\n",
            "AvgSurvivalRound =\n",
            "PSurvival Round in Each Test\n",
            "Num of Test (10)\n",
            "Prediction Accuracy evaluates the accuracy of\n",
            "player’s predictions regarding rivals’ future moves.\n",
            "--------------------------------------------------\n",
            "Chunk 211:\n",
            "In the G0.8A, it involves calculating the absolute\n",
            "difference between the player’s predicted average\n",
            "and the actual average in each round:\n",
            "Pred Acc =\n",
            "P|AvgP red− AvgActual|\n",
            "Num of Test (11)\n",
            "In the SAG, the focus shifts to measuring the ab-\n",
            "--------------------------------------------------\n",
            "Chunk 212:\n",
            "solute error between the player’s prediction of the\n",
            "highest bid by opponents and the actual highest bid\n",
            "made by them.\n",
            "Pred Acc =\n",
            "P|Max BidP red− Max BidActual|\n",
            "Num of Test (12)\n",
            "Strategic Level\n",
            "StrategicDepth(choice) = logα(choice/50)\n",
            "(13)\n",
            "--------------------------------------------------\n",
            "Chunk 213:\n",
            "Here, α represents the target value coefficient, and\n",
            "50 represents the average of a random choice be-\n",
            "tween 0 and 100, which is used to represent level-0\n",
            "players. In the settings of [1][2], the parameter α is\n",
            "set to 2\n",
            "--------------------------------------------------\n",
            "Chunk 214:\n",
            "3 . In our configuration, α is set to 0.8, which\n",
            "is the origin of the name G0.8A.\n",
            "12\n",
            "--------------------------------------------------\n",
            "Chunk 215:\n",
            "Introduction Prompt:\n",
            "You are Alex and involved in a survive challenge. You are one of five players in the game. Everyone is required to choose an integer\n",
            "--------------------------------------------------\n",
            "Chunk 216:\n",
            "between 1 and 100 in each round. The player whose chosen number is closest to (0.8 * the average of all chosen numbers) wins the\n",
            "--------------------------------------------------\n",
            "Chunk 217:\n",
            "round without any HP deduction. All other players will have 1 HP deducted. But if all players choose the same number, their h ealth \n",
            "points are deducted together.\n",
            "Round Start Prompt (Standard):\n",
            "--------------------------------------------------\n",
            "Chunk 218:\n",
            "Ok, Alex! Now is the ROUND 1, and your HP is at 10. Please choose an integer between 1 and 100 for this round.”\n",
            "Notification Result Prompt :\n",
            "--------------------------------------------------\n",
            "Chunk 219:\n",
            "Thank you all for participating in Round 1. In this round, Alex chose 45, Bob chose 45, Cindy chose 50, David chose 45, Eric chose 45.\n",
            "The average is (45 + 45 + 50 + 45 + 45) / 5 = 46.0.  The average 46.0 multiplied by 0.8 equals 36.8.\n",
            "--------------------------------------------------\n",
            "Chunk 220:\n",
            "Alex: |45 - 36.8| = 8, Bob: |45 - 36.8| = 8, Cindy: |50 - 36.8| = 13, David: |45 - 36.8| = 8, Eric: |45 - 36.8| = 8\n",
            "[Alex, Bob, David, Eric]'s choice of 45 is closest to 36.8.\n",
            "--------------------------------------------------\n",
            "Chunk 221:\n",
            "Round winner: Alex, Bob, David, Eric. All other players lose 1 point. After the deduction, player information is: \n",
            "name: Alex  HP: 10, name: Bob HP: 10, name: Cindy HP: 9, name: David HP: 10, name: Eric  HP: 10.\n",
            "Congratulation Prompt (When Win):\n",
            "--------------------------------------------------\n",
            "Chunk 222:\n",
            "You have successfully chosen the number closest to the target number, which is the average of all players' selected numbers \n",
            "multiplied by 0.8. As a result, you have won this round. All other players will now deduct 1 HP. \n",
            "Warning Prompt (When Loss):\n",
            "--------------------------------------------------\n",
            "Chunk 223:\n",
            "WARNING: You have lost 1 point of HP in this round! You now have only 9 points of health left. You are one step closer to dea th.\n",
            "G0.8A Game Prompt\n",
            "Figure 4: Prompts used in Guessing 0.8 of the Average game.\n",
            "Introduction Prompt:\n",
            "--------------------------------------------------\n",
            "Chunk 224:\n",
            "You are Alex and a resident living in W-Town. W Town is experiencing a rare drought. Every residents in Town W is ensuring their survival \n",
            "over a period of 10 days by acquiring the water resources.\n",
            "--------------------------------------------------\n",
            "Chunk 225:\n",
            "Attention, all W-Town residents, welcome to the Water Allocation Challenge!\n",
            "In this challenge, you are tasked with ensuring your survival over a period of 10 days by acquiring the necessary water resources to maintain\n",
            "--------------------------------------------------\n",
            "Chunk 226:\n",
            "your health. You will participate in daily auctions to bid for water resources to meet your individual needs.\n",
            "Here are the game rules and settings:\n",
            "1. You are one of five residents with same water requirements, budgets, and health points.\n",
            "--------------------------------------------------\n",
            "Chunk 227:\n",
            "2. Your goal is to survive until the end of the 10 days.\n",
            "3. Each resident has a maximum of 10 health points and starts with 8 health points. If your health points drop below or equal to 0, you will\n",
            "--------------------------------------------------\n",
            "Chunk 228:\n",
            "be considered dead and eliminated from the game! All your accumulated money will be reset to Zero! \n",
            "4. Every day, you will bid on water resources to meet your needs. If your consecutive days without obtaining water resource (No-Drink Days)\n",
            "--------------------------------------------------\n",
            "Chunk 229:\n",
            "reach n, your health will be deducted by n points on that day. If your water needs are met, 2 points will be added to your health, and the \n",
            "No-Drink Days will be reset to 0.\n",
            "5. Daily water resources can only meet the needs of one resident.\n",
            "--------------------------------------------------\n",
            "Chunk 230:\n",
            "6. Each resident has $100 daily income;\n",
            "7. To allocate water resources, a sealed-bid auction will be conducted daily. Each resident submits a single bid for their entire water need. \n",
            "The resident with the highest bid is eligible to obtain water resources.\n",
            "--------------------------------------------------\n",
            "Chunk 231:\n",
            "8. If the highest bid results in a tie, no residents will have access to water . \n",
            "All bidding information will be made public after the allocation of water resources on the same day.\n",
            "--------------------------------------------------\n",
            "Chunk 232:\n",
            "Remember , the key to success is effective bidding and strategizing to ensure your survival. Good luck!!\n",
            "Round Start Prompt (Standard):\n",
            "Hello, Alex! Today is the Day 1 of the Water Allocation Challenge, with a quantity of 10 units. Your status:\n",
            "--------------------------------------------------\n",
            "Chunk 233:\n",
            "name: Alex  balance:100  HP:8  no_drink : 1  \n",
            "Please carefully analyze your situation to decide on this round of bidding. Remember , the most important thing is to SURVIVE! ! Now, if you\n",
            "--------------------------------------------------\n",
            "Chunk 234:\n",
            "want to participate in today's water resource auction, please provide your bid.\n",
            "Notification Result Prompt :\n",
            "Thank you all for participating in Round 1. In this round, Alex bid 25, Bob bid 40, Cindy bid 40, David bid 30, Eric bid 60.\n",
            "--------------------------------------------------\n",
            "Chunk 235:\n",
            "Total water resource supply is 10. According to the principle of the highest bidder and the rule when the game is tied, Eric won this auction \n",
            "and obtain water resource. \n",
            "After allocation, all survival residents' information is as follows:\n",
            "--------------------------------------------------\n",
            "Chunk 236:\n",
            "name: Alex balance: 100  HP:7 no_drink : 2,   name: Bob  balance: 100  HP:7 no_drink:2 \n",
            "name :Cindy  balance:100 HP:7 no_drink:2,   name: David  balance: 100 HP: :7 no_drink:2\n",
            "name:Eric balance:40  HP:10 no_drink:1\n",
            "Congratulation Prompt (When Win):\n",
            "--------------------------------------------------\n",
            "Chunk 237:\n",
            "You have successfully won the bidding for today's water resources and restored 2 points of HP .\n",
            "Warning Prompt (When Lose):\n",
            "WARNING: You have lost 1point of HP in this round! You now have only 7 points of health left. You are one step closer to death.\n",
            "--------------------------------------------------\n",
            "Chunk 238:\n",
            "Survival Auction Game Prompt\n",
            "Bidding Result Parse Prompt:\n",
            "By reading the conversation, extract the number chosen by player . Output format: number . If the player does not bid, Output: 0.\n",
            "Figure 5: Prompts used in Survival Auction Game.\n",
            "13\n",
            "--------------------------------------------------\n",
            "Chunk 239:\n",
            "D Performance of Large Language\n",
            "Models Competing with Programmatic\n",
            "Strategies\n",
            "In addition to using the LLM-LLM Combat com-\n",
            "parison setting in Section 4, we have also designed\n",
            "a set of LLM-Programmatic Strategy Combat\n",
            "--------------------------------------------------\n",
            "Chunk 240:\n",
            "comparisons. In Player-Programmatic Strategy\n",
            "Combat setting, the “player\" will be equipped with\n",
            "a specific reasoning method, while opponents will\n",
            "play according to programmatic strategic patterns,\n",
            "which will not be adjusted with the game going.\n",
            "--------------------------------------------------\n",
            "Chunk 241:\n",
            "This mode is to check different methods’ adapta-\n",
            "tion to different predefined but fixed patterns. For\n",
            "the Player-Programmatic Player Combat Combat\n",
            "in G0.8A, the programmatic strategies include:\n",
            "1) 0-Level (Fix): The characteristic of a 0-Level\n",
            "--------------------------------------------------\n",
            "Chunk 242:\n",
            "player is that their choice of strategy is uniform\n",
            "(Stahl and Wilson, 1995). We limit the choice space\n",
            "of the 0-Level Computer player to only 40.\n",
            "2) 0-Level (Var): Modified from the 0-Level\n",
            "(Fix) strategy, the selection is sampled from a Gaus-\n",
            "--------------------------------------------------\n",
            "Chunk 243:\n",
            "sian distribution with a mean of 40 and a variance\n",
            "of 5.\n",
            "3) MonoTrend (Fix): The numbers chosen by\n",
            "the computer players follow an arithmetic sequence\n",
            "with a decreasing common difference, and the com-\n",
            "mon differences for all four computer players are\n",
            "--------------------------------------------------\n",
            "Chunk 244:\n",
            "the same.\n",
            "4) MonoTrend (Var): The numbers chosen by\n",
            "the computer players follow an arithmetic sequence\n",
            "with a decreasing common difference, and the com-\n",
            "mon differences for the four computer players are\n",
            "randomly generated from 1 to 5.\n",
            "--------------------------------------------------\n",
            "Chunk 245:\n",
            "5) LastBids (Fix): The computer player chooses\n",
            "the target number from the previous round (selects\n",
            "40 in the first round).\n",
            "6) LastBids (Var): Modified from the LastBids\n",
            "strategy, the selection is sampled from a Gaussian\n",
            "--------------------------------------------------\n",
            "Chunk 246:\n",
            "distribution with a mean equal to the target number\n",
            "of the previous round and a variance of 5.\n",
            "Overall, the dynamic changes of these three set-\n",
            "tings are LastBids > MonoTrend > 0-Level. We\n",
            "use these three programs to test the reasoning capa-\n",
            "--------------------------------------------------\n",
            "Chunk 247:\n",
            "bility to adapt to and counter different patterns.\n",
            "Table 9 reveals a significant trend in the perfor-\n",
            "mance of players against other approaches. The\n",
            "effectiveness of reasoning approaches decreases\n",
            "in the following order: 0-Level, MonoTrend, and\n",
            "--------------------------------------------------\n",
            "Chunk 248:\n",
            "LastBids. This pattern highlights a reduction in the\n",
            "efficacy of the LLM in more dynamic environments.\n",
            "We found that only K-Level Reasoning shows an\n",
            "advantage in LastBids (Fix), indicating that com-\n",
            "pared to K-Level Reasoning, previous reasoning\n",
            "--------------------------------------------------\n",
            "Chunk 249:\n",
            "methods on static problems lack observation and\n",
            "judgment of the opponent. Conversely, this also\n",
            "demonstrates that K-Level Reasoning can implic-\n",
            "itly infer the behavior pattern of the opponent based\n",
            "on their historical actions.\n",
            "--------------------------------------------------\n",
            "Chunk 250:\n",
            "Intriguingly, reasoning methods significantly in-\n",
            "fluence the performance in dynamic settings. Meth-\n",
            "ods like CoT and Self-Refine, traditionally favored\n",
            "in static reasoning, also demonstrate substantial\n",
            "improvements over the Standard Prompt approach.\n",
            "--------------------------------------------------\n",
            "Chunk 251:\n",
            "This finding underscores the necessity for more\n",
            "elaborate reasoning processes in dynamic decision-\n",
            "making, akin to static problem-solving scenarios.\n",
            "Table 9: Win Rate of the player against different pro-\n",
            "grammatic strategies in Guessing 0.8 of the Average\n",
            "--------------------------------------------------\n",
            "Chunk 252:\n",
            "game.\n",
            "Opponent Direct CoT Persona Reflect Refine PCoT K-R\n",
            "Player VS Programmatic Strategies\n",
            "0-Level (Fix) 0.65 0.87 0.87 0.81 0.99 0.800.97\n",
            "0-Level (Var)0.44 0.67 0.69 0.61 0.54 0.760.77\n",
            "MonoTrend (Fix)0.05 0.06 0.15 0.00 0.29 0.150.48\n",
            "--------------------------------------------------\n",
            "Chunk 253:\n",
            "MonoTrend (Var)0.34 0.44 0.57 0.33 0.49 0.460.74\n",
            "LastBids (Fix)0.01 0.12 0.16 0.01 0.27 0.060.75\n",
            "LastBids (Var)0.06 0.15 0.18 0.19 0.18 0.140.18\n",
            "E Open Source LLM with K-Level\n",
            "Reasoning\n",
            "In addition to the experiments on GPT3.5 /GPT4,\n",
            "--------------------------------------------------\n",
            "Chunk 254:\n",
            "we conducted tests with an open-source smaller-\n",
            "scale model, LLaMA-7B-Chat, in the \"G0.8A\"\n",
            "game. To clearly compare the performance of dif-\n",
            "ferent LLMs, we adopted the LLM-Programmatic\n",
            "Strategy Combat setting described in Appendix B.\n",
            "--------------------------------------------------\n",
            "Chunk 255:\n",
            "From the experimental results, we can see that:\n",
            "1. Llama2-7B and GPT3.5, even including GPT4,\n",
            "perform poorly when competing against program-\n",
            "matic strategies using standard prompting, strug-\n",
            "gling even with some very simple strategies. It\n",
            "--------------------------------------------------\n",
            "Chunk 256:\n",
            "underscores the significance of our research; 2. For\n",
            "all tested models, applying k-level reasoning effec-\n",
            "tively enhanced the win rate, highlighting the stabil-\n",
            "ity of the improvement our proposed model brings\n",
            "--------------------------------------------------\n",
            "Chunk 257:\n",
            "to different base models. Interestingly, for stronger\n",
            "LLMs, applying K-R can achieve a higher relative\n",
            "improvement, we speculate that the enhancement is\n",
            "simultaneously derived from the opponent’s action\n",
            "simulation and reasoning capabilities of the base\n",
            "--------------------------------------------------\n",
            "Chunk 258:\n",
            "model.\n",
            "14\n",
            "--------------------------------------------------\n",
            "Chunk 259:\n",
            "Table 10: Win Rate of the reasoning methods with open\n",
            "source LLMs against different programmatic strategies\n",
            "in Guessing 0.8 of the Average game.\n",
            "Methods Direct K-R[K=2] Direct K-R[K=2] Direct K-R[K=2]\n",
            "--------------------------------------------------\n",
            "Chunk 260:\n",
            "Base Model [LLaMA-7B] [LLaMA-7B] [GPT3.5] [GPT3.5] [GPT4] [GPT4]\n",
            "Player VS Programmatic Strategies\n",
            "--------------------------------------------------\n",
            "Chunk 261:\n",
            "0-Level (Fix)0.30 0.43 0.30 0.49 0.65 0.970-Level (Var)0.13 0.22 0.11 0.36 0.44 0.77MonoTrend (Fix)0.12 0.12 0.17 0.32 0.05 0.48MonoTrend (Var)0.17 0.13 0.19 0.42 0.34 0.74LastBids (Fix)0.04 0.11 0.22 0.38 0.01 0.75LastBids (Var)0.03 0.08 0.11 0.10 0.06\n",
            "--------------------------------------------------\n",
            "Chunk 262:\n",
            "0.18\n",
            "--------------------------------------------------\n",
            "Chunk 263:\n",
            "Avg 0.13 0.18 (+0.05) 0.18 0.35 (+0.17) 0.26 0.65 (+0.39)\n",
            "F Batter Nash Equilibrium\n",
            "Approximation with K-Level Reasoning\n",
            "To assess the impact of K-Level Reasoning on Nash\n",
            "equilibrium, we conducted experiments testing the\n",
            "--------------------------------------------------\n",
            "Chunk 264:\n",
            "performance of LLMs at different K-Levels in the\n",
            "Prisoner’s Dilemma. The Prisoner’s Dilemma is\n",
            "a classic concept in game theory that illustrates\n",
            "a paradoxical situation in which individuals act-\n",
            "ing in their own self-interest lead to a suboptimal\n",
            "--------------------------------------------------\n",
            "Chunk 265:\n",
            "outcome for everyone involved. It’s often used\n",
            "to study decision-making in situations involving\n",
            "cooperation and competition.\n",
            "From Table 11, it is evident that when K=1, play-\n",
            "ers exhibit weaker rationality: they tend to choose\n",
            "--------------------------------------------------\n",
            "Chunk 266:\n",
            "cooperation over betrayal. As the K-Level of one\n",
            "player increases (first row from left to right), play-\n",
            "ers with higher K-Levels demonstrate stronger ra-\n",
            "tionality: they tend to choose betrayal over coop-\n",
            "eration. Moreover, when both players’ K-Levels\n",
            "--------------------------------------------------\n",
            "Chunk 267:\n",
            "increase, they are more likely to reach a state of\n",
            "Nash equilibrium: both choosing to betray each\n",
            "other.\n",
            "Table 11: Statistical analysis of the Payoff Matrix\n",
            "for LLM in the Prisoner’s Dilemma across different\n",
            "--------------------------------------------------\n",
            "Chunk 268:\n",
            "K-Levels. The Nash equilibrium of the Prisoner’s\n",
            "Dilemma, where both players choose to betray each\n",
            "other, is highlighted with a green background in the\n",
            "bottom-right corner of each cell.\n",
            "Level-1 Level-2 Level-3 Level-4\n",
            "10 0 7 3 1 9 0 10Level-1\n",
            "--------------------------------------------------\n",
            "Chunk 269:\n",
            "0 0 0 0 0 0 0 0\n",
            "7 0 2 0 0 2 0 1Level-2\n",
            "3 0 5 3 0 8 0 9\n",
            "1 0 0 0 0 0 0 0Level-3\n",
            "9 0 2 8 0 10 1 9\n",
            "0 0 0 0 0 1 0 0Level-4\n",
            "10 0 1 9 0 9 1 9\n",
            "G Computational Cost Analysis\n",
            "Table 12: Average input/output/total token consumption\n",
            "per game test. Unit: Kilo tokens.\n",
            "--------------------------------------------------\n",
            "Chunk 270:\n",
            "Game Metric Direct CoT Persona Reflect Refine PCoT K-R\n",
            "GO8A\n",
            "Input 14.80 23.30 18.70 39.50145.5030.80 123.40Output 0.10 1.80 0.60 1.20 6.901.30 1.60Total 14.90 25.10 19.30 40.70152.4032.10 124.90\n",
            "Avg Win Rate 0.16 0.42 0.41 0.24 0.37 0.400.65\n",
            "SAG\n",
            "--------------------------------------------------\n",
            "Chunk 271:\n",
            "Input 21.30 29.00 27.10 51.40130.5037.00 90.10Output 0.70 1.00 0.90 1.80 3.301.30 1.40Total 22.00 30.00 28.10 53.20133.8038.20 91.60\n",
            "Avg Surv Round 6.51 7.44 7.59 4.82 7.33 6.179.01\n",
            "To understand how different reasoning meth-\n",
            "--------------------------------------------------\n",
            "Chunk 272:\n",
            "ods affect token consumption, thereby assisting\n",
            "users in utilizing models more effectively and opti-\n",
            "mizing resource utilization and cost control, we\n",
            "conducted an analysis of the computational ex-\n",
            "penditure associated with various reasoning ap-\n",
            "--------------------------------------------------\n",
            "Chunk 273:\n",
            "proaches. Specifically, we calculated the average\n",
            "input/output/total token consumption per game test\n",
            "for both the \"Guessing 0.8 of the Average\" and\n",
            "\"Survival Auction Game.\"\n",
            "K-Level Reasoning, due to simulating the oppo-\n",
            "--------------------------------------------------\n",
            "Chunk 274:\n",
            "nents’ actions based on public historical behavior\n",
            "information with new sessions, inevitably causes\n",
            "more token consumption. The increase in token\n",
            "consumption linearly correlates with the number of\n",
            "opponents that need to be simulated and the rounds.\n",
            "--------------------------------------------------\n",
            "Chunk 275:\n",
            "We also find that more token consumption does\n",
            "not necessarily lead to better results. The Self-\n",
            "Refine method, due to its action-feedback-refine\n",
            "pipeline, leads to a substantial increase in token\n",
            "consumption for both input and output, yet it did\n",
            "--------------------------------------------------\n",
            "Chunk 276:\n",
            "not outperform our proposed K-Level Reasoning\n",
            "in terms of performance. Compared to baselines,\n",
            "the proposed K-Level Reasoning method is an ef-\n",
            "fective and efficient way to recursively simulate the\n",
            "decision-making process of the opponent and make\n",
            "--------------------------------------------------\n",
            "Chunk 277:\n",
            "decisions based on the simulation results.\n",
            "H Statistical Significance of K-Level\n",
            "Reasoning efficacy\n",
            "Due to the utilization of a large language model for\n",
            "evaluation, inherent stochasticity is present, and\n",
            "the sample size for testing is limited (only con-\n",
            "--------------------------------------------------\n",
            "Chunk 278:\n",
            "ducted 10 experiments). To objectively assess the\n",
            "reliability of the experiment result, we subjected\n",
            "the results from G0.8A and SAG to a t-test for sig-\n",
            "nificance with p = 0.05. Specifically, different\n",
            "significance testing methods were employed for\n",
            "--------------------------------------------------\n",
            "Chunk 279:\n",
            "different evaluation metrics, as outlined below:\n",
            "15\n",
            "--------------------------------------------------\n",
            "Chunk 280:\n",
            "Table 13: The significance of metric result on G0.8A and SAG, comparing K-R against differentbaseline models in\n",
            "terms of Win Rate, Average Survival Round, and Adaptation Index.\n",
            "Game Metric Direct CoT Persona Reflect Refine PCoT\n",
            "--------------------------------------------------\n",
            "Chunk 281:\n",
            "G0.8A Win Rate ✓(0.001) ✓(0.005) ✓(0.001) ✓(0.001) ✓(0.001) ✓(0.001)\n",
            "Adaption Index ✓(0.007) ✓(0.010) ✓(0.039) ×(0.062) ✓(0.003) ✓(0.021)\n",
            "SAG Average Survival Round ✓(0.003) ✓(0.010) ×(0.074) ✓(0.001) ✓(0.001) ✓(0.001)\n",
            "--------------------------------------------------\n",
            "Chunk 282:\n",
            "Adaption Index ×(0.337) ×(0.786) ×(0.659) ×(0.066) ×(0.672) ×(0.894)\n",
            "Table 14: The significance of comparing K-R with PCoT concerning the differential performance across various\n",
            "Baseline models on the metric of Prediction Accuracy.\n",
            "--------------------------------------------------\n",
            "Chunk 283:\n",
            "Game Direct CoT Persona Reflect Refine PCoT K-R\n",
            "G0.8A ✓(0.003) ×(0.058) ✓(0.031) ✓(0.003) ✓(0.022) ✓(0.023) ×(0.107)\n",
            "SAG ×(0.091) ✓(0.023) ✓(0.049) ×(0.907) ×(0.956) ×(0.656) ✓(0.028)\n",
            "• Win Rate & Average Survival Round: A t-test\n",
            "--------------------------------------------------\n",
            "Chunk 284:\n",
            "was conducted on the Win Rate and Average\n",
            "Survival Round of K-R versus other baselines\n",
            "when facing different agents. The null hypoth-\n",
            "esis posited no significant difference in perfor-\n",
            "mance between K-R and other baselines con-\n",
            "--------------------------------------------------\n",
            "Chunk 285:\n",
            "cerning Win Rate & Average Survival Round.\n",
            "• Adaptation Index: The method akin to that\n",
            "of Win Rate & Average Survival Round was\n",
            "applied.\n",
            "• Prediction Accuracy: Since only PCoT and\n",
            "K-R explicitly predicted opponents, we com-\n",
            "--------------------------------------------------\n",
            "Chunk 286:\n",
            "pared the significance of the prediction differ-\n",
            "ences between PCoT and K-R. Unlike Win\n",
            "Rate and Adaptation Index, we assessed the\n",
            "differences in predictions (averaged over mul-\n",
            "tiple experiments) between PCoT and K-R\n",
            "--------------------------------------------------\n",
            "Chunk 287:\n",
            "when facing the same opponents (e.g., CoT)\n",
            "across different game rounds.\n",
            "From Table 13 and Table 14, it is evident that\n",
            "K-R exhibits a significant advantage over other\n",
            "baselines in Win Rate and Average Survival Round\n",
            "--------------------------------------------------\n",
            "Chunk 288:\n",
            "metrics. This indicates K-R’s superior rational-\n",
            "ity in both G0.8A and SAG. Additionally, we ob-\n",
            "served weaker significance of K-R’s Adaptation\n",
            "Index compared to baselines in SAG. We attribute\n",
            "this observation to: 1) the more factors considered\n",
            "--------------------------------------------------\n",
            "Chunk 289:\n",
            "by each agent in SAG (e.g., health status), result-\n",
            "ing in a more dynamic and complex environment;\n",
            "and 2) the wider bidding range in later rounds of\n",
            "SAG games, potentially leading to greater bias in\n",
            "agent bidding and rendering the Adaptation Index\n",
            "--------------------------------------------------\n",
            "Chunk 290:\n",
            "a challenging metric.\n",
            "I Timing in Dynamic Reasoning\n",
            "In our experiment, we implemented two LLM self-\n",
            "refinement reasoning methods: Reflect (Madaan\n",
            "et al., 2023) and Refine (Shinn et al., 2023), and\n",
            "noticed that Refine performed significantly better\n",
            "--------------------------------------------------\n",
            "Chunk 291:\n",
            "than Reflect in the experimental results. To further\n",
            "explore the differences in performance between\n",
            "these two methods, we analyzed their respective\n",
            "working principles and applicable scenarios.\n",
            "The Reflect method involves making decisions\n",
            "--------------------------------------------------\n",
            "Chunk 292:\n",
            "first, then summarizing the experience based on\n",
            "feedback from the environment. This method\n",
            "may be effective in scenarios where the environ-\n",
            "ment does not change much or where the decision-\n",
            "making cycle is long, as it allows for quick decision-\n",
            "--------------------------------------------------\n",
            "Chunk 293:\n",
            "making. However, its drawback is that, in dynamic\n",
            "environments, the experience from the previous\n",
            "round may not be suitable for the next round. In\n",
            "fact, in the Survival Auction Game (SAG), a rapidly\n",
            "changing environment, the survival rate of the Re-\n",
            "--------------------------------------------------\n",
            "Chunk 294:\n",
            "flect method is even lower compared to making\n",
            "direct decisions. This is likely because this method\n",
            "does not sufficiently take into account the dynamic\n",
            "nature of the environment.\n",
            "In contrast, the Refine method involves mul-\n",
            "--------------------------------------------------\n",
            "Chunk 295:\n",
            "tiple analyses before making a decision, includ-\n",
            "ing an initial analysis and improvements to that\n",
            "initial analysis. Importantly, both of these anal-\n",
            "yses are conducted in the context of the current\n",
            "decision-making environment. This makes the Re-\n",
            "16\n",
            "--------------------------------------------------\n",
            "Chunk 296:\n",
            "Ok, Alex! Now is the ROUND 1, and your HP is at 10. Guess which number will win in the \n",
            "next round. Let's think step by step, and finally answer a number you think you can win.\n",
            "Prompt\n",
            "Ok, Alex! Now is the ROUND 2, and your HP is at 9. Please\n",
            "--------------------------------------------------\n",
            "Chunk 297:\n",
            "choose an integer between 1 and 100 for this round.\n",
            "In the first round, since there is no prior information about the other players' choices, it's \n",
            "difficult to accurately predict which number will win. However, we can make some\n",
            "--------------------------------------------------\n",
            "Chunk 298:\n",
            "assumptions and try to optimize our chances of winning.\n",
            "Let's assume that all players, including myself, choose numbers uniformly and \n",
            "independently between 1 and 100. Then, the expected average of all chosen numbers\n",
            "--------------------------------------------------\n",
            "Chunk 299:\n",
            "would be (1 + 100) / 2 = 50.5. If we multiply this by 0.8, we get 0.8 * 50.5 = 40.4. Since we \n",
            "need to choose an integer, we can round this to 40.\n",
            "Therefore, my initial guess for the first round is 40.\n",
            "Historical Targets: \n",
            "Round1:38\n",
            "Last Round choices:\n",
            "--------------------------------------------------\n",
            "Chunk 300:\n",
            "Player1:50 Player2:45 Plyaer3:50 Player4:45 Player5:50\n",
            "Historical Targets: \n",
            "None\n",
            "Last Round choices: \n",
            "None\n",
            "Round-1: Player1Prompt\n",
            "Result:\n",
            "Player1: 40 Player2:47 Player3: 40 Player4: 60 Player5:42\n",
            "Target number: (40 + 47 + 40 + 60 + 42) / 5 * 0.8 = 37\n",
            "--------------------------------------------------\n",
            "Chunk 301:\n",
            "Winner: Player 1, Player3 \n",
            "Result:\n",
            "Player1: 32 Player2: 42 Player3: 50  Player4: 50 Player5: 45\n",
            "Target number(32 + 42 + 50 + 50 + 45) / 5 * 0.8 = 35\n",
            "Winner: Player 1\n",
            "delayed response\n",
            "Lose Win\n",
            "Round-2: Player1\n",
            "Reflect\n",
            "……\n",
            "Self-Refine\n",
            "……\n",
            "Output\n",
            "OutputOutput\n",
            "--------------------------------------------------\n",
            "Chunk 302:\n",
            "I choose 40 for this round.\n",
            "Reflect Prompt\n",
            "In Round 2, the chosen numbers were 40, 47, 40, 60, and 42. The average of these numbers was 45.8, \n",
            "and 0.8 times the average was 36.64. Alex and Cindy's choices of 40 were the closest to 36.64,\n",
            "--------------------------------------------------\n",
            "Chunk 303:\n",
            "making them the winners of the round. \n",
            "From this round, we can observe that choosing a number closer to the expected average, considering \n",
            "the choices of other players, and adapting based on their choices is a good strategy. It's also\n",
            "--------------------------------------------------\n",
            "Chunk 304:\n",
            "important to note that the chosen numbers in this round were more diverse compared to the first \n",
            "round, which affected the average and the target number. Learning from the previous round and\n",
            "--------------------------------------------------\n",
            "Chunk 305:\n",
            "adjusting your choice accordingly can improve your chances of winning.\n",
            "Review the previous round games, summarize the experience.\n",
            "Prompt\n",
            "Ok, Alex! Now is the ROUND 3, and your HP is at 9. Please choose an integer between 1 and 100 \n",
            "for this round.\n",
            "--------------------------------------------------\n",
            "Chunk 306:\n",
            "Round-3: Player1\n",
            "Output\n",
            "I choose 44 for this round.\n",
            "Win\n",
            "Result:\n",
            "Player1: 44 Player2:44 Player3: 55 Player4: 48 Player5:38\n",
            "Target number: (44 + 44 + 55 + 48 + 38)/ 5 * 0.8 = 37\n",
            "Winner: Player5\n",
            "Reflect: Player1\n",
            "outdated experience\n",
            "Feedback Prompt\n",
            "--------------------------------------------------\n",
            "Chunk 307:\n",
            "I have a game expert's advice on your strategy in this round. You can adjust your \n",
            "strategy just now according to his suggestion. Here are his suggestions:\n",
            "“As a game expert, I suggest a slight modification to the user's strategy to improve their\n",
            "--------------------------------------------------\n",
            "Chunk 308:\n",
            "winning rate in this round. Instead of assuming that all players will choose numbers \n",
            "uniformly and independently between 1 and 100, we can recognize that other players \n",
            "might also use a similar strategy and choose a number close to 40.\n",
            "--------------------------------------------------\n",
            "Chunk 309:\n",
            "To optimize our chances of winning, we can try to be one step ahead of them. If we \n",
            "assume that the average of the chosen numbers will be around 40, we can multiply this\n",
            "--------------------------------------------------\n",
            "Chunk 310:\n",
            "by 0.8, which gives us 0.8 * 40 = 32. This way, we are closer to the 0.8 * the average if \n",
            "other players also cluster around 40. So, my optimized suggestion for the first round is to \n",
            "choose the number 32.”\n",
            "Refine Output\n",
            "--------------------------------------------------\n",
            "Chunk 311:\n",
            "Taking the game expert's advice into consideration, it's possible that other players might \n",
            "also use a similar strategy and choose numbers close to 40. To stay one step ahead, I will\n",
            "--------------------------------------------------\n",
            "Chunk 312:\n",
            "adjust my strategy and choose the number 32 for the first round. This way, I can be closer \n",
            "to the 0.8 * the average if other players also cluster around 40.\n",
            "real-time experience\n",
            "timely adjustment\n",
            "--------------------------------------------------\n",
            "Chunk 313:\n",
            "Figure 6: Illustration of Reflect and Refine methods in the Guessing 0.8 of the Average game.\n",
            "fine method more adaptable to dynamic environ-\n",
            "ments, as it can consider real-time changes in the\n",
            "current environment, thus making more accurate\n",
            "decisions.\n",
            "--------------------------------------------------\n",
            "Chunk 314:\n",
            "In summary, the reason why the Refine method\n",
            "performed better in our experiment is mainly that\n",
            "it adapts better to rapidly changing dynamic envi-\n",
            "ronments.\n",
            "J Better Adaptability: Self-Refine vs.\n",
            "K-Level Reasoning\n",
            "--------------------------------------------------\n",
            "Chunk 315:\n",
            "As described in Section 2.1, K-R optimizes ini-\n",
            "tial actions through predictions of opponent behav-\n",
            "ior, thereby implementing higher-order beliefs. Al-\n",
            "though Self-Refine also optimizes initial actions via\n",
            "self-feedback, previous experiments have demon-\n",
            "--------------------------------------------------\n",
            "Chunk 316:\n",
            "strated that K-R significantly outperforms Self-\n",
            "Refine. To further investigate the source of K-R’s\n",
            "performance enhancement, we present in Figure 7 a\n",
            "statistical analysis of action differences before and\n",
            "after optimization for both K-R and Self-Refine.\n",
            "--------------------------------------------------\n",
            "Chunk 317:\n",
            "Analysis of the results reveals that Self-Refine\n",
            "initially exerts a substantial influence on actions.\n",
            "However, as time progresses, its optimization scope\n",
            "gradually diminishes, leading to a decrease in ef-\n",
            "Round 2 Round 4 Round 6 Round 8 Round 10\n",
            "0\n",
            "10\n",
            "20\n",
            "--------------------------------------------------\n",
            "Chunk 318:\n",
            "30\n",
            "40T uning Range\n",
            "K-R T uning Range\n",
            "Refine T uning Range\n",
            "Figure 7: The tuning range before and after adjustment\n",
            "during the G0.8A between PCoT and K-Level Reason-\n",
            "ing. A larger tuning range indicates that the method\n",
            "exerts a more substantial influence.\n",
            "--------------------------------------------------\n",
            "Chunk 319:\n",
            "ficacy. In contrast, K-R exhibits a broader range\n",
            "of optimization, indicating that the higher-order\n",
            "belief mechanism has a more pronounced impact\n",
            "on K-R’s performance.\n",
            "This disparity primarily stems from the distinct\n",
            "--------------------------------------------------\n",
            "Chunk 320:\n",
            "feedback mechanisms employed by K-R and Self-\n",
            "Refine. K-R generates feedback based on predic-\n",
            "tions of opponent behavior, enabling it to capture\n",
            "trends in opponent actions and form an understand-\n",
            "17\n",
            "--------------------------------------------------\n",
            "Chunk 321:\n",
            "ing of the environment, thus facilitating rapid adap-\n",
            "tation. Conversely, Self-Refine’s feedback is de-\n",
            "rived from its own strategy, which often adheres to\n",
            "fixed patterns. Consequently, Self-Refine underper-\n",
            "--------------------------------------------------\n",
            "Chunk 322:\n",
            "forms K-R in terms of environmental adaptability.\n",
            "K Reasoning Method Implementation\n",
            "Details\n",
            "18\n",
            "--------------------------------------------------\n",
            "Chunk 323:\n",
            "Round Start Prompt:\n",
            "Ok, Alex! Now is the ROUND 1, and your HP is at 10. Please choose an integer between 1 and 100 for this round.\n",
            "Example Output:\n",
            "I choose 45.\n",
            "Figure 8: G0.8A: Direct Prompt\n",
            "Reflect Prompt (Following Notification Result Prompt ):\n",
            "--------------------------------------------------\n",
            "Chunk 324:\n",
            "Review the previous round games, summarize the experience.\n",
            "Example Output:\n",
            "In the previous round, the majority of the players chose numbers around 40, which resulted in a lower average of 42.8. When m ultiplied by\n",
            "--------------------------------------------------\n",
            "Chunk 325:\n",
            "0.8, the target number was 34.24. My choice of 50 was too high, causing me to lose 1 HP . T o improve my chances in the next ro und, I should \n",
            "consider choosing a number closer to the majority's choice, taking into account the 0.8 multiplier .\n",
            "--------------------------------------------------\n",
            "Chunk 326:\n",
            "Figure 9: G0.8A-Reflect Prompt: Because the Reflect method requires correct labels, which is unrealistic in dynamic\n",
            "problems, we modified this method to have the LLM attempt to summarize the experience of victory or failure at\n",
            "--------------------------------------------------\n",
            "Chunk 327:\n",
            "the end of each round, and save the generated feedback content to assist the decision-making process in the next\n",
            "round. The content in Appendix I shows the implementation differences between Reflexion and Self-Refine.\n",
            "Round Start Prompt:\n",
            "--------------------------------------------------\n",
            "Chunk 328:\n",
            "Ok, Alex! Now is the ROUND 1, and your HP is at 10. Guess which number will win in the next round. Let's think step by step, and finally \n",
            "answer a number you think you can win.\n",
            "Example Output:\n",
            "--------------------------------------------------\n",
            "Chunk 329:\n",
            "Step 1: Consider the range of possible numbers. Since the integers can be between 1 and 100, the average of all chosen number s will likely \n",
            "fall within this range as well.\n",
            "--------------------------------------------------\n",
            "Chunk 330:\n",
            "Step 2: Determine the target number . Since the winning number is closest to 0.8 * the average, we should focus on finding a n umb er that \n",
            "will be close to this value.\n",
            "--------------------------------------------------\n",
            "Chunk 331:\n",
            "Step 3: Make an educated guess. Since it's difficult to predict the exact numbers other players will choose, we can make an e ducated guess\n",
            "--------------------------------------------------\n",
            "Chunk 332:\n",
            "based on the range of possible numbers. Assuming players choose numbers evenly across the range, the average should be around  the \n",
            "midpoint, which is 50. \n",
            "Step 4: Calculate the target number based on our guess. 0.8 * 50 = 40.\n",
            "--------------------------------------------------\n",
            "Chunk 333:\n",
            "Step 5: Choose a number close to the target number . To increase the chances of winning, we should choose a number close to 40 .\n",
            "My final answer: I will choose 40.\n",
            "Figure 10: G0.8A: CoT Prompt\n",
            "19\n",
            "--------------------------------------------------\n",
            "Chunk 334:\n",
            "Round Start Prompt:\n",
            "Ok, Alex! Now is the ROUND 2, and your HP is at 9. Please choose an integer between 1 and 100 for this round.\n",
            "--------------------------------------------------\n",
            "Chunk 335:\n",
            "First of all, predict the next round of choices based on the choices of other players in the previous round. The players' cho ices in the \n",
            "previous rounds are as follows:\n",
            "--------------------------------------------------\n",
            "Chunk 336:\n",
            "Round 1: Alex chose 50, Bob chose 47, Cindy chose 50, David chose 45, Eric chose 50. Your output should be of the following f ormat:\n",
            "Predict:\n",
            "The choice of each player in the next round here.\n",
            "--------------------------------------------------\n",
            "Chunk 337:\n",
            "Based on the prediction of other players, the average number in the next round here, and the target number in the next round (0.8 * the \n",
            "average of all chosen numbers) here.\n",
            "Answer:\n",
            "the number will you choose to win the next round game here.\n",
            "--------------------------------------------------\n",
            "Chunk 338:\n",
            "Example Output:\n",
            "Predict:\n",
            "Based on the choices of other players in the previous round, I predict the following choices for the next round:\n",
            "Player 1 (Bob): 47\n",
            "Player 2 (Cindy): 50\n",
            "Player 3 (David): 45\n",
            "Player 4 (Eric): 50\n",
            "--------------------------------------------------\n",
            "Chunk 339:\n",
            "Based on these predictions, the average number in the next round would be (47 + 50 + 45 + 50)/4 = 48, and the target number ( 0.8 * the \n",
            "average of all chosen numbers) would be 0.8 * 48 = 38.4.\n",
            "Answer:\n",
            "--------------------------------------------------\n",
            "Chunk 340:\n",
            "For this round, I will choose 39 to get closer to the target number of 38.4.\n",
            "Figure 11: G0.8A PCot Prompt: PCot diverges from the standard Chain of Thought (CoT) by explicitly requiring\n",
            "--------------------------------------------------\n",
            "Chunk 341:\n",
            "the LLM to predict opponents’ actions before making a decision. This method responds to the immediate problem\n",
            "by anticipating future scenarios, which is crucial in dynamic reasoning.\n",
            "Introduction Prompt:\n",
            "--------------------------------------------------\n",
            "Chunk 342:\n",
            "You are Alex and involved in a survive challenge. You are a game expert, good at predicting other people‘s behavior and deducing\n",
            "--------------------------------------------------\n",
            "Chunk 343:\n",
            "calculations, and using the most favorable strategy to win the game. SURVIVE CHALLENGE!!! You are one of five players in the game.\n",
            "--------------------------------------------------\n",
            "Chunk 344:\n",
            "Everyone is required to choose an integer between 1 and 100 in each round. The player whose chosen number is closest to (0.8 * the\n",
            "--------------------------------------------------\n",
            "Chunk 345:\n",
            "average of all chosen numbers) wins the round without any HP deduction. All other players will have 1 HP deducted. But if all  players choose \n",
            "the same number , their health points are deducted together .\n",
            "Round Start Prompt:\n",
            "--------------------------------------------------\n",
            "Chunk 346:\n",
            "Ok, Alex! Now is the ROUND 1, and your HP is at 10. Please choose an integer between 1 and 100 for this round.Don't forget your expert \n",
            "status, use your expertise to win this round!\n",
            "Example Output:\n",
            "--------------------------------------------------\n",
            "Chunk 347:\n",
            "Based on my expertise in predicting other people's behavior and deducing calculations, I will choose the number 40 for this r ound. I'm \n",
            "assuming that the average of all chosen numbers will be around 50, and 0.8 times that is 40.\n",
            "--------------------------------------------------\n",
            "Chunk 348:\n",
            "Figure 12: G0.8A:Persona Prompt\n",
            "20\n",
            "--------------------------------------------------\n",
            "Chunk 349:\n",
            "Round Start Prompt:\n",
            "Ok, Alex! Now is the ROUND 1, and your HP is at 10. Guess which number will win in the next round. Let's think step by step, and finally \n",
            "answer a number you think you can win.\n",
            "First Output:\n",
            "--------------------------------------------------\n",
            "Chunk 350:\n",
            "I'll start by assuming that the other players might choose numbers randomly or evenly distributed between 1 and 100. In this case, the \n",
            "average of the chosen numbers could be around 50.\n",
            "--------------------------------------------------\n",
            "Chunk 351:\n",
            "Next, I'll calculate 0.8 times the average, which would be 0.8 * 50 = 40. \n",
            "Considering this, I will choose 40 as my number for this round.\n",
            "Refine Prompt:\n",
            "--------------------------------------------------\n",
            "Chunk 352:\n",
            "I have a game expert's advice on your strategy in this round. You can adjust your strategy just now according to his suggesti on. Here are his \n",
            "suggestions:\n",
            "--------------------------------------------------\n",
            "Chunk 353:\n",
            "”Certainly! To optimize the user's strategy, we can apply a more advanced approach, taking into consideration the other playe rs' potential \n",
            "strategies. This is known as \"iterated elimination of dominated strategies.\"\n",
            "--------------------------------------------------\n",
            "Chunk 354:\n",
            "Let's assume that all players will think similarly to Alex and also aim to choose a number closest to 0.8 * the average. We c an then narrow \n",
            "down the range of numbers that they would likely choose.\n",
            "--------------------------------------------------\n",
            "Chunk 355:\n",
            "Since the range is between 1 and 100, and the average would be around 50, we can eliminate numbers below 0.8 * 50 = 40, as th ese \n",
            "numbers would not be an optimal choice for the other players.\n",
            "--------------------------------------------------\n",
            "Chunk 356:\n",
            "Now, we'll focus on the range between 40 and 100. The average within this range is (40 + 100) / 2 = 70. Then, we can calculat e 0.8 * 70 = 56.\n",
            "--------------------------------------------------\n",
            "Chunk 357:\n",
            "Given this information, Alex should choose 56 to improve his winning rate in this round. This strategy assumes that the other  players are \n",
            "also thinking strategically and eliminating dominated options. ”\n",
            "Second Output:\n",
            "--------------------------------------------------\n",
            "Chunk 358:\n",
            "Thank you for the expert's advice. Based on the iterated elimination of dominated strategies, I will adjust my choice and sel ect 56 for this \n",
            "round to improve my chances of winning.\n",
            "Feedback Prompt:\n",
            "--------------------------------------------------\n",
            "Chunk 359:\n",
            "Carefully study the user's strategy in this round of the game. As a game expert, can you give a suggestion to optimize the us er's strategy so \n",
            "that he can improve his winning rate in this round?\n",
            "Figure 13: G0.8A: Refine Prompt\n",
            "Round Start Prompt:\n",
            "--------------------------------------------------\n",
            "Chunk 360:\n",
            "Ok, Alex! Now is the ROUND 1, and your HP is at 10. Another game expert's prediction for the next round of other players is a s follows: Bob\n",
            "--------------------------------------------------\n",
            "Chunk 361:\n",
            "might choose 50, Cindy might choose 57, David might choose 45, Eric might choose 55. According to the game expert's predictio n, what \n",
            "number will you give in the next round is most likely to be close to the target number?\n",
            "Example Output:\n",
            "--------------------------------------------------\n",
            "Chunk 362:\n",
            "First, let's find the average of the predicted numbers chosen by the other players: (50 + 57 + 45 + 55) / 4 = 207 / 4 = 51.75\n",
            "Now, let's calculate 0.8 times the average: 0.8 * 51.75 = 41.4\n",
            "--------------------------------------------------\n",
            "Chunk 363:\n",
            "To have the best chance of winning the round, you should choose a number close to 41.4. Since you can only choose integers, y ou should \n",
            "choose either 41 or 42 in the next round.\n",
            "Figure 14: G0.8A: K-Level Reasoning\n",
            "Round Start Prompt:\n",
            "--------------------------------------------------\n",
            "Chunk 364:\n",
            "Hello, Alex! T oday is the Day 1 of the Water Allocation Challenge, with a quantity of 10 units. Y our status:\n",
            "name: Alex   balance: 100 HP:8 no_drink:1\n",
            "--------------------------------------------------\n",
            "Chunk 365:\n",
            "Please carefully analyze your situation to decide on this round of bidding. Remember , the most important thing is to SURVIVE! ! N ow, if you \n",
            "want to participate in today's water resource auction, please provide your bid.\n",
            "Example Output:\n",
            "--------------------------------------------------\n",
            "Chunk 366:\n",
            "I will bid $25 for today's water resource auction.\n",
            "Figure 15: SAG: Direct Prompt\n",
            "21\n",
            "--------------------------------------------------\n",
            "Chunk 367:\n",
            "Reflect Prompt (Following Notification Result Prompt ):\n",
            "Review the previous round games, summarize the experience.\n",
            "Example Output:\n",
            "--------------------------------------------------\n",
            "Chunk 368:\n",
            "In the previous round, I bid $20 which was not enough to secure the water resources. I need to adjust my bidding strategy by increasing my\n",
            "--------------------------------------------------\n",
            "Chunk 369:\n",
            "bid to have a better chance of winning the auction. I should also observe and adapt to other residents' bidding patterns to i mprove my \n",
            "chances of survival.\n",
            "Figure 16: SAG: Reflect Prompt\n",
            "Round Start Prompt:\n",
            "--------------------------------------------------\n",
            "Chunk 370:\n",
            "Hello, Alex! Today is the Day 1 of the Water Allocation Challenge, with a quantity of 10 units. Your status:\n",
            "NAME:Alex  BALANCE:100  HEALTH POINT:8  NO_DRINK:1\n",
            "--------------------------------------------------\n",
            "Chunk 371:\n",
            "Please carefully analyze your situation to decide on this round of bidding. Remember , the most important thing is to SURVIVE! ! N ow, if you\n",
            "--------------------------------------------------\n",
            "Chunk 372:\n",
            "want to participate in today‘s water resource auction, please provide your bid. Think carefully about your next round of bidding strategy to \n",
            "be most likely to survive. Let's think step by step, and finally provide your bid.\n",
            "Example Output:\n",
            "--------------------------------------------------\n",
            "Chunk 373:\n",
            "I need to carefully consider my bidding strategy for today. With a balance of $100, I have some room to bid, but I also need to think about\n",
            "--------------------------------------------------\n",
            "Chunk 374:\n",
            "the other residents and their bids. Since we all have the same daily water requirement and budget, I need to outbid at least one resident to \n",
            "secure my water resources for today.\n",
            "--------------------------------------------------\n",
            "Chunk 375:\n",
            "Considering that the total daily water supply is 10 units, which is enough to meet only one resident's water requirements, th e competition \n",
            "will be tough. However , bidding too high might leave me with less money for the upcoming days.\n",
            "--------------------------------------------------\n",
            "Chunk 376:\n",
            "Taking all these factors into account, I will place a bid of $60 for today's water resource auction. This should give me a de cent chance of \n",
            "outbidding at least one resident while still maintaining some funds for the next few days.\n",
            "--------------------------------------------------\n",
            "Chunk 377:\n",
            "Figure 17: SAG: CoT Prompt\n",
            "Round Start Prompt:\n",
            "Hello, Alex! Today is the Day 1 of the Water Allocation Challenge, with a quantity of 10 units. Your status:\n",
            "NAME:Alex  BALANCE:100  HEALTH POINT:8  NO_DRINK:1\n",
            "--------------------------------------------------\n",
            "Chunk 378:\n",
            "Please carefully analyze your situation to decide on this round of bidding. Remember , the most important thing is to SURVIVE! ! N ow, if you\n",
            "--------------------------------------------------\n",
            "Chunk 379:\n",
            "want to participate in today‘s water resource auction, please provide your bid. First of all, predict the next round of bidding of opponents\n",
            "--------------------------------------------------\n",
            "Chunk 380:\n",
            "based on the choices of other players in the previous round. Since this is the first round, there is no historical informatio n about the last \n",
            "round. You can predict according to your understanding. Your output should be of the following format:\n",
            "Predict:\n",
            "--------------------------------------------------\n",
            "Chunk 381:\n",
            "The choice of each player in the next round here.\n",
            "Based on the prediction of other players, think carefully about your next round of bidding strategy to be most likely to surv ive. Let's think \n",
            "step by step, and finally provide your bid. Answer:\n",
            "--------------------------------------------------\n",
            "Chunk 382:\n",
            "the bidding will you choose in the next round game here.\n",
            "Example Output:\n",
            "Predict:\n",
            "Player 1: $30\n",
            "Player 2: $40\n",
            "Player 3: $50\n",
            "Player 4: $60\n",
            "Answer:\n",
            "--------------------------------------------------\n",
            "Chunk 383:\n",
            "Since this is the first round and we don't have any historical information about the other players, I will choose a bid of $3 5 f or the next\n",
            "--------------------------------------------------\n",
            "Chunk 384:\n",
            "round. This bid is higher than the lowest predicted bid but not too high, which should give me a chance to secure water resou rces while \n",
            "preserving my budget.\n",
            "Figure 18: SAG: PCoT Prompt\n",
            "22\n",
            "--------------------------------------------------\n",
            "Chunk 385:\n",
            "Introduction Prompt:\n",
            "You are Alex and a resident living in W-Town. W Town is experiencing a rare drought. Every residents in Town W is ensuring their survival\n",
            "--------------------------------------------------\n",
            "Chunk 386:\n",
            "over a period of 10 days by acquiring the water resources.  You are a game expert, good at predicting other people‘s behavior and\n",
            "--------------------------------------------------\n",
            "Chunk 387:\n",
            "deducing calculations, and using the most favorable strategy to win the game. 。。。(The following is the same as the Introduction \n",
            "Prompt.)\n",
            "Round Start Prompt:\n",
            "--------------------------------------------------\n",
            "Chunk 388:\n",
            "Hello, Alex! Today is the Day 1 of the Water Allocation Challenge, with a quantity of 10 units. Your status:\n",
            "NAME:Alex BALANCE:100 HEALTH POINT:8 NO_DRINK:1\n",
            "--------------------------------------------------\n",
            "Chunk 389:\n",
            "Please carefully analyze your situation to decide on this round of bidding. Remember , the most important thing is to SURVIVE! ! N ow, if you\n",
            "--------------------------------------------------\n",
            "Chunk 390:\n",
            "want to participate in today's water resource auction, please provide your bid. Don't forget your expert status, use your exp ertise to win this \n",
            "round!\n",
            "Example Output:\n",
            "--------------------------------------------------\n",
            "Chunk 391:\n",
            "Given that everyone starts with the same budget and water requirements, it's important to strategize and predict the bidding behavior of\n",
            "--------------------------------------------------\n",
            "Chunk 392:\n",
            "the other residents. As it is the first day of the challenge, I will assume that other residents may bid aggressively to secu re their water \n",
            "resources.\n",
            "--------------------------------------------------\n",
            "Chunk 393:\n",
            "To increase my chances of winning, I will place a bid slightly higher than the average expected bid. Since the daily salary i s $100, I predict \n",
            "most residents might bid around $60 to $80.\n",
            "--------------------------------------------------\n",
            "Chunk 394:\n",
            "Considering this, I will place a bid of $85 for Day 1 of the Water Allocation Challenge.\n",
            "Figure 19: SAG: Persona Prompt\n",
            "23\n",
            "--------------------------------------------------\n",
            "Chunk 395:\n",
            "Round Start Prompt:\n",
            "Hello, Alex! Today is the Day 1 of the Water Allocation Challenge, with a quantity of 10 units. Your status:\n",
            "NAME:Alex BALANCE:100 HEALTH POINT:8 NO_DRINK:1\n",
            "--------------------------------------------------\n",
            "Chunk 396:\n",
            "Please carefully analyze your situation to decide on this round of bidding. Remember , the most important thing is to SURVIVE! ! N ow, if you\n",
            "--------------------------------------------------\n",
            "Chunk 397:\n",
            "want to participate in today's water resource auction, please provide your bid. Think carefully about your next round of bidd ing strategy to \n",
            "be most likely to survive. Let's think step by step, and finally provide your bid.\n",
            "First Output:\n",
            "--------------------------------------------------\n",
            "Chunk 398:\n",
            "Considering the current situation, my status is:\n",
            "- Balance: $100\n",
            "- Health Points: 8\n",
            "- No Drink Days: 1\n",
            "As it's the first day of the challenge, I want to ensure that I have enough water to meet my needs and avoid any health point  deductions.\n",
            "--------------------------------------------------\n",
            "Chunk 399:\n",
            "However , I also need to be strategic about my bidding to ensure I have enough money for future bids. \n",
            "Since the total daily water supply is 10 units, and I need 10 units of water per day, I will need to secure all the available  water resources for\n",
            "--------------------------------------------------\n",
            "Chunk 400:\n",
            "today. As it's the first day, other residents might also be bidding aggressively to secure their water resources.\n",
            "--------------------------------------------------\n",
            "Chunk 401:\n",
            "Therefore, I will bid $60 for the water resources today, which is a little over half of my daily salary. This should give me a competitive edge \n",
            "while also leaving me with enough money for future bids.\n",
            "My bid for today's water resource auction: $60.\n",
            "--------------------------------------------------\n",
            "Chunk 402:\n",
            "Refine Prompt:\n",
            "I have a game expert's advice on your strategy in this round. You can adjust your strategy just now according to his suggesti on. Here are his\n",
            "--------------------------------------------------\n",
            "Chunk 403:\n",
            "suggestions: While the user's strategy of bidding $60 is a good starting point, there is room for optimization to improve the  winning rate in\n",
            "--------------------------------------------------\n",
            "Chunk 404:\n",
            "this round. Since everyone has the same daily water requirement and budget, it's essential to consider the bidding behavior o f the other \n",
            "residents.\n",
            "--------------------------------------------------\n",
            "Chunk 405:\n",
            "A suggested optimization would be to slightly increase the bid to $65. This increment gives an added advantage over competito rs who might\n",
            "--------------------------------------------------\n",
            "Chunk 406:\n",
            "also be bidding around half of their daily salary. Additionally, bidding an odd number reduces the chances of a tie, as other  residents may \n",
            "place round number bids.\n",
            "--------------------------------------------------\n",
            "Chunk 407:\n",
            "With this optimized strategy, the user still maintains a good balance of aggressive bidding and budget management, increasing  their chances \n",
            "of securing the water resources for today.\n",
            "Optimized bid for today's water resource auction: $65.\n",
            "--------------------------------------------------\n",
            "Chunk 408:\n",
            "Finally provide your bid. Answer: the bidding will you choose.\n",
            "Second Output:\n",
            "After considering the game expert's advice, I have decided to adjust my bid for today's water resource auction. I will increa se my bid to $65,\n",
            "--------------------------------------------------\n",
            "Chunk 409:\n",
            "as this gives me a better chance of winning the auction and reduces the risk of a tie.\n",
            "My final bid for today's water resource auction: $65.\n",
            "Feedback Prompt:\n",
            "--------------------------------------------------\n",
            "Chunk 410:\n",
            "Carefully study the user's strategy in this round of the game. As a game expert, can you give a suggestion to optimize the us er's strategy so \n",
            "that he can improve his winning rate in this round?\n",
            "Figure 20: SAG: Refine Prompt\n",
            "Round Start Prompt:\n",
            "--------------------------------------------------\n",
            "Chunk 411:\n",
            "Hello, Alex! Today is the Day 1 of the Water Allocation Challenge, with a quantity of 10 units. Your status:\n",
            "NAME:Alex BALANCE:100 HEALTH POINT:8. NO_DRINK:1\n",
            "--------------------------------------------------\n",
            "Chunk 412:\n",
            "Please carefully analyze your situation to decide on this round of bidding. Remember , the most important thing is to SURVIVE! ! N ow, if you\n",
            "--------------------------------------------------\n",
            "Chunk 413:\n",
            "want to participate in today's water resource auction, please provide your bid. Another game expert's prediction for the next  round of other\n",
            "--------------------------------------------------\n",
            "Chunk 414:\n",
            "players is as follows: Bob might choose 30, Cindy might choose 30, David might choose 40, Eric might choose 25.  Based on the  prediction of \n",
            "other players, think carefully about your next round of bidding strategy to be most likely to survive.\n",
            "--------------------------------------------------\n",
            "Chunk 415:\n",
            "Example Output:\n",
            "Given the game expert's prediction, I will bid $35 to increase my chances of winning the water resources for today.\n",
            "Figure 21: SAG: K-Level Reasoning Prompt\n",
            "24\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_or_fetch_embeddings(index_name, docs):\n",
        "  import pinecone\n",
        "  from langchain_community.vectorstores import Pinecone\n",
        "  from langchain_openai import OpenAIEmbeddings\n",
        "  # from pinecone import PodSpec\n",
        "  from pinecone import Pinecone, ServerlessSpec\n",
        "  from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "  from uuid import uuid4\n",
        "\n",
        "  from langchain_core.documents import Document\n",
        "\n",
        "  import time\n",
        "\n",
        "  # pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
        "  pc = pinecone.Pinecone(api_key=pc_apikey)\n",
        "\n",
        "  # from openai import OpenAI\n",
        "  # client = OpenAI()\n",
        "\n",
        "  embeddings = OpenAIEmbeddings(model='text-embedding-3-small', dimensions=512, api_key=openai_api_key)  # 512 works as well\n",
        "\n",
        "  existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
        "\n",
        "  # loading from existing index\n",
        "  if index_name in pc.list_indexes().names():\n",
        "      print(f'Index {index_name} already exists. Loading embeddings ... ', end='')\n",
        "  else:\n",
        "      # creating the index and embedding the docs into the index\n",
        "      print(f'Creating index {index_name} and embeddings ...', end='')\n",
        "\n",
        "      # creating a new index\n",
        "      pc.create_index(\n",
        "          name=index_name,\n",
        "          dimension=512,\n",
        "          metric='cosine',\n",
        "          # spec=PodSpec(environment='gcp-starter')\n",
        "          spec=ServerlessSpec(\n",
        "              cloud=\"aws\",\n",
        "              region=\"us-east-1\"\n",
        "          )\n",
        "      )\n",
        "\n",
        "      print(\"index created....\")\n",
        "\n",
        "  # processing the input documents, generating embeddings using the provided `OpenAIEmbeddings` instance,\n",
        "  # inserting the embeddings into the index and returning a new Pinecone vector store object.\n",
        "  index = pc.Index(index_name)\n",
        "  vector_store = PineconeVectorStore(index=index, embedding=embeddings) # Initialize with the index and embedding\n",
        "  uuids = [str(uuid4()) for _ in range(len(docs))]\n",
        "  vector_store.add_documents(docs, ids=uuids)\n",
        "  print('Ok')\n",
        "  return vector_store"
      ],
      "metadata": {
        "id": "HV0CGE9YvOiH"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_pinecone_index(index_name='all'):\n",
        "    import pinecone\n",
        "    pc = pinecone.Pinecone(api_key=pc_apikey)\n",
        "\n",
        "    if index_name == 'all':\n",
        "        indexes = pc.list_indexes().names()\n",
        "        print('Deleting all indexes ... ')\n",
        "        for index in indexes:\n",
        "            pc.delete_index(index)\n",
        "        print('Ok')\n",
        "    else:\n",
        "        print(f'Deleting index {index_name} ...', end='')\n",
        "        pc.delete_index(index_name)\n",
        "        print('Ok')\n"
      ],
      "metadata": {
        "id": "Kt1txsO60x6P"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "quuV79MiCipe"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_pinecone_index()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGxMUxXdATzg",
        "outputId": "e81d304c-afef-44bb-b4ea-5ac6488a6996"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting all indexes ... \n",
            "Ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IPlZVYBsDnFq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_document('/content/KR-reasoning-LLM-framework.pdf')\n",
        "print(f'Length of data {len(data)}')\n",
        "chunks = chunk_data(data)\n",
        "print(f'Length of data {len(chunks)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa6WZtP37NIF",
        "outputId": "f28e4361-bac2-4079-afc0-de9f96bb60d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/KR-reasoning-LLM-framework - .pdf\n",
            "Loading /content/KR-reasoning-LLM-framework.pdf\n",
            "Length of data 24\n",
            "Length of data 415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import Document\n",
        "\n",
        "def convert_chunks_to_documents(chunks, metadata=None):\n",
        "    \"\"\"\n",
        "    Converts chunks into a list of Document objects with metadata.\n",
        "\n",
        "    Args:\n",
        "    - chunks: List of chunks (list of strings or objects with `page_content`).\n",
        "    - metadata: A dictionary containing metadata to attach to each document.\n",
        "\n",
        "    Returns:\n",
        "    - List of Document objects.\n",
        "    \"\"\"\n",
        "    documents = []\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        content = chunk.page_content if hasattr(chunk, 'page_content') else chunk\n",
        "        doc_metadata = metadata.copy() if metadata else {}\n",
        "        doc_metadata['chunk_index'] = i  # Add chunk-specific metadata\n",
        "        documents.append(Document(page_content=content, metadata=doc_metadata))\n",
        "    return documents\n",
        "\n",
        "# Example usage:\n",
        "# Assuming `chunks` is the list of text chunks\n",
        "metadata = {'source': 'KR-reasoning-LLM-framework.pdf'}\n",
        "documents = convert_chunks_to_documents(chunks, metadata)\n",
        "\n",
        "# Print the resulting Document objects\n",
        "for doc in documents:\n",
        "    print(doc)\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "i7LaXjuWespb",
        "outputId": "1972bc56-63d2-4531-91b1-11dc6fd61355"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='K-Level Reasoning: Establishing Higher Order Beliefs\n",
            "in Large Language Models for Strategic Reasoning\n",
            "Yadong Zhang1,2,*, Shaoguang Mao2,†, Tao Ge2, Xun Wang2,\n",
            "Yan Xia2, Man Lan1, Furu Wei2,\n",
            "1East China Normal University, 2Microsoft Research Asia\n",
            "Abstract' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 0}\n",
            "--------------------------------------------------\n",
            "page_content='Strategic reasoning is a complex yet essential\n",
            "capability for intelligent agents. It requires\n",
            "Large Language Model (LLM) agents to adapt\n",
            "their strategies dynamically in multi-agent en-\n",
            "vironments. Unlike static reasoning tasks, suc-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 1}\n",
            "--------------------------------------------------\n",
            "page_content='cess in these contexts depends on anticipating\n",
            "other agents’ beliefs and actions while contin-\n",
            "uously adjusting strategies to achieve individ-\n",
            "ual goals. LLMs and LLM agents often strug-\n",
            "gle with strategic reasoning due to the absence' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 2}\n",
            "--------------------------------------------------\n",
            "page_content='of a reasoning framework that enables them\n",
            "to dynamically infer others’ perspectives and\n",
            "adapt to changing environments. Inspired by\n",
            "the Level-K framework1 from game theory and\n",
            "behavioral economics, which extends reason-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 3}\n",
            "--------------------------------------------------\n",
            "page_content='ing from simple reactions to structured strate-\n",
            "gic depth, we propose a novel framework: \"K-\n",
            "Level Reasoning with Large Language Mod-\n",
            "els (K-R).\" This framework employs recursive\n",
            "mechanisms to enable LLMs to achieve vary-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 4}\n",
            "--------------------------------------------------\n",
            "page_content='ing levels of strategic depth, allowing agents to\n",
            "form higher order beliefs—beliefs about others’\n",
            "beliefs. We validate this framework through\n",
            "rigorous testing on four testbeds: two classi-\n",
            "cal game theory problems and two social in-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 5}\n",
            "--------------------------------------------------\n",
            "page_content='telligence tasks. The results demonstrate the\n",
            "advantages of K-R in strategic reasoning. Our\n",
            "work presents the first recursive implementa-\n",
            "tion of strategic depth in large language models\n",
            "(LLMs). It establishes a foundation for future' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 6}\n",
            "--------------------------------------------------\n",
            "page_content='research into theory of mind and strategic rea-\n",
            "soning in LLMs.\n",
            "1 Introduction\n",
            "Strategic reasoning—decision-making in multi-\n",
            "participant environments—presents unique chal-\n",
            "lenges for Large Language Models (LLMs) and' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 7}\n",
            "--------------------------------------------------\n",
            "page_content='LLM agents(Zhang et al., 2024b). In these settings,\n",
            "*Work was done when interning at Microsoft Research\n",
            "Asia. † Correspondence to: shaoguang.mao@microsoft.com\n",
            "1According to the Level-k Framework, k-level thinking' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 8}\n",
            "--------------------------------------------------\n",
            "page_content='involves considering what opponent/partner are likely to do,\n",
            "what they think you will do, and what they believe you think\n",
            "they will do, and so on.\n",
            "First-level Thinking Second-level Thinking\n",
            "…\n",
            "Third-level Thinking\n",
            "……' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 9}\n",
            "--------------------------------------------------\n",
            "page_content='Figure 1: Level-K Framework: In first-level thinking,\n",
            "agents respond directly to the environment. In second-\n",
            "level thinking, agents consider the first-level thinking of\n",
            "others. This process continues iteratively, with agents' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 10}\n",
            "--------------------------------------------------\n",
            "page_content='forming higher order beliefs based on assumptions about\n",
            "others’ thoughts.\n",
            "agents must respond to the actions of others while\n",
            "adapting to dynamic environments. They also need\n",
            "to align their decisions with their own goals during' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 11}\n",
            "--------------------------------------------------\n",
            "page_content='these interactions. Strategic reasoning is essential\n",
            "for intelligent agents and is widely applied in real-\n",
            "world tasks, such as investment, business strategy\n",
            "making(Zhao et al., 2023), negotiation(Hua et al.,\n",
            "2023), and policy-making(Li et al., 2024).' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 12}\n",
            "--------------------------------------------------\n",
            "page_content='Effective strategic reasoning relies on under-\n",
            "standing others’ perspectives and anticipating their\n",
            "strategies. While there are some research efforts on\n",
            "LLMs’ strategic reasoning, most methods rely on\n",
            "static prompting (Fu et al., 2023; Xu et al., 2023b).' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 13}\n",
            "--------------------------------------------------\n",
            "page_content='This typically involves instructing the model to ac-\n",
            "count for others’ beliefs and decisions during its\n",
            "own decision-making process in the prompt. How-\n",
            "ever, these approaches fall short in enabling LLMs\n",
            "to form true higher order beliefs—beliefs about' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 14}\n",
            "--------------------------------------------------\n",
            "page_content='what others believe, and lack the flexibility needed\n",
            "for deeper strategic reasoning.\n",
            "K-level thinking (Figure 1) (Nagel, 1995; Cui\n",
            "et al., 2021), a classical concept in behavioral eco-\n",
            "nomics and game theory, categorizes reasoning into' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 15}\n",
            "--------------------------------------------------\n",
            "page_content='varying depths of strategic thought. It involves not\n",
            "only predicting others’ actions but also considering\n",
            "1\n",
            "arXiv:2402.01521v2  [cs.CL]  17 Oct 2024' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 16}\n",
            "--------------------------------------------------\n",
            "page_content='Please choose an integer between 1 and 100. The player \n",
            "whose chosen number is closest to 0.8 * the average of all \n",
            "chosen numbers wins the round. Let's start the 1st round.\n",
            "I think in the\n",
            "1st  round …\n",
            " …\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 17}\n",
            "--------------------------------------------------\n",
            "page_content='(40 + 50 + 34 + 40 + 36) / 5 = 40  (Average)\n",
            "40 * 0.8 = 32 (Target) \n",
            "The daily available water can meet the needs of only one \n",
            "resident. An auction is conducted, and the highest bidder \n",
            "will obtain today's water supply.\n",
            "$55\n",
            "$100\n",
            "8 1\n",
            "$60\n",
            "$ 100\n",
            "$50\n",
            "$ 100' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 18}\n",
            "--------------------------------------------------\n",
            "page_content='$70\n",
            "$ 100\n",
            "$30\n",
            "$ 100\n",
            "In today’s bidding,        placed the highest bid of $70, \n",
            "securing the water resources for the day.        +2     and \n",
            "resets the number of days thirsty =0 . Other residents \n",
            "have their HP deducted based on the number of days they' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 19}\n",
            "--------------------------------------------------\n",
            "page_content='have been thirsty （ = - ）. \n",
            "A new day! All residents receive a daily salary of  $100. \n",
            "Today, the daily available water can meet the needs of only \n",
            "one resident ...\n",
            "Today I will bid \n",
            "$40 because …\n",
            "8 1\n",
            " 8 1\n",
            " 8 1\n",
            " 8 1\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "$90\n",
            "$200\n",
            "7 2\n",
            "$80\n",
            "$ 200' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 20}\n",
            "--------------------------------------------------\n",
            "page_content='$100\n",
            "$ 200\n",
            "$50\n",
            "$ 130\n",
            "$80\n",
            "$ 200\n",
            "In yesterday, \n",
            "  ………\n",
            "7 2\n",
            " 7 2\n",
            " 10 1\n",
            " 7 2\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "Guessing 0.8 of the Average Survival Auction Game\n",
            "40 50 34 40 36\n",
            "Let's start the 2nd round.\n",
            "In last \n",
            "round …\n",
            " …\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "…\n",
            "31 36 24 25 21\n",
            "Closest to the target.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 21}\n",
            "--------------------------------------------------\n",
            "page_content='40-32=8 50-32=18 34-32=2 40-32=8 36-32=4\n",
            "Private Utilities\n",
            "Private Utilities\n",
            "5\n",
            " 0 8\n",
            "We have 5         , 5       , and 5        . \n",
            "Please negotiate how to distribute \n",
            "them.\n",
            "7\n",
            " 2 1\n",
            "I want more        , as a result, I can \n",
            "accept less       , so I propose …' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 22}\n",
            "--------------------------------------------------\n",
            "page_content='I propose …\n",
            "Agreement achieved. \n",
            "      has 4      , 4        , and 0        , \n",
            "while     has 1       , 1       , and 5      . \n",
            "The total utilities:  \n",
            "     :36,      : 45.          wins!\n",
            "Negotiation' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 23}\n",
            "--------------------------------------------------\n",
            "page_content='Figure 2: The illustration of three reasoning problems in dynamic, interactive environments in this paper. Left:\n",
            "Guessing 0.8 of the Average; Middle: Survival Auction Game; Right: Negotiation.\n",
            "their beliefs about one’s actions, and even further' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 24}\n",
            "--------------------------------------------------\n",
            "page_content='layers of recursive thinking.\n",
            "Inspired by K-level thinking, we propose a novel\n",
            "strategic reasoning framework termed \"K-Level\n",
            "Reasoning with LLMs (K-R).\" K-R organizes rea-\n",
            "soning into hierarchical levels and employs a recur-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 25}\n",
            "--------------------------------------------------\n",
            "page_content='sive mechanism to integrate varying strategic depth\n",
            "into decision-making. Specifically, it involves: 1)\n",
            "recursively anticipating others’ actions at varying\n",
            "levels of strategic depth with environmental context' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 26}\n",
            "--------------------------------------------------\n",
            "page_content='and historical public information, and 2) reason-\n",
            "ing the optimal action based on these anticipations.\n",
            "To the best of our knowledge, this is the first ap-\n",
            "proach to implementing varying levels of strategic\n",
            "depth in LLMs using a recursive mechanism and' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 27}\n",
            "--------------------------------------------------\n",
            "page_content='enables deeper reasoning in LLM agents through\n",
            "an algorithmic framework.\n",
            "We validate this framework through rigorous\n",
            "testing on four testbeds: two classical game theory\n",
            "problems and two social intelligence tasks. The' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 28}\n",
            "--------------------------------------------------\n",
            "page_content='game theory problems includes Guessing 0.8 of\n",
            "the Average (Figure 2 left) and Survival Auction\n",
            "Game (Mao et al., 2023) (Figure 2 middle). The\n",
            "social intelligence tasks includes Negotiation (Cao\n",
            "et al., 2018) (Figure 2 right) and SOTOPIA bench-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 29}\n",
            "--------------------------------------------------\n",
            "page_content='mark(Zhou et al., 2024). These settings serve as\n",
            "microcosms of the complex decision-making pro-\n",
            "cesses involved in strategic reasoning. Through\n",
            "extensive experiments, we demonstrate that our\n",
            "framework significantly outperforms existing rea-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 30}\n",
            "--------------------------------------------------\n",
            "page_content='soning methods and flexibly achieves varying lev-\n",
            "els of strategic depth. In addition to empirical evi-\n",
            "dence, we provide a theoretical analysis highlight-\n",
            "ing the benefits of K-R. We show that, leveraging\n",
            "the in-context learning capabilities of LLMs, K-R' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 31}\n",
            "--------------------------------------------------\n",
            "page_content='can effectively model opponents’ behavior using\n",
            "accumulated public and available opponent infor-\n",
            "mation.\n",
            "Furthermore, we align the strategic depth of\n",
            "LLMs with human participants (Nagel, 1995;\n",
            "Bosch-Domenech et al., 2002). Using human as' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 32}\n",
            "--------------------------------------------------\n",
            "page_content='anchors, we observe that the K-R significantly en-\n",
            "hances the strategic depth of LLMs from 0.25 to\n",
            "1.89. Notably, when K=3, the strategic depth (1.89)\n",
            "of the LLM closely approaches that of financial\n",
            "newspaper readers (1.91). This strongly indicates' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 33}\n",
            "--------------------------------------------------\n",
            "page_content='that K-R establishes higher order beliefs in LLMs\n",
            "for strategic reasoning.\n",
            "The contributions of this work are as follows:\n",
            "• We introduce K-R, a novel framework that\n",
            "extends k-level thinking to LLMs, enabling\n",
            "flexible strategic reasoning at varying depths' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 34}\n",
            "--------------------------------------------------\n",
            "page_content='through a recursive mechanism.\n",
            "• We conduct extensive evaluations, including\n",
            "game theory and social intelligence problems,\n",
            "demonstrating that K-R significantly outper-\n",
            "forms existing methods in terms of flexibility' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 35}\n",
            "--------------------------------------------------\n",
            "page_content='and effectiveness, across both closed-source\n",
            "and open-source models.\n",
            "• We provide an in-depth analysis of K-R, con-\n",
            "firming its ability to build higher order beliefs\n",
            "and enhance strategic reasoning. This lays\n",
            "a foundation for future research in theory of' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 36}\n",
            "--------------------------------------------------\n",
            "page_content='mind and strategic reasoning in LLMs.\n",
            "2 K-Level Reasoning with Large\n",
            "Language Models\n",
            "2.1 Methodology\n",
            "Strategic reasoning requires considering both the\n",
            "decision context and the possible actions of other\n",
            "2' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 37}\n",
            "--------------------------------------------------\n",
            "page_content='participants.We employ a multi-round normal form\n",
            "multi-participant game to introduce the proposed\n",
            "method. In this setting, an agent’s decision-making\n",
            "process is formalized as follows: each agent i se-\n",
            "lects an action at\n",
            "i from a set At\n",
            "i at timestep t. The' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 38}\n",
            "--------------------------------------------------\n",
            "page_content='payoff for agent i, resulting from the collective ac-\n",
            "tion profile At = (at\n",
            "1, at\n",
            "2, ..., at\n",
            "N ) and environment\n",
            "Et, is denoted as Ui(Et, At).\n",
            "At k = 1, agents decide based on environment\n",
            "Et without strategic anticipation:\n",
            "at,1\n",
            "i = arg max\n",
            "ai∈At\n",
            "i' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 39}\n",
            "--------------------------------------------------\n",
            "page_content='E[Ui(Et, ai)] (1)\n",
            "At higher level thinking (k ≥ 2), agent i simulates\n",
            "other agents operating at level k − 1 and adjusts\n",
            "their strategy accordingly2:\n",
            "at,k\n",
            "i = arg max\n",
            "ai∈At\n",
            "i\n",
            "E[Ui(Et, ai, ˆat,k−1\n",
            "−i )] (2)\n",
            "where ˆat,k−1' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 40}\n",
            "--------------------------------------------------\n",
            "page_content='−i are the predicted actions of other\n",
            "agents based on their k − 1 level reasoning.\n",
            "We propose a novel strategic reasoning frame-\n",
            "work with recursive mechanisms , termed “K-\n",
            "Level Reasoning with Large Language Models' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 41}\n",
            "--------------------------------------------------\n",
            "page_content='(K-R),” involving 1) recursively anticipating the\n",
            "actions ˆat,k\n",
            "−i of others at different thinking levels\n",
            "using environment contexts and historical public\n",
            "information, followed by 2) reasoning the optimal\n",
            "action at,k' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 42}\n",
            "--------------------------------------------------\n",
            "page_content='i based on anticipation of others’ actions.\n",
            "The K-Level Reasoning process is formulated as\n",
            "follows:\n",
            "1) Anticipation:\n",
            "ˆat,m\n",
            "j =\n",
            "(\n",
            "LLM(Et, Ht\n",
            "j) if m = 1\n",
            "LLM(Et, Ht\n",
            "j, ˆat,m−1\n",
            "−j ) if m >1 (3)\n",
            "where Ht\n",
            "j = {(E1, a1\n",
            "j ), (E2, a2\n",
            "j ), ...,(Et−1, at−1\n",
            "j )}' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 43}\n",
            "--------------------------------------------------\n",
            "page_content='represents public historical data of agent j, and m\n",
            "denotes the specified thinking level.\n",
            "2) Reasoning:\n",
            "at,k\n",
            "i = LLM(Et, Ht\n",
            "i , ˆat,k−1\n",
            "−i ) (4)\n",
            "Algorithm 1 outlines the implementation of K-R.\n",
            "This recursive method enables flexible and progres-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 44}\n",
            "--------------------------------------------------\n",
            "page_content='sively deeper strategic reasoning ( 1, 2, ..., k, k+\n",
            "1, ...), thereby enhancing higher order belief in\n",
            "LLM agents.\n",
            "2 To simplify the formulation, we assume that all oppo-\n",
            "nents are in the same thinking level. In practice, varying' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 45}\n",
            "--------------------------------------------------\n",
            "page_content='thinking level can be implemented.\n",
            "Algorithm 1 K-Level Reasoning with LLMs\n",
            "Require: Et: Current decision context at time t;\n",
            "Ht\n",
            "i : Historical information up to time t for\n",
            "agent i;\n",
            "K: Depth of strategic reasoning;\n",
            "Ensure: at,K' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 46}\n",
            "--------------------------------------------------\n",
            "page_content='i : Action for agent i at time t after\n",
            "K-level reasoning.\n",
            "1: Function K_REASONING(i, k):\n",
            "2: if k == 1then\n",
            "3: return LLM(Et, Ht\n",
            "i )\n",
            "4: else\n",
            "5: for each agent j ̸= i do\n",
            "6: ˆat,k−1\n",
            "j = K_REASONING(j, k− 1)\n",
            "7: end for\n",
            "8: return LLM(Et, Ht\n",
            "i , {ˆat,k−1' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 47}\n",
            "--------------------------------------------------\n",
            "page_content='j | j ̸= i})\n",
            "9: end if\n",
            "10: at,K\n",
            "i = K_REASONING(i, K)\n",
            "11: return at,K\n",
            "i\n",
            "2.2 Theoretical Analysis\n",
            "This section discusses the benefits from K-R from\n",
            "a theoretical perspective. We utilize the in-context\n",
            "learning capabilities of LLMs to effectively model' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 48}\n",
            "--------------------------------------------------\n",
            "page_content='opponents’ behavior. Suppose agent j’s decision-\n",
            "making process follows a hidden strategy θ∗\n",
            "j . Thus,\n",
            "agent j’s decision-making can be expressed as:\n",
            "P(at\n",
            "j | Et, θ∗\n",
            "j ) (5)\n",
            "The in-context learning of LLMs can be formally' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 49}\n",
            "--------------------------------------------------\n",
            "page_content='defined as implicit Bayesian inference(Xie et al.,\n",
            "2021); therefore, given the environment Et, the\n",
            "next action prediction conditioned on Ht\n",
            "j is:\n",
            "P(at\n",
            "j | Et, Ht\n",
            "j) =\n",
            "Z\n",
            "P(at\n",
            "j | Et, θj)P(θj | Ht\n",
            "j)dθj\n",
            "(6)\n",
            "As t → ∞, by the law of large numbers and proper-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 50}\n",
            "--------------------------------------------------\n",
            "page_content='ties of Bayesian updating, the posterior distribution\n",
            "concentrates around the true parameter θ∗\n",
            "j :\n",
            "P(θj | Ht\n",
            "j) → δ(θj − θ∗\n",
            "j ) (7)\n",
            "where δ is the Dirac delta function. Therefore,\n",
            "Z\n",
            "P(at\n",
            "j | Et, θj)P(θj | Ht\n",
            "j)dθj → P(at\n",
            "j | Et, θ∗\n",
            "j )\n",
            "(8)' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 51}\n",
            "--------------------------------------------------\n",
            "page_content='This implies that as the number of interactions\n",
            "increases, K-R can more accurately predict oppo-\n",
            "nents’ behavior.\n",
            "It is also worth noting that interaction data can-\n",
            "not be infinite, and in-context learning is related to\n",
            "3' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 52}\n",
            "--------------------------------------------------\n",
            "page_content='the performance of large language models (LLMs).\n",
            "Therefore, we empircally validate these hypotheses\n",
            "and reasoning in Section 5.2.\n",
            "3 Experiments: Game Theory\n",
            "To fairly compare the strategic reasoning capabili-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 53}\n",
            "--------------------------------------------------\n",
            "page_content='ties of LLMs, we first adopt two widely used game\n",
            "theory settings. These controlled, well-defined\n",
            "game theory problems provide a robust assessment\n",
            "of LLMs’ performance, with detailed setups out-\n",
            "lined in Appendix B.\n",
            "3.1 Task Definition and Metrics' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 54}\n",
            "--------------------------------------------------\n",
            "page_content='3.1.1 Guessing 0.8 of the Average (G0.8A)\n",
            "G0.8A (Figure 2 Left) is a classic game theory\n",
            "problem introduced by Alain Ledoux (Ledoux,\n",
            "1981). It involves 10-round games where each\n",
            "player selects a number between 1 and 100. The' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 55}\n",
            "--------------------------------------------------\n",
            "page_content='objective is to choose a number closest to 80% of\n",
            "the group’s average choice. The key idea is to guess\n",
            "how others will estimate the average and decide the\n",
            "number to submit. This concept is also illustrated\n",
            "in the Keynesian Beauty Contest (Keynes, 1936).' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 56}\n",
            "--------------------------------------------------\n",
            "page_content='This game mirrors the challenge of anticipating\n",
            "collective behavior in financial markets, where in-\n",
            "vestors must predict not only the value of an asset\n",
            "but also how others will value it in the future.\n",
            "The performance of the agent is evaluated using' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 57}\n",
            "--------------------------------------------------\n",
            "page_content='the Win Rate. Specifically, the Win Rate is calcu-\n",
            "lated based on the wins achieved by the agent in in-\n",
            "dividual round, rather than an entire game episode.\n",
            "3.1.2 Survival Auction Game (SAG)\n",
            "SAG (Figure 2 Middle) is derived from the Wa-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 58}\n",
            "--------------------------------------------------\n",
            "page_content='ter Allocation Challenge proposed in (Mao et al.,\n",
            "2023). Each resident’s goal is to survive a 10-day\n",
            "drought period by bidding for water resources and\n",
            "maintaining health points above zero. If a player\n",
            "successfully bids for water, they gain health points;' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 59}\n",
            "--------------------------------------------------\n",
            "page_content='otherwise, they lose health points. This integration\n",
            "of the auction system with the health points mecha-\n",
            "nism creates a dynamic environment where players\n",
            "must balance health and finances.\n",
            "We use Average Survival Roundmeasures the' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 60}\n",
            "--------------------------------------------------\n",
            "page_content='mean round in which a player remains active in the\n",
            "game.\n",
            "3.2 Base Techniques\n",
            "We adapt a variety of approaches, originally from\n",
            "traditional reasoning and agent benchmarks. These\n",
            "base techniques include:\n",
            "Standard Prompting (Direct): This is the con-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 61}\n",
            "--------------------------------------------------\n",
            "page_content='ventional prompting method in which the LLM\n",
            "generates the final answer (Action) in response to\n",
            "the given game setting prompt.\n",
            "Chain-of-Thought (CoT) (Wei et al., 2022): We\n",
            "employ the zero-shot Chain-of-Thought reasoning\n",
            "method (Kojima et al., 2022).' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 62}\n",
            "--------------------------------------------------\n",
            "page_content='Persona Prompting (Persona) (Deshpande\n",
            "et al., 2023): This technique modifies the standard\n",
            "prompting process by incorporating a “Game Ex-\n",
            "pert” persona to enhance the reasoning capabilities\n",
            "of the LLM.\n",
            "Reflexion (Reflect) (Shinn et al., 2023): This' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 63}\n",
            "--------------------------------------------------\n",
            "page_content='method refers to language agents with verbal rein-\n",
            "forcement learning and has been adapted for dy-\n",
            "namic tasks. Detailed modifications are explained\n",
            "in K.\n",
            "Self-Refine (Refine) (Madaan et al., 2023): This\n",
            "is a multi-round iterative reasoning approach where' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 64}\n",
            "--------------------------------------------------\n",
            "page_content='an additional LLM offers comments and adjust-\n",
            "ments prior to reaching a final decision. The dis-\n",
            "tinctions between Self-Refine and Reflect are elab-\n",
            "orated upon in the Appendix I.\n",
            "Prediction Chain of Thought (PCoT) : This' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 65}\n",
            "--------------------------------------------------\n",
            "page_content='strong baseline diverges from CoT by requiring the\n",
            "LLM to explicitly predict opponents’ actions be-\n",
            "fore making decisions. Unlike K-Level Reasoning,\n",
            "which involves a recursive approach, PCoT focuses\n",
            "on direct prediction based on context.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 66}\n",
            "--------------------------------------------------\n",
            "page_content='For implementation details and specific exam-\n",
            "ples, please refer to Appendix K.\n",
            "3.3 Experimental Settings\n",
            "We established a controllable environment and dis-\n",
            "tinguished between two roles: the player (primary\n",
            "focus) and the opponents. The player is equipped' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 67}\n",
            "--------------------------------------------------\n",
            "page_content='with a specific method, while all opponents use\n",
            "another reasoning approach. This well-defined set-\n",
            "ting allows for a clearer comparison of reasoning\n",
            "capabilities between methods.\n",
            "In G0.8A and SAG, there is one player and four' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 68}\n",
            "--------------------------------------------------\n",
            "page_content='opponents for each game. Experiments for each\n",
            "setting are repeated 10 times and have passed the\n",
            "significance test (Appendix H), and each experi-\n",
            "ment consists of a 10-round game.\n",
            "All methods in main experiments were imple-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 69}\n",
            "--------------------------------------------------\n",
            "page_content='mented using GPT-4 (Achiam et al., 2023) (gpt4-\n",
            "32k), with the temperature set at 0.7 and the top-p\n",
            "set at 0.9. We also conducted experiments with\n",
            "open-source LLMs, Details of which are provided\n",
            "in Appendix E. Unless specified otherwise, the\n",
            "4' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 70}\n",
            "--------------------------------------------------\n",
            "page_content='level of thinking in K-Level Reasoning is set to\n",
            "K=2.\n",
            "3.4 Results\n",
            "To distinguish between “Player” and “Opponent”\n",
            "in the table, the headers for Player (bold) and Op-\n",
            "ponents (italics) are formatted accordingly.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 71}\n",
            "--------------------------------------------------\n",
            "page_content='Table 1: Win Rate of the player against different oppo-\n",
            "nents in G0.8A game.\n",
            "Direct CoT Persona Reflect Refine PCoT K-R\n",
            "Direct 0.43 0.67 0.62 0.53 0.43 0.61 0.82\n",
            "CoT 0.07 0.32 0.35 0.14 0.22 0.45 0.63\n",
            "Persona0.05 0.37 0.29 0.05 0.37 0.11 0.46' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 72}\n",
            "--------------------------------------------------\n",
            "page_content='Reflect 0.42 0.68 0.63 0.39 0.64 0.74 0.78\n",
            "Refine 0.10 0.34 0.32 0.31 0.23 0.22 0.46\n",
            "PCoT 0.03 0.44 0.52 0.21 0.51 0.54 0.85\n",
            "K-R 0.04 0.15 0.14 0.04 0.17 0.14 0.52\n",
            "Average0.16\n",
            "± 0.18\n",
            "0.32\n",
            "± 0.19\n",
            "0.41\n",
            "± 0.18\n",
            "0.24\n",
            "± 0.18\n",
            "0.37\n",
            "± 0.17\n",
            "0.40\n",
            "± 0.25\n",
            "0.65\n",
            "± 0.17' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 73}\n",
            "--------------------------------------------------\n",
            "page_content='Table 2: Average Survival Round of the player against\n",
            "different opponents in Survival Auction Game.\n",
            "Direct CoT Persona Reflect Refine PCoT K-R\n",
            "Direct 5.90 7.00 7.50 4.70 8.70 6.60 9.40\n",
            "CoT 5.70 6.50 5.30 4.00 8.10 5.30 10.00' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 74}\n",
            "--------------------------------------------------\n",
            "page_content='Persona5.70 7.70 7.40 5.20 6.30 7.20 9.30\n",
            "Reflect 9.40 9.40 9.90 5.20 8.60 8.20 10.00\n",
            "Refine 6.30 6.40 8.10 4.30 8.20 5.30 7.90\n",
            "PCoT 8.50 9.60 9.90 6.30 8.50 6.20 9.70\n",
            "K-R 4.10 5.50 5.00 4.04 5.70 4.40 6.80\n",
            "Average6.51\n",
            "± 1.82\n",
            "7.44\n",
            "± 1.55\n",
            "7.59\n",
            "± 1.95\n",
            "4.82' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 75}\n",
            "--------------------------------------------------\n",
            "page_content='± 0.82\n",
            "7.73\n",
            "± 1.21\n",
            "6.17\n",
            "± 1.29\n",
            "9.01\n",
            "± 1.21\n",
            "Table 1 presents Win Rate of players utilizing\n",
            "different methods against various opponents in the\n",
            "G0.8A game. Notably, the K-R method demon-\n",
            "strates a superior Win Rate of 0.65, significantly' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 76}\n",
            "--------------------------------------------------\n",
            "page_content='exceeding the win rates of the other strategies. Ta-\n",
            "ble 2 provides insights into the Average Survival\n",
            "Round of players across different auction game\n",
            "strategies in SAG, with the K-R method again\n",
            "standing out. The K-R method achieves an av-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 77}\n",
            "--------------------------------------------------\n",
            "page_content='erage survival round of 9.01, considerably higher\n",
            "than all other methods.\n",
            "The experiment result underscores the effective-\n",
            "ness of the K-R method in enhancing player strat-\n",
            "egy, suggesting its strategic superiority in the con-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 78}\n",
            "--------------------------------------------------\n",
            "page_content='text of this game. Its effectiveness lies in its ability\n",
            "to anticipate opponent moves, outperforming other\n",
            "prompting methods.\n",
            "The performance of Reflect did not demonstrate\n",
            "the effectiveness of the reasoning method. We hy-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 79}\n",
            "--------------------------------------------------\n",
            "page_content='pothesize that this is due to the fact that, in dynamic\n",
            "environments, Reflect on the experiences summa-\n",
            "rized from the previous round (Shinn et al., 2023)\n",
            "may not be applicable to the subsequent round of\n",
            "the game. Furthermore, in both games, Refine did' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 80}\n",
            "--------------------------------------------------\n",
            "page_content='not show an advantage over CoT and was signif-\n",
            "icantly lower than K-R. This is because Refine\n",
            "involves adjustments based on one’sown strategy.\n",
            "However, these adjustments do not explicitly con-\n",
            "sider the hidden strategies of the opponent’s behav-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 81}\n",
            "--------------------------------------------------\n",
            "page_content='ior, rendering them inapplicable against opponents\n",
            "employing different strategies.\n",
            "4 Experiments: Social Intelligence\n",
            "We then evaluate K-R in two social intelligence\n",
            "benchmarks to assess its performance in more open-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 82}\n",
            "--------------------------------------------------\n",
            "page_content='ended realistic scenarios. Compared to the abstract\n",
            "and theoretical settings of Game Theory, these sce-\n",
            "narios involve richer contextual backgrounds and\n",
            "complicated goal pursuits, which better demon-\n",
            "strate the value of LLM-based agents in practical' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 83}\n",
            "--------------------------------------------------\n",
            "page_content='applications, such as in chatbots and strategic deci-\n",
            "sion making.\n",
            "4.1 Task Definition and Metrics\n",
            "4.1.1 Negotiation (NEG)\n",
            "NEG (Figure 2 Right)(Cao et al., 2018; Duan et al.,\n",
            "2024) is an open-ended and realistic task. In this' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 84}\n",
            "--------------------------------------------------\n",
            "page_content='setting, two agents are presented with three types\n",
            "of items: peppers, cherries, and strawberries. Each\n",
            "agent has private utility values for these items and\n",
            "must negotiate to allocate the public item pool.\n",
            "The agent who secures more utility upon reach-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 85}\n",
            "--------------------------------------------------\n",
            "page_content='ing an agreement wins the game, and we calculated\n",
            "the Win Rate to assess the performance of different\n",
            "agents.\n",
            "4.1.2 SOTOPIA Benchmark\n",
            "SOTOPIA (Zhou et al., 2024) is an open-ended en-\n",
            "vironment to simulate complex social interactions' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 86}\n",
            "--------------------------------------------------\n",
            "page_content='between artificial agents and evaluate their social in-\n",
            "telligence. It includes a variety of social scenarios,\n",
            "and each scenario includes a context background,\n",
            "and private social goals of each agent. Meanwhile,' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 87}\n",
            "--------------------------------------------------\n",
            "page_content='each agent has a character profiles which consists\n",
            "of name, gender, personality, occupation, etc.\n",
            "For each episode, agents are scored at the end\n",
            "of the interaction along each of seven dimensions\n",
            "in SOTOPIA-Eval, including Goal Completion' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 88}\n",
            "--------------------------------------------------\n",
            "page_content='(GOAL), Believability (BEL), Knowledge (KNO),\n",
            "Secret ( SEC), Relationship ( REL), Social Rules\n",
            "(SOC), Financial and Material Benefits (FIN).\n",
            "5' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 89}\n",
            "--------------------------------------------------\n",
            "page_content='4.2 Experimental Settings\n",
            "We employed the majority of the reasoning ap-\n",
            "proaches introduced in Section 3.2 as baseline mod-\n",
            "els for comparison.\n",
            "In NEG, the experiments followed the settings\n",
            "from (Cao et al., 2018; Duan et al., 2024). There is' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 90}\n",
            "--------------------------------------------------\n",
            "page_content='one player and one opponent for each game. We\n",
            "test the performance of the Baselines and K-Level\n",
            "Reasoning in 100 repeated independent games. To\n",
            "eliminate positional advantages, we swapped the\n",
            "positions of each player for each setting. To en-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 91}\n",
            "--------------------------------------------------\n",
            "page_content='sure the reliability, three trials were conducted, and\n",
            "the results are reported as averages with standard\n",
            "deviation.\n",
            "Meanwhile, We adhered to the SOTOPIA-hard\n",
            "(Zhou et al., 2024) setup comprising a total of 100' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 92}\n",
            "--------------------------------------------------\n",
            "page_content='episodes, which is commonly found to be challeng-\n",
            "ing for LLMs, and utilize a fixed GPT-4o based\n",
            "agent as partner. Additionally, to evaluate the\n",
            "agents’ scores, we utilized GPT-4 as the assessment\n",
            "model, as it has been determined by SOTOPIA' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 93}\n",
            "--------------------------------------------------\n",
            "page_content='benchmark (Zhou et al., 2024) to serve as a reliable\n",
            "serves as a proxy for human judgments in evalu-\n",
            "ating model performance across most dimensions\n",
            "and for human performance on the GOAL dimen-\n",
            "sion.\n",
            "4.3 Results' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 94}\n",
            "--------------------------------------------------\n",
            "page_content='Table 3: Win Rate of the player against opponent in\n",
            "Negotiation Setting.\n",
            "Direct CoT Persona Reflect Refine PCoT K-R\n",
            "Direct 50.00 61.34 49.58 66.67 65.83 63.03 70.83\n",
            "CoT 38.66 50.00 36.67 45.83 45.76 47.27 55.36' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 95}\n",
            "--------------------------------------------------\n",
            "page_content='Persona 50.42 63.33 50.00 70.00 67.50 62.50 70.83\n",
            "Reflection33.33 54.17 30.00 50.00 57.14 55.00 55.00\n",
            "Refine 34.17 54.24 32.50 42.86 50.00 55.77 54.55\n",
            "PCoT 36.97 52.73 37.50 45.00 44.23 50.00 57.00\n",
            "K-R 29.17 44.64 29.17 45.00 45.45 43.00 50.00' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 96}\n",
            "--------------------------------------------------\n",
            "page_content='Average38.96\n",
            "±2.53\n",
            "54.35\n",
            "±0.50\n",
            "37.92\n",
            "±5.84\n",
            "52.19\n",
            "±1.73\n",
            "53.70\n",
            "±4.41\n",
            "53.80\n",
            "±4.34\n",
            "59.08\n",
            "± 2.20\n",
            "The results presented in Table 3 and Table 4 il-\n",
            "lustrate the effectiveness of the K-Level Reasoning\n",
            "in the context of NEG and SOTOPIA-hard settings,\n",
            "respectively.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 97}\n",
            "--------------------------------------------------\n",
            "page_content='In NEG, the K-R method demonstrates a notable\n",
            "win rate of 59.08%, positioning it significantly\n",
            "above the average win rates achieved by other meth-\n",
            "ods. This indicates that, in most cases, the propos-\n",
            "als generated through K-Level Reasoning are more' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 98}\n",
            "--------------------------------------------------\n",
            "page_content='advantageous to itself, as well as suggesting a ten-\n",
            "dency to accept the opponent’s proposals when the\n",
            "Table 4: SOTOPIA-Eval of the player against opponent\n",
            "in SOTOPIA-hard.\n",
            "Direct CoT Refine K-R Direct CoT Refine K-R\n",
            "Metric [GPT-4o] [LLaMA-3.1-70B]' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 99}\n",
            "--------------------------------------------------\n",
            "page_content='BEL[0–10] 8.97 9.00 9.00 8.97 8.88 8.85 8.90 8.97\n",
            "REL[-5–5] 2.38 2.40 2.27 2.67 1.38 1.18 0.82 2.40\n",
            "KNO[0–10] 6.05 6.05 6.25 6.25 5.88 5.53 5.33 6.12\n",
            "SEC[-10-0] 0.00 -0.05 0.00 0.00 -0.28 -0.25 -0.180.00' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 100}\n",
            "--------------------------------------------------\n",
            "page_content='SOC[-10–0] -0.05 0.00 -0.05 0.00 -0.70 -0.72 -0.640.00\n",
            "FIN[-5–5] 0.90 0.78 0.80 0.72 0.38 0.35 -0.08 0.75\n",
            "GOAL[0–10] 6.356.60 6.15 6.47 5.35 5.40 4.95 6.38\n",
            "Overall 3.51\n",
            "± 0.09\n",
            "3.54\n",
            "± 0.08\n",
            "3.49\n",
            "± 0.08\n",
            "3.59\n",
            "± 0.09\n",
            "2.98\n",
            "± 0.23\n",
            "2.90\n",
            "± 0.26\n",
            "2.73\n",
            "± 0.25\n",
            "3.52' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 101}\n",
            "--------------------------------------------------\n",
            "page_content='± 0.13\n",
            "perceived benefits are substantial.\n",
            "The results from SOTOPIA reveal several in-\n",
            "triguing findings. Firstly, while K-R demonstrates\n",
            "some improvement compared to other methods, the\n",
            "results are not statistically significant. We hypothe-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 102}\n",
            "--------------------------------------------------\n",
            "page_content='size that this may be due to the inherent tendency\n",
            "of GPT-4 based models to assign higher scores to\n",
            "responses generated by GPT-4 based agents. No-\n",
            "tably, we observed that employing agents based on\n",
            "LLaMA 3.1 70B with K-R can lead to significant' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 103}\n",
            "--------------------------------------------------\n",
            "page_content='performance enhancements. Meanwhile, the over-\n",
            "all metrics indicate that K-R achieves performance\n",
            "levels comparable to those of the GPT-4 model,\n",
            "highlighting K-R’s potential in the realm of social\n",
            "intelligence.\n",
            "5 Discussions' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 104}\n",
            "--------------------------------------------------\n",
            "page_content='5.1 Does K-R Efficiently Establish a Higher\n",
            "Order Belief in LLMs?\n",
            "Table 5: Human performance in G2/3A.\n",
            "Experiments Lab Classroom Take-home TheoristsInternetNewsgroupNewspaper\n",
            "Mean Choice 35.13 26.84 25.20 17.15 22.16 23.08' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 105}\n",
            "--------------------------------------------------\n",
            "page_content='Strategic Depth 0.87 1.53 1.682.63 2.01 1.91\n",
            "Table 6: LLM performance in G0.8A in the first round.\n",
            "Method Direct CoT Persona Refine Reflect PCoT KR[k=2] KR[k=3]\n",
            "Mean Choice 47.29 37.8 41.0 41.0 45.2 44.0 38.42 32.79' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 106}\n",
            "--------------------------------------------------\n",
            "page_content='Strategic Depth 0.25 1.25 0.89 0.89 0.45 0.57 1.181.89\n",
            "As a classic game theory issue, the G0.8A\n",
            "problem has garnered significant research interest\n",
            "across various disciplines. We reference the exper-\n",
            "imental results of the classic research among hu-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 107}\n",
            "--------------------------------------------------\n",
            "page_content='man participants (Nagel, 1995; Bosch-Domenech\n",
            "et al., 2002) as anchor points and present the av-\n",
            "erage decisions made by the K-Level Reasoning\n",
            "method (GPT-4) in the first round. Through this\n",
            "6' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 108}\n",
            "--------------------------------------------------\n",
            "page_content='comparison, we can observe the relative relation-\n",
            "ship between human cognitive levels and LLMs\n",
            "under different reasoning methods. The specific\n",
            "calculation method on strategic depth is described\n",
            "in Appendix C. The performance of humans and' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 109}\n",
            "--------------------------------------------------\n",
            "page_content='LLMs is shown in the Table 5 and Table 6\n",
            "From these observations, we can conclude that\n",
            "even when employing SOTA models, the strategic\n",
            "depth of GPT-4 under Direct Prompt (0.25) cannot\n",
            "compete with that of lower-strategic-capability un-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 110}\n",
            "--------------------------------------------------\n",
            "page_content='dergraduate students in laboratory settings (0.87).\n",
            "Furthermore, the K-Level reasoning approach sig-\n",
            "nificantly enhances the reasoning depth of large\n",
            "language models, increasing it from 0.25 to 1.89,\n",
            "and the strategic depth of the large language model' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 111}\n",
            "--------------------------------------------------\n",
            "page_content='(1.89) approaches that of a group of financial news-\n",
            "paper readers (1.91) when K=3.\n",
            "5.2 K-Level Reasoning Leads to More\n",
            "Accurate Predictions About Opponents\n",
            "Round 2 Round 4 Round 6 Round 8 Round 10\n",
            "0\n",
            "5\n",
            "10\n",
            "15\n",
            "20Prediction Deviation\n",
            "K-R Prediction' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 112}\n",
            "--------------------------------------------------\n",
            "page_content='PCoT Prediction\n",
            "Figure 3: The deviation in prediction during the G0.8A\n",
            "between PCoT and K-Level Reasoning.\n",
            "Since K-R involves an intermediate step of mod-\n",
            "eling the opponent’s behavior, we examine the pro-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 113}\n",
            "--------------------------------------------------\n",
            "page_content='gression of prediction accuracy. Figure 3 illustrates\n",
            "the prediction deviation between K-R and PCoT\n",
            "in G0.8A. K-R exhibits higher prediction accuracy\n",
            "than PCoT from Round 1, starting with more pre-\n",
            "cise and less random predictions. Moreover, the' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 114}\n",
            "--------------------------------------------------\n",
            "page_content='predictions converge quickly and become highly\n",
            "accurate in the second half of the game. This trend\n",
            "highlights the LLM’s increasing proficiency in un-\n",
            "derstanding higher order belief with more game-\n",
            "play context. Essentially, K-R instantiates new' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 115}\n",
            "--------------------------------------------------\n",
            "page_content='sessions to compute the opponent’s future actions.\n",
            "This approach leverages the in-context learning ca-\n",
            "pabilities of LLMs more effectively than PCoT’s\n",
            "prediction process (as theoretically discussed in\n",
            "Section 2.2). As a result, K-R achieves better pre-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 116}\n",
            "--------------------------------------------------\n",
            "page_content='diction accuracy.\n",
            "5.3 Better Reasoning Methodology vs.\n",
            "Stronger Foundation Model\n",
            "There is a consensus that LLMs trained with more\n",
            "data and possessing larger parameter sizes demon-\n",
            "strate stronger reasoning capabilities. We explore' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 117}\n",
            "--------------------------------------------------\n",
            "page_content='whether K-Level Reasoning can significantly en-\n",
            "hance the strategic reasoning abilities of relatively\n",
            "weaker LLMs. To investigate, we conducted ex-\n",
            "periments comparing the performance of K-R with\n",
            "GPT-3.5 (K-R[GPT-3.5]) against other reasoning' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 118}\n",
            "--------------------------------------------------\n",
            "page_content='methods based on GPT-4. All experiments were\n",
            "repeated 10 times.\n",
            "Table 7: A comparison of K-Level Reasoning with GPT-\n",
            "3.5 and other reasoning approaches with GPT-4. For\n",
            "the Guessing 0.8 of the Average, we report the win rate;' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 119}\n",
            "--------------------------------------------------\n",
            "page_content='for the Survival Auction Game, we report the average\n",
            "survival round.\n",
            "Guessing 0.8 of the Average Survival Auction Game\n",
            "OpponentDirect K-R Direct K-R Direct K-R Direct K-R\n",
            "[GPT-4][GPT-3.5] [GPT-3.5] [GPT-4] [GPT-4] [GPT-3.5] [GPT-3.5] [GPT-4] [GPT-4]' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 120}\n",
            "--------------------------------------------------\n",
            "page_content='Direct 0.18 0.18 0.43 0.82 5.00 9.40 5.90 9.40\n",
            "CoT 0.14 0.37 0.07 0.63 5.30 8.10 5.7010.00\n",
            "Persona0.10 0.23 0.05 0.46 5.00 7.50 5.70 9.30\n",
            "Reflect 0.24 0.38 0.42 0.78 5.00 8.50 9.4010.00\n",
            "Refine 0.14 0.13 0.10 0.46 5.10 6.70 6.30 7.90' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 121}\n",
            "--------------------------------------------------\n",
            "page_content='PCoT 0.19 0.46 0.03 0.85 4.10 6.80 8.50 9.70\n",
            "Average0.16 0.29 0.18 0.67 4.92 7.83 6.92 9.38\n",
            "From the results in Table 7, we observe that K-\n",
            "R[GPT-3.5] outperforms the standard prompting\n",
            "method of GPT-4 (Direct[GPT4]) from average per-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 122}\n",
            "--------------------------------------------------\n",
            "page_content='formance. Furthermore, when competing against\n",
            "opponents using reasoning methods on GPT-4, K-\n",
            "R[GPT-3.5] demonstrates remarkable capabilities.\n",
            "K-R, with its excellent restoration of the rival’s\n",
            "perspective, enhances the LLM’s ability in compet-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 123}\n",
            "--------------------------------------------------\n",
            "page_content='itive environments. Additionally, we compared the\n",
            "performance of the open-source model LLAMA2-\n",
            "7B with GPT-3.5/4 in Appendix E, finding that\n",
            "K-R significantly enhances reasoning in interactive\n",
            "contexts across different LLMs.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 124}\n",
            "--------------------------------------------------\n",
            "page_content='5.4 The Deeper Thinking Level, the Better\n",
            "Strategic Performance?\n",
            "Table 8: Comparison between K-Level Reasoning[K=2]\n",
            "and K-Level Reasoning[K=3] in the two games.\n",
            "Guessing 0.8 of the Average Survival Auction Game' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 125}\n",
            "--------------------------------------------------\n",
            "page_content='OpponentDirect K-R[K=2] K-R[K=3] Direct K-R[K=2] K-R[K=3]\n",
            "Direct 0.43 0.82 0.77 (-0.05)5.90 9.40 9.40(+0.00)K-R[K=2]0.04 0.52 0.60(+0.08)4.10 6.80 8.30(+1.50)\n",
            "K-R models opponents’ thinking processes re-\n",
            "cursively. We examine how thinking level affect\n",
            "7' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 126}\n",
            "--------------------------------------------------\n",
            "page_content='reasoning outcomes by comparing K-R[K=2] and\n",
            "K-R[K=3] in two games. The results, detailed in Ta-\n",
            "ble 8, reveal the impact of increased thinking level.\n",
            "Against the Direct method (first-level thinking), K-\n",
            "R[K=3] showed a decreased win rate in G0.8A but' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 127}\n",
            "--------------------------------------------------\n",
            "page_content='maintained performance in SAG, suggesting pos-\n",
            "sible overthinking. However, K-R[K=3] improved\n",
            "significantly against K-R[K=2] in both games. It\n",
            "suggests that the key factor in K-R is the relative\n",
            "depth of thought compared to the opponent. A one-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 128}\n",
            "--------------------------------------------------\n",
            "page_content='level deeper approach offers a strategic advantage,\n",
            "but advancing two levels may lead to diminishing\n",
            "returns due to over-anticipation. In interactive en-\n",
            "vironments, identifying opponents’ thinking levels' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 129}\n",
            "--------------------------------------------------\n",
            "page_content='is difficult. Adapting to varying levels and using K-\n",
            "Level Reasoning for deeper analysis is a valuable\n",
            "direction for future research.\n",
            "Additionally, a higher thinking level with the re-\n",
            "cursive prompting implementation increases com-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 130}\n",
            "--------------------------------------------------\n",
            "page_content='putational cost. The computational cost of K-R is\n",
            "thoroughly discussed in Appendix G.\n",
            "6 Related Work\n",
            "6.1 Reasoning with LLMs\n",
            "Large Language Models (LLMs) excel in diverse\n",
            "complex reasoning tasks, such as mathematical' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 131}\n",
            "--------------------------------------------------\n",
            "page_content='(Miao et al., 2021; Patel et al., 2021), common\n",
            "sense (Talmor et al., 2022; Bhakthavatsalam et al.,\n",
            "2021), and symbolic reasoning (Srivastava et al.,\n",
            "2022; Suzgun et al., 2022). A notable reason-\n",
            "ing approach involves breaking down complex' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 132}\n",
            "--------------------------------------------------\n",
            "page_content='questions into a series of intermediate steps, a\n",
            "technique known as the Chain-of-Thought (CoT)\n",
            "method (Wei et al., 2022; Kojima et al., 2022).\n",
            "Subsequently, some works have emerged to ex-\n",
            "tend CoT, with innovations like Tree of Thought' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 133}\n",
            "--------------------------------------------------\n",
            "page_content='(ToT) (Yao et al., 2023), Graph of Thought (GoT)\n",
            "(Besta et al., 2023) and Skeleton-of-thought (Ning\n",
            "et al., 2023). Besides, approaches like Self-Refine\n",
            "(Madaan et al., 2023) and Reflexion (Shinn et al.,\n",
            "2023) enhance CoT’s consistency by having LLMs' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 134}\n",
            "--------------------------------------------------\n",
            "page_content='review and refine their responses. Moreover, recent\n",
            "research has revealed that integrating persona in-\n",
            "formation into LLMs significantly improves their\n",
            "reasoning processes (Deshpande et al., 2023). A\n",
            "series of studies (Fu et al., 2023; Wang et al., 2023)' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 135}\n",
            "--------------------------------------------------\n",
            "page_content='have been conducted to incorporate more persona\n",
            "information, aiming to enhance the rationality and\n",
            "knowledge ability of the LLM reasoning process.\n",
            "These methods have been applied to various static\n",
            "tasks, but have not been adequately evaluated in' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 136}\n",
            "--------------------------------------------------\n",
            "page_content='dynamic problems (multi-agent environment) to\n",
            "validate their efficacy in reasoning capabilities.\n",
            "6.2 Strategic Reasoning within Multiple\n",
            "Agent System\n",
            "Dynamic problems arise when multiple participants\n",
            "are involved in multi-round interactions. One key' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 137}\n",
            "--------------------------------------------------\n",
            "page_content='factor is the simultaneous interactions of multiple\n",
            "participants with the environment. Unlike single-\n",
            "agent systems, multiple agent system (MAS) en-\n",
            "counters a broader range of issues and challenges,\n",
            "as noted by (Wong et al., 2021), including compu-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 138}\n",
            "--------------------------------------------------\n",
            "page_content='tational complexity (Ding and Dong, 2020), nonsta-\n",
            "tionarity (Papoudakis et al., 2019), partial observ-\n",
            "ability (Mahajan et al., 2019; Foerster et al., 2016),\n",
            "and challenges in credit assignment (Sunehag et al.,' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 139}\n",
            "--------------------------------------------------\n",
            "page_content='2017). Particularly, in the context of inference us-\n",
            "ing LLMs, the nonstationarity of the environment\n",
            "poses a distinct challenge.\n",
            "Recently, research on LLMs in strategic reason-\n",
            "ing has been conducted across various MAS includ-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 140}\n",
            "--------------------------------------------------\n",
            "page_content='ing social behavior(Zhou et al., 2024; Hua et al.,\n",
            "2023), economic simulations(Zhao et al., 2023; Li\n",
            "et al., 2023), game theory(Duan et al., 2024; Xu\n",
            "et al., 2023a), and game playing(Ma et al., 2023;\n",
            "Xu et al., 2023b). To enhance the performance of' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 141}\n",
            "--------------------------------------------------\n",
            "page_content='LLMs in strategic reasoning scenarios, researchers\n",
            "have utilized the concepts of Theory of Mind (ToM)\n",
            "(Gandhi et al., 2023; Guo et al., 2023) and Re-\n",
            "inforcement Learning (Xu et al., 2023c; Zhang\n",
            "et al., 2024a) to optimize the reasoning processes of' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 142}\n",
            "--------------------------------------------------\n",
            "page_content='LLMs. These approaches involve prompting LLMs\n",
            "to recognize the intricacies of strategic tasks, like\n",
            "our proposed Prediction Chain-of-Thought base-\n",
            "line. However, our experimental results indicate\n",
            "that this approach fails to establish a clear cogni-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 143}\n",
            "--------------------------------------------------\n",
            "page_content='tive hierarchy necessary for recursive and deeper\n",
            "strategic thinking.\n",
            "7 Conclusion\n",
            "This paper represents a significant stride in under-\n",
            "standing and enhancing the strategic reasoning ca-\n",
            "pabilities of LLMs. We propose “K-Level Rea-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 144}\n",
            "--------------------------------------------------\n",
            "page_content='soning with LLMs.” This innovative approach\n",
            "leverages recursive mechanisms to achieve vary-\n",
            "ing thinking level within LLMs, enabling them\n",
            "to engage in deeper strategic thinking. Through\n",
            "extensive experiments, we validate the advantage' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 145}\n",
            "--------------------------------------------------\n",
            "page_content='offered by this method. It establishes a foundation\n",
            "for future research into theory of mind and strategic\n",
            "reasoning in LLMs.\n",
            "8' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 146}\n",
            "--------------------------------------------------\n",
            "page_content='8 Limitations\n",
            "We validate the effectiveness of the K-Level Rea-\n",
            "soning framework from two perspectives: game\n",
            "theory and social intelligence. While our exper-\n",
            "imental results provide substantial evidence sup-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 147}\n",
            "--------------------------------------------------\n",
            "page_content='porting the framework’s validity, further research\n",
            "is necessary to explore the performance of large\n",
            "language models (LLMs) in few-shot agent model-\n",
            "ing (He et al., 2016) across various environments,\n",
            "strategic factors, and action sets.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 148}\n",
            "--------------------------------------------------\n",
            "page_content='Additionally, K-R predicts opponents’ most\n",
            "likely behavior by initiating a new LLM inference\n",
            "session. The recursive mechanism employed to\n",
            "achieve varying levels of strategic depth inevitably\n",
            "increases computational cost. Appendix G pro-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 149}\n",
            "--------------------------------------------------\n",
            "page_content='vides a detailed discussion on how K-R relates\n",
            "to this rise in computational cost and compares it\n",
            "across different reasoning methods. Despite the in-\n",
            "creased demands, K-R outperforms other methods\n",
            "with comparable computational costs.\n",
            "References' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 150}\n",
            "--------------------------------------------------\n",
            "page_content='Josh Achiam, Steven Adler, Sandhini Agarwal, Lama\n",
            "Ahmad, Ilge Akkaya, Florencia Leoni Aleman,\n",
            "Diogo Almeida, Janko Altenschmidt, Sam Altman,\n",
            "Shyamal Anadkat, et al. 2023. Gpt-4 technical report.\n",
            "arXiv preprint arXiv:2303.08774.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 151}\n",
            "--------------------------------------------------\n",
            "page_content='Maciej Besta, Nils Blach, Ales Kubicek, Robert Ger-\n",
            "stenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz\n",
            "Lehmann, Michal Podstawski, Hubert Niewiadomski,\n",
            "Piotr Nyczyk, et al. 2023. Graph of thoughts: Solv-\n",
            "ing elaborate problems with large language models.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 152}\n",
            "--------------------------------------------------\n",
            "page_content='arXiv preprint arXiv:2308.09687.\n",
            "Sumithra Bhakthavatsalam, Daniel Khashabi, Tushar\n",
            "Khot, Bhavana Dalvi Mishra, Kyle Richardson,\n",
            "Ashish Sabharwal, Carissa Schoenick, Oyvind\n",
            "Tafjord, and Peter Clark. 2021. Think you have' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 153}\n",
            "--------------------------------------------------\n",
            "page_content='solved direct-answer question answering? try arc-\n",
            "da, the direct-answer ai2 reasoning challenge. arXiv\n",
            "preprint arXiv:2102.03315.\n",
            "Antoni Bosch-Domenech, Jose G Montalvo, Rosemarie\n",
            "Nagel, and Albert Satorra. 2002. One, two,(three),' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 154}\n",
            "--------------------------------------------------\n",
            "page_content='infinity,. . . : Newspaper and lab beauty-contest ex-\n",
            "periments. American Economic Review, 92(5):1687–\n",
            "1701.\n",
            "Kris Cao, Angeliki Lazaridou, Marc Lanctot, Joel Z\n",
            "Leibo, Karl Tuyls, and Stephen Clark. 2018. Emer-\n",
            "gent communication through negotiation. arXiv' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 155}\n",
            "--------------------------------------------------\n",
            "page_content='preprint arXiv:1804.03980.\n",
            "Brandon Cui, Hengyuan Hu, Luis Pineda, and Jakob\n",
            "Foerster. 2021. K-level reasoning for zero-shot coor-\n",
            "dination in hanabi. Advances in Neural Information\n",
            "Processing Systems, 34:8215–8228.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 156}\n",
            "--------------------------------------------------\n",
            "page_content='Ameet Deshpande, Vishvak Murahari, Tanmay Rajpuro-\n",
            "hit, Ashwin Kalyan, and Karthik Narasimhan. 2023.\n",
            "Toxicity in chatgpt: Analyzing persona-assigned lan-\n",
            "guage models. arXiv preprint arXiv:2304.05335.\n",
            "Zihan Ding and Hao Dong. 2020. Challenges of rein-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 157}\n",
            "--------------------------------------------------\n",
            "page_content='forcement learning. Deep Reinforcement Learning:\n",
            "Fundamentals, Research and Applications , pages\n",
            "249–272.\n",
            "Jinhao Duan, Renming Zhang, James Diffenderfer,\n",
            "Bhavya Kailkhura, Lichao Sun, Elias Stengel-Eskin,\n",
            "Mohit Bansal, Tianlong Chen, and Kaidi Xu. 2024.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 158}\n",
            "--------------------------------------------------\n",
            "page_content='Gtbench: Uncovering the strategic reasoning limita-\n",
            "tions of llms via game-theoretic evaluations. arXiv\n",
            "preprint arXiv:2402.12348.\n",
            "Jakob Foerster, Ioannis Alexandros Assael, Nando\n",
            "De Freitas, and Shimon Whiteson. 2016. Learning' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 159}\n",
            "--------------------------------------------------\n",
            "page_content='to communicate with deep multi-agent reinforcement\n",
            "learning. Advances in neural information processing\n",
            "systems, 29.\n",
            "Yao Fu, Hao Peng, Tushar Khot, and Mirella Lapata.\n",
            "2023. Improving language model negotiation with' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 160}\n",
            "--------------------------------------------------\n",
            "page_content='self-play and in-context learning from ai feedback.\n",
            "arXiv preprint arXiv:2305.10142.\n",
            "Kanishk Gandhi, Dorsa Sadigh, and Noah D Goodman.\n",
            "2023. Strategic reasoning with language models.\n",
            "arXiv preprint arXiv:2305.19165.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 161}\n",
            "--------------------------------------------------\n",
            "page_content='Jiaxian Guo, Bo Yang, Paul Yoo, Bill Yuchen\n",
            "Lin, Yusuke Iwasawa, and Yutaka Matsuo. 2023.\n",
            "Suspicion-agent: Playing imperfect information\n",
            "games with theory of mind aware gpt-4. arXiv\n",
            "preprint arXiv:2309.17277.\n",
            "He He, Jordan Boyd-Graber, Kevin Kwok, and Hal' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 162}\n",
            "--------------------------------------------------\n",
            "page_content='Daumé III. 2016. Opponent modeling in deep rein-\n",
            "forcement learning. In International conference on\n",
            "machine learning, pages 1804–1813. PMLR.\n",
            "Wenyue Hua, Lizhou Fan, Lingyao Li, Kai Mei,\n",
            "Jianchao Ji, Yingqiang Ge, Libby Hemphill, and' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 163}\n",
            "--------------------------------------------------\n",
            "page_content='Yongfeng Zhang. 2023. War and peace (waragent):\n",
            "Large language model-based multi-agent simulation\n",
            "of world wars. arXiv preprint arXiv:2311.17227.\n",
            "John Maynard Keynes. 1936. The general theory of\n",
            "employment. The quarterly journal of economics ,' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 164}\n",
            "--------------------------------------------------\n",
            "page_content='51(2):209–223.\n",
            "Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\n",
            "taka Matsuo, and Yusuke Iwasawa. 2022. Large lan-\n",
            "guage models are zero-shot reasoners. Advances in\n",
            "neural information processing systems , 35:22199–\n",
            "22213.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 165}\n",
            "--------------------------------------------------\n",
            "page_content='Alain Ledoux. 1981. Concours résultats complets. Les\n",
            "victimes se sont plu à jouer le, 14:10–11.\n",
            "Nian Li, Chen Gao, Mingyu Li, Yong Li, and Qing-\n",
            "min Liao. 2024. EconAgent: Large language model-\n",
            "empowered agents for simulating macroeconomic ac-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 166}\n",
            "--------------------------------------------------\n",
            "page_content='tivities. In Proceedings of the 62nd Annual Meeting\n",
            "9' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 167}\n",
            "--------------------------------------------------\n",
            "page_content='of the Association for Computational Linguistics (Vol-\n",
            "ume 1: Long Papers), pages 15523–15536, Bangkok,\n",
            "Thailand. Association for Computational Linguistics.\n",
            "Yang Li, Yangyang Yu, Haohang Li, Zhi Chen, and\n",
            "Khaldoun Khashanah. 2023. Tradinggpt: Multi-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 168}\n",
            "--------------------------------------------------\n",
            "page_content='agent system with layered memory and distinct char-\n",
            "acters for enhanced financial trading performance.\n",
            "arXiv preprint arXiv:2309.03736.\n",
            "Weiyu Ma, Qirui Mi, Xue Yan, Yuqiao Wu, Runji Lin,\n",
            "Haifeng Zhang, and Jun Wang. 2023. Large lan-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 169}\n",
            "--------------------------------------------------\n",
            "page_content='guage models play starcraft ii: Benchmarks and a\n",
            "chain of summarization approach. arXiv preprint\n",
            "arXiv:2312.11865.\n",
            "Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler\n",
            "Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon,' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 170}\n",
            "--------------------------------------------------\n",
            "page_content='Nouha Dziri, Shrimai Prabhumoye, Yiming Yang,\n",
            "et al. 2023. Self-refine: Iterative refinement with\n",
            "self-feedback. arXiv preprint arXiv:2303.17651.\n",
            "Anuj Mahajan, Tabish Rashid, Mikayel Samvelyan, and\n",
            "Shimon Whiteson. 2019. Maven: Multi-agent varia-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 171}\n",
            "--------------------------------------------------\n",
            "page_content='tional exploration. Advances in neural information\n",
            "processing systems, 32.\n",
            "Shaoguang Mao, Yuzhe Cai, Yan Xia, Wenshan Wu,\n",
            "Xun Wang, Fengyi Wang, Tao Ge, and Furu Wei.\n",
            "2023. Alympics: Language agents meet game theory.\n",
            "arXiv preprint arXiv:2311.03220.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 172}\n",
            "--------------------------------------------------\n",
            "page_content='Shen-Yun Miao, Chao-Chun Liang, and Keh-Yih Su.\n",
            "2021. A diverse corpus for evaluating and developing\n",
            "english math word problem solvers. arXiv preprint\n",
            "arXiv:2106.15772.\n",
            "Rosemarie Nagel. 1995. Unraveling in guessing games:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 173}\n",
            "--------------------------------------------------\n",
            "page_content='An experimental study. The American economic re-\n",
            "view, 85(5):1313–1326.\n",
            "Xuefei Ning, Zinan Lin, Zixuan Zhou, Huazhong Yang,\n",
            "and Yu Wang. 2023. Skeleton-of-thought: Large\n",
            "language models can do parallel decoding. arXiv\n",
            "preprint arXiv:2307.15337.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 174}\n",
            "--------------------------------------------------\n",
            "page_content='Georgios Papoudakis, Filippos Christianos, Arrasy Rah-\n",
            "man, and Stefano V Albrecht. 2019. Dealing with\n",
            "non-stationarity in multi-agent deep reinforcement\n",
            "learning. arXiv preprint arXiv:1906.04737.\n",
            "Arkil Patel, Satwik Bhattamishra, and Navin Goyal.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 175}\n",
            "--------------------------------------------------\n",
            "page_content='2021. Are nlp models really able to solve\n",
            "simple math word problems? arXiv preprint\n",
            "arXiv:2103.07191.\n",
            "Noah Shinn, Federico Cassano, Ashwin Gopinath,\n",
            "Karthik R Narasimhan, and Shunyu Yao. 2023. Re-\n",
            "flexion: Language agents with verbal reinforcement' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 176}\n",
            "--------------------------------------------------\n",
            "page_content='learning. In Thirty-seventh Conference on Neural\n",
            "Information Processing Systems.\n",
            "Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao,\n",
            "Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch,\n",
            "Adam R Brown, Adam Santoro, Aditya Gupta,' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 177}\n",
            "--------------------------------------------------\n",
            "page_content='Adrià Garriga-Alonso, et al. 2022. Beyond the\n",
            "imitation game: Quantifying and extrapolating the\n",
            "capabilities of language models. arXiv preprint\n",
            "arXiv:2206.04615.\n",
            "Dale O Stahl and Paul W Wilson. 1995. On players’' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 178}\n",
            "--------------------------------------------------\n",
            "page_content='models of other players: Theory and experimental ev-\n",
            "idence. Games and Economic Behavior, 10(1):218–\n",
            "254.\n",
            "Peter Sunehag, Guy Lever, Audrunas Gruslys, Woj-\n",
            "ciech Marian Czarnecki, Vinicius Zambaldi, Max\n",
            "Jaderberg, Marc Lanctot, Nicolas Sonnerat, Joel Z' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 179}\n",
            "--------------------------------------------------\n",
            "page_content='Leibo, Karl Tuyls, et al. 2017. Value-decomposition\n",
            "networks for cooperative multi-agent learning. arXiv\n",
            "preprint arXiv:1706.05296.\n",
            "Mirac Suzgun, Nathan Scales, Nathanael Schärli, Se-\n",
            "bastian Gehrmann, Yi Tay, Hyung Won Chung,' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 180}\n",
            "--------------------------------------------------\n",
            "page_content='Aakanksha Chowdhery, Quoc V Le, Ed H Chi, Denny\n",
            "Zhou, et al. 2022. Challenging big-bench tasks and\n",
            "whether chain-of-thought can solve them. arXiv\n",
            "preprint arXiv:2210.09261.\n",
            "Alon Talmor, Ori Yoran, Ronan Le Bras, Chandra Bha-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 181}\n",
            "--------------------------------------------------\n",
            "page_content='gavatula, Yoav Goldberg, Yejin Choi, and Jonathan\n",
            "Berant. 2022. Commonsenseqa 2.0: Exposing the\n",
            "limits of ai through gamification. arXiv preprint\n",
            "arXiv:2201.05320.\n",
            "Zhenhailong Wang, Shaoguang Mao, Wenshan Wu,\n",
            "Tao Ge, Furu Wei, and Heng Ji. 2023. Unleash-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 182}\n",
            "--------------------------------------------------\n",
            "page_content='ing cognitive synergy in large language models:\n",
            "A task-solving agent through multi-persona self-\n",
            "collaboration. arXiv preprint arXiv:2307.05300.\n",
            "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\n",
            "Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 183}\n",
            "--------------------------------------------------\n",
            "page_content='et al. 2022. Chain-of-thought prompting elicits rea-\n",
            "soning in large language models. Advances in Neural\n",
            "Information Processing Systems, 35:24824–24837.\n",
            "Annie Wong, Thomas Bäck, Anna V Kononova, and\n",
            "Aske Plaat. 2021. Deep multiagent reinforcement' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 184}\n",
            "--------------------------------------------------\n",
            "page_content='learning: Challenges and directions. arXiv preprint\n",
            "arXiv:2106.15691.\n",
            "Sang Michael Xie, Aditi Raghunathan, Percy Liang, and\n",
            "Tengyu Ma. 2021. An explanation of in-context learn-\n",
            "ing as implicit bayesian inference. arXiv preprint\n",
            "arXiv:2111.02080.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 185}\n",
            "--------------------------------------------------\n",
            "page_content='Lin Xu, Zhiyuan Hu, Daquan Zhou, Hongyu Ren, Zhen\n",
            "Dong, Kurt Keutzer, See-Kiong Ng, and Jiashi Feng.\n",
            "2023a. Magic: Investigation of large language model\n",
            "powered multi-agent in cognition, adaptability, ratio-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 186}\n",
            "--------------------------------------------------\n",
            "page_content='nality and collaboration. In ICLR 2024 Workshop on\n",
            "Large Language Model (LLM) Agents.\n",
            "Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xi-\n",
            "aolong Wang, Weidong Liu, and Yang Liu. 2023b.\n",
            "Exploring large language models for communica-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 187}\n",
            "--------------------------------------------------\n",
            "page_content='tion games: An empirical study on werewolf. arXiv\n",
            "preprint arXiv:2309.04658.\n",
            "10' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 188}\n",
            "--------------------------------------------------\n",
            "page_content='Zelai Xu, Chao Yu, Fei Fang, Yu Wang, and Yi Wu.\n",
            "2023c. Language agents with reinforcement learn-\n",
            "ing for strategic play in the werewolf game. arXiv\n",
            "preprint arXiv:2310.18940.\n",
            "Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran,' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 189}\n",
            "--------------------------------------------------\n",
            "page_content='Thomas L Griffiths, Yuan Cao, and Karthik\n",
            "Narasimhan. 2023. Tree of thoughts: Deliberate\n",
            "problem solving with large language models. arXiv\n",
            "preprint arXiv:2305.10601.\n",
            "Wenqi Zhang, Ke Tang, Hai Wu, Mengna Wang,' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 190}\n",
            "--------------------------------------------------\n",
            "page_content='Yongliang Shen, Guiyang Hou, Zeqi Tan, Peng Li,\n",
            "Yueting Zhuang, and Weiming Lu. 2024a. Agent-\n",
            "pro: Learning to evolve via policy-level reflection\n",
            "and optimization. arXiv preprint arXiv:2402.17574.\n",
            "Yadong Zhang, Shaoguang Mao, Tao Ge, Xun Wang,' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 191}\n",
            "--------------------------------------------------\n",
            "page_content='Yan Xia, Wenshan Wu, Ting Song, Man Lan, and\n",
            "Furu Wei. 2024b. LLM as a mastermind: A survey\n",
            "of strategic reasoning with large language models. In\n",
            "First Conference on Language Modeling.\n",
            "Qinlin Zhao, Jindong Wang, Yixuan Zhang, Yiqiao Jin,' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 192}\n",
            "--------------------------------------------------\n",
            "page_content='Kaijie Zhu, Hao Chen, and Xing Xie. 2023. Com-\n",
            "peteai: Understanding the competition behaviors in\n",
            "large language model-based agents. arXiv preprint\n",
            "arXiv:2310.17512.\n",
            "Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang,' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 193}\n",
            "--------------------------------------------------\n",
            "page_content='Haofei Yu, Zhengyang Qi, Louis-Philippe Morency,\n",
            "Yonatan Bisk, Daniel Fried, Graham Neubig, and\n",
            "Maarten Sap. 2024. SOTOPIA: Interactive evalua-\n",
            "tion for social intelligence in language agents. In\n",
            "The Twelfth International Conference on Learning' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 194}\n",
            "--------------------------------------------------\n",
            "page_content='Representations.\n",
            "11' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 195}\n",
            "--------------------------------------------------\n",
            "page_content='A Impact Statements\n",
            "Our research introduces the K-Level Reasoning\n",
            "framework, designed to formulate strategies in dy-\n",
            "namic, interactive and competitive scenarios by\n",
            "anticipating the reactions of adversaries, poten-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 196}\n",
            "--------------------------------------------------\n",
            "page_content='tially users. Theoretically, this approach offers a\n",
            "novel perspective for understanding and optimizing\n",
            "decision-making processes. However, we recog-\n",
            "nize when the goal setting diverges from user inter-\n",
            "ests, the application of K-Level Reasoning could' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 197}\n",
            "--------------------------------------------------\n",
            "page_content='result in manipulative behaviors by adapting to the\n",
            "predicted user’s reactions. This risk is notably pro-\n",
            "nounced in scenarios designed to influence user\n",
            "decisions or behaviors, such as in recommenda-\n",
            "tion systems, advertising placements, and content' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 198}\n",
            "--------------------------------------------------\n",
            "page_content='distribution on social media platforms.\n",
            "Although K-Level Reasoning provides a potent\n",
            "powerful tool for strategic planning, interacting and\n",
            "reasoning, ethical considerations must be meticu-\n",
            "lously managed in its practical application. This' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 199}\n",
            "--------------------------------------------------\n",
            "page_content='ensures that the development and utilization of tech-\n",
            "nology do not detrimentally impact user and soci-\n",
            "etal interests. To this end, we advocate for height-\n",
            "ened transparency, ensuring users have a compre-\n",
            "hensive understanding and control over how their' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 200}\n",
            "--------------------------------------------------\n",
            "page_content='data is utilized.\n",
            "B Game Setting\n",
            "B.1 Guessing 0.8 of the Average\n",
            "Initial Setup: For each round, each player select\n",
            "a number between 1 and 100. The objective is to\n",
            "select a number that is closest to 80% of the group’s' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 201}\n",
            "--------------------------------------------------\n",
            "page_content='average choice. Formally, each player i chooses a\n",
            "number ni, aiming for ni ≈ 0.8 × n, where n is\n",
            "the average of all chosen numbers.\n",
            "Scoring and Continuation: A player scores a\n",
            "point if his/her chosen number is closest to 80%' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 202}\n",
            "--------------------------------------------------\n",
            "page_content='of the average number chosen by the group. If\n",
            "all players select the same number, no points are\n",
            "awarded for this round. Mathematically, the score\n",
            "for player i in in round t is given by st\n",
            "i, which is 1\n",
            "if |ni −0.8 ×n| is the minimum among all players,' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 203}\n",
            "--------------------------------------------------\n",
            "page_content='and 0 otherwise.\n",
            "B.2 Survival Auction Game\n",
            "Initial Setup: Players start with 8 health points,\n",
            "out of a maximum of 10. Every day, each player\n",
            "possesses a fixed income of $100. The daily water\n",
            "supply can only satisfy one resident’s requirement.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 204}\n",
            "--------------------------------------------------\n",
            "page_content='Scoring and Continuation: Everyday, players\n",
            "engage in a daily auction to secure the necessary\n",
            "water resources, and the highest bidder wins. In\n",
            "case of a tie, the resources are not allocated to\n",
            "any player. If a player successfully bid the water' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 205}\n",
            "--------------------------------------------------\n",
            "page_content='resources, they will gain 2 health points; otherwise,\n",
            "they will lose health points equal to the number\n",
            "of consecutive days, denoted as n, during which\n",
            "they have not obtained water resources. Once a\n",
            "player’s health points fall to 0 or below, they will' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 206}\n",
            "--------------------------------------------------\n",
            "page_content='be eliminated. The health point of player i on day\n",
            "t, denoted as ht\n",
            "i, is crucial in determining their\n",
            "survival and bidding strategy.\n",
            "C Detailed Metric Computational\n",
            "Formulas\n",
            "Win Rate is calculated based on the number of' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 207}\n",
            "--------------------------------------------------\n",
            "page_content='wins over game going, providing a measure of the\n",
            "overall ability.\n",
            "WinRate = Num of Wins\n",
            "Total Round per Test× Num of Test(9)\n",
            "Average Survival Roundcalculates the average\n",
            "round in which the player remains in the game.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 208}\n",
            "--------------------------------------------------\n",
            "page_content='It’s an effective way to assess performance in\n",
            "elimination-based game, like SAG.\n",
            "AvgSurvivalRound =\n",
            "PSurvival Round in Each Test\n",
            "Num of Test (10)\n",
            "Prediction Accuracy evaluates the accuracy of\n",
            "player’s predictions regarding rivals’ future moves.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 209}\n",
            "--------------------------------------------------\n",
            "page_content='In the G0.8A, it involves calculating the absolute\n",
            "difference between the player’s predicted average\n",
            "and the actual average in each round:\n",
            "Pred Acc =\n",
            "P|AvgP red− AvgActual|\n",
            "Num of Test (11)\n",
            "In the SAG, the focus shifts to measuring the ab-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 210}\n",
            "--------------------------------------------------\n",
            "page_content='solute error between the player’s prediction of the\n",
            "highest bid by opponents and the actual highest bid\n",
            "made by them.\n",
            "Pred Acc =\n",
            "P|Max BidP red− Max BidActual|\n",
            "Num of Test (12)\n",
            "Strategic Level\n",
            "StrategicDepth(choice) = logα(choice/50)\n",
            "(13)' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 211}\n",
            "--------------------------------------------------\n",
            "page_content='Here, α represents the target value coefficient, and\n",
            "50 represents the average of a random choice be-\n",
            "tween 0 and 100, which is used to represent level-0\n",
            "players. In the settings of [1][2], the parameter α is\n",
            "set to 2' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 212}\n",
            "--------------------------------------------------\n",
            "page_content='3 . In our configuration, α is set to 0.8, which\n",
            "is the origin of the name G0.8A.\n",
            "12' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 213}\n",
            "--------------------------------------------------\n",
            "page_content='Introduction Prompt:\n",
            "You are Alex and involved in a survive challenge. You are one of five players in the game. Everyone is required to choose an integer' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 214}\n",
            "--------------------------------------------------\n",
            "page_content='between 1 and 100 in each round. The player whose chosen number is closest to (0.8 * the average of all chosen numbers) wins the' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 215}\n",
            "--------------------------------------------------\n",
            "page_content='round without any HP deduction. All other players will have 1 HP deducted. But if all players choose the same number, their h ealth \n",
            "points are deducted together.\n",
            "Round Start Prompt (Standard):' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 216}\n",
            "--------------------------------------------------\n",
            "page_content='Ok, Alex! Now is the ROUND 1, and your HP is at 10. Please choose an integer between 1 and 100 for this round.”\n",
            "Notification Result Prompt :' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 217}\n",
            "--------------------------------------------------\n",
            "page_content='Thank you all for participating in Round 1. In this round, Alex chose 45, Bob chose 45, Cindy chose 50, David chose 45, Eric chose 45.\n",
            "The average is (45 + 45 + 50 + 45 + 45) / 5 = 46.0.  The average 46.0 multiplied by 0.8 equals 36.8.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 218}\n",
            "--------------------------------------------------\n",
            "page_content='Alex: |45 - 36.8| = 8, Bob: |45 - 36.8| = 8, Cindy: |50 - 36.8| = 13, David: |45 - 36.8| = 8, Eric: |45 - 36.8| = 8\n",
            "[Alex, Bob, David, Eric]'s choice of 45 is closest to 36.8.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 219}\n",
            "--------------------------------------------------\n",
            "page_content='Round winner: Alex, Bob, David, Eric. All other players lose 1 point. After the deduction, player information is: \n",
            "name: Alex  HP: 10, name: Bob HP: 10, name: Cindy HP: 9, name: David HP: 10, name: Eric  HP: 10.\n",
            "Congratulation Prompt (When Win):' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 220}\n",
            "--------------------------------------------------\n",
            "page_content='You have successfully chosen the number closest to the target number, which is the average of all players' selected numbers \n",
            "multiplied by 0.8. As a result, you have won this round. All other players will now deduct 1 HP. \n",
            "Warning Prompt (When Loss):' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 221}\n",
            "--------------------------------------------------\n",
            "page_content='WARNING: You have lost 1 point of HP in this round! You now have only 9 points of health left. You are one step closer to dea th.\n",
            "G0.8A Game Prompt\n",
            "Figure 4: Prompts used in Guessing 0.8 of the Average game.\n",
            "Introduction Prompt:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 222}\n",
            "--------------------------------------------------\n",
            "page_content='You are Alex and a resident living in W-Town. W Town is experiencing a rare drought. Every residents in Town W is ensuring their survival \n",
            "over a period of 10 days by acquiring the water resources.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 223}\n",
            "--------------------------------------------------\n",
            "page_content='Attention, all W-Town residents, welcome to the Water Allocation Challenge!\n",
            "In this challenge, you are tasked with ensuring your survival over a period of 10 days by acquiring the necessary water resources to maintain' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 224}\n",
            "--------------------------------------------------\n",
            "page_content='your health. You will participate in daily auctions to bid for water resources to meet your individual needs.\n",
            "Here are the game rules and settings:\n",
            "1. You are one of five residents with same water requirements, budgets, and health points.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 225}\n",
            "--------------------------------------------------\n",
            "page_content='2. Your goal is to survive until the end of the 10 days.\n",
            "3. Each resident has a maximum of 10 health points and starts with 8 health points. If your health points drop below or equal to 0, you will' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 226}\n",
            "--------------------------------------------------\n",
            "page_content='be considered dead and eliminated from the game! All your accumulated money will be reset to Zero! \n",
            "4. Every day, you will bid on water resources to meet your needs. If your consecutive days without obtaining water resource (No-Drink Days)' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 227}\n",
            "--------------------------------------------------\n",
            "page_content='reach n, your health will be deducted by n points on that day. If your water needs are met, 2 points will be added to your health, and the \n",
            "No-Drink Days will be reset to 0.\n",
            "5. Daily water resources can only meet the needs of one resident.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 228}\n",
            "--------------------------------------------------\n",
            "page_content='6. Each resident has $100 daily income;\n",
            "7. To allocate water resources, a sealed-bid auction will be conducted daily. Each resident submits a single bid for their entire water need. \n",
            "The resident with the highest bid is eligible to obtain water resources.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 229}\n",
            "--------------------------------------------------\n",
            "page_content='8. If the highest bid results in a tie, no residents will have access to water . \n",
            "All bidding information will be made public after the allocation of water resources on the same day.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 230}\n",
            "--------------------------------------------------\n",
            "page_content='Remember , the key to success is effective bidding and strategizing to ensure your survival. Good luck!!\n",
            "Round Start Prompt (Standard):\n",
            "Hello, Alex! Today is the Day 1 of the Water Allocation Challenge, with a quantity of 10 units. Your status:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 231}\n",
            "--------------------------------------------------\n",
            "page_content='name: Alex  balance:100  HP:8  no_drink : 1  \n",
            "Please carefully analyze your situation to decide on this round of bidding. Remember , the most important thing is to SURVIVE! ! Now, if you' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 232}\n",
            "--------------------------------------------------\n",
            "page_content='want to participate in today's water resource auction, please provide your bid.\n",
            "Notification Result Prompt :\n",
            "Thank you all for participating in Round 1. In this round, Alex bid 25, Bob bid 40, Cindy bid 40, David bid 30, Eric bid 60.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 233}\n",
            "--------------------------------------------------\n",
            "page_content='Total water resource supply is 10. According to the principle of the highest bidder and the rule when the game is tied, Eric won this auction \n",
            "and obtain water resource. \n",
            "After allocation, all survival residents' information is as follows:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 234}\n",
            "--------------------------------------------------\n",
            "page_content='name: Alex balance: 100  HP:7 no_drink : 2,   name: Bob  balance: 100  HP:7 no_drink:2 \n",
            "name :Cindy  balance:100 HP:7 no_drink:2,   name: David  balance: 100 HP: :7 no_drink:2\n",
            "name:Eric balance:40  HP:10 no_drink:1\n",
            "Congratulation Prompt (When Win):' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 235}\n",
            "--------------------------------------------------\n",
            "page_content='You have successfully won the bidding for today's water resources and restored 2 points of HP .\n",
            "Warning Prompt (When Lose):\n",
            "WARNING: You have lost 1point of HP in this round! You now have only 7 points of health left. You are one step closer to death.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 236}\n",
            "--------------------------------------------------\n",
            "page_content='Survival Auction Game Prompt\n",
            "Bidding Result Parse Prompt:\n",
            "By reading the conversation, extract the number chosen by player . Output format: number . If the player does not bid, Output: 0.\n",
            "Figure 5: Prompts used in Survival Auction Game.\n",
            "13' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 237}\n",
            "--------------------------------------------------\n",
            "page_content='D Performance of Large Language\n",
            "Models Competing with Programmatic\n",
            "Strategies\n",
            "In addition to using the LLM-LLM Combat com-\n",
            "parison setting in Section 4, we have also designed\n",
            "a set of LLM-Programmatic Strategy Combat' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 238}\n",
            "--------------------------------------------------\n",
            "page_content='comparisons. In Player-Programmatic Strategy\n",
            "Combat setting, the “player\" will be equipped with\n",
            "a specific reasoning method, while opponents will\n",
            "play according to programmatic strategic patterns,\n",
            "which will not be adjusted with the game going.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 239}\n",
            "--------------------------------------------------\n",
            "page_content='This mode is to check different methods’ adapta-\n",
            "tion to different predefined but fixed patterns. For\n",
            "the Player-Programmatic Player Combat Combat\n",
            "in G0.8A, the programmatic strategies include:\n",
            "1) 0-Level (Fix): The characteristic of a 0-Level' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 240}\n",
            "--------------------------------------------------\n",
            "page_content='player is that their choice of strategy is uniform\n",
            "(Stahl and Wilson, 1995). We limit the choice space\n",
            "of the 0-Level Computer player to only 40.\n",
            "2) 0-Level (Var): Modified from the 0-Level\n",
            "(Fix) strategy, the selection is sampled from a Gaus-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 241}\n",
            "--------------------------------------------------\n",
            "page_content='sian distribution with a mean of 40 and a variance\n",
            "of 5.\n",
            "3) MonoTrend (Fix): The numbers chosen by\n",
            "the computer players follow an arithmetic sequence\n",
            "with a decreasing common difference, and the com-\n",
            "mon differences for all four computer players are' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 242}\n",
            "--------------------------------------------------\n",
            "page_content='the same.\n",
            "4) MonoTrend (Var): The numbers chosen by\n",
            "the computer players follow an arithmetic sequence\n",
            "with a decreasing common difference, and the com-\n",
            "mon differences for the four computer players are\n",
            "randomly generated from 1 to 5.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 243}\n",
            "--------------------------------------------------\n",
            "page_content='5) LastBids (Fix): The computer player chooses\n",
            "the target number from the previous round (selects\n",
            "40 in the first round).\n",
            "6) LastBids (Var): Modified from the LastBids\n",
            "strategy, the selection is sampled from a Gaussian' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 244}\n",
            "--------------------------------------------------\n",
            "page_content='distribution with a mean equal to the target number\n",
            "of the previous round and a variance of 5.\n",
            "Overall, the dynamic changes of these three set-\n",
            "tings are LastBids > MonoTrend > 0-Level. We\n",
            "use these three programs to test the reasoning capa-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 245}\n",
            "--------------------------------------------------\n",
            "page_content='bility to adapt to and counter different patterns.\n",
            "Table 9 reveals a significant trend in the perfor-\n",
            "mance of players against other approaches. The\n",
            "effectiveness of reasoning approaches decreases\n",
            "in the following order: 0-Level, MonoTrend, and' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 246}\n",
            "--------------------------------------------------\n",
            "page_content='LastBids. This pattern highlights a reduction in the\n",
            "efficacy of the LLM in more dynamic environments.\n",
            "We found that only K-Level Reasoning shows an\n",
            "advantage in LastBids (Fix), indicating that com-\n",
            "pared to K-Level Reasoning, previous reasoning' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 247}\n",
            "--------------------------------------------------\n",
            "page_content='methods on static problems lack observation and\n",
            "judgment of the opponent. Conversely, this also\n",
            "demonstrates that K-Level Reasoning can implic-\n",
            "itly infer the behavior pattern of the opponent based\n",
            "on their historical actions.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 248}\n",
            "--------------------------------------------------\n",
            "page_content='Intriguingly, reasoning methods significantly in-\n",
            "fluence the performance in dynamic settings. Meth-\n",
            "ods like CoT and Self-Refine, traditionally favored\n",
            "in static reasoning, also demonstrate substantial\n",
            "improvements over the Standard Prompt approach.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 249}\n",
            "--------------------------------------------------\n",
            "page_content='This finding underscores the necessity for more\n",
            "elaborate reasoning processes in dynamic decision-\n",
            "making, akin to static problem-solving scenarios.\n",
            "Table 9: Win Rate of the player against different pro-\n",
            "grammatic strategies in Guessing 0.8 of the Average' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 250}\n",
            "--------------------------------------------------\n",
            "page_content='game.\n",
            "Opponent Direct CoT Persona Reflect Refine PCoT K-R\n",
            "Player VS Programmatic Strategies\n",
            "0-Level (Fix) 0.65 0.87 0.87 0.81 0.99 0.800.97\n",
            "0-Level (Var)0.44 0.67 0.69 0.61 0.54 0.760.77\n",
            "MonoTrend (Fix)0.05 0.06 0.15 0.00 0.29 0.150.48' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 251}\n",
            "--------------------------------------------------\n",
            "page_content='MonoTrend (Var)0.34 0.44 0.57 0.33 0.49 0.460.74\n",
            "LastBids (Fix)0.01 0.12 0.16 0.01 0.27 0.060.75\n",
            "LastBids (Var)0.06 0.15 0.18 0.19 0.18 0.140.18\n",
            "E Open Source LLM with K-Level\n",
            "Reasoning\n",
            "In addition to the experiments on GPT3.5 /GPT4,' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 252}\n",
            "--------------------------------------------------\n",
            "page_content='we conducted tests with an open-source smaller-\n",
            "scale model, LLaMA-7B-Chat, in the \"G0.8A\"\n",
            "game. To clearly compare the performance of dif-\n",
            "ferent LLMs, we adopted the LLM-Programmatic\n",
            "Strategy Combat setting described in Appendix B.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 253}\n",
            "--------------------------------------------------\n",
            "page_content='From the experimental results, we can see that:\n",
            "1. Llama2-7B and GPT3.5, even including GPT4,\n",
            "perform poorly when competing against program-\n",
            "matic strategies using standard prompting, strug-\n",
            "gling even with some very simple strategies. It' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 254}\n",
            "--------------------------------------------------\n",
            "page_content='underscores the significance of our research; 2. For\n",
            "all tested models, applying k-level reasoning effec-\n",
            "tively enhanced the win rate, highlighting the stabil-\n",
            "ity of the improvement our proposed model brings' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 255}\n",
            "--------------------------------------------------\n",
            "page_content='to different base models. Interestingly, for stronger\n",
            "LLMs, applying K-R can achieve a higher relative\n",
            "improvement, we speculate that the enhancement is\n",
            "simultaneously derived from the opponent’s action\n",
            "simulation and reasoning capabilities of the base' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 256}\n",
            "--------------------------------------------------\n",
            "page_content='model.\n",
            "14' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 257}\n",
            "--------------------------------------------------\n",
            "page_content='Table 10: Win Rate of the reasoning methods with open\n",
            "source LLMs against different programmatic strategies\n",
            "in Guessing 0.8 of the Average game.\n",
            "Methods Direct K-R[K=2] Direct K-R[K=2] Direct K-R[K=2]' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 258}\n",
            "--------------------------------------------------\n",
            "page_content='Base Model [LLaMA-7B] [LLaMA-7B] [GPT3.5] [GPT3.5] [GPT4] [GPT4]\n",
            "Player VS Programmatic Strategies' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 259}\n",
            "--------------------------------------------------\n",
            "page_content='0-Level (Fix)0.30 0.43 0.30 0.49 0.65 0.970-Level (Var)0.13 0.22 0.11 0.36 0.44 0.77MonoTrend (Fix)0.12 0.12 0.17 0.32 0.05 0.48MonoTrend (Var)0.17 0.13 0.19 0.42 0.34 0.74LastBids (Fix)0.04 0.11 0.22 0.38 0.01 0.75LastBids (Var)0.03 0.08 0.11 0.10 0.06' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 260}\n",
            "--------------------------------------------------\n",
            "page_content='0.18' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 261}\n",
            "--------------------------------------------------\n",
            "page_content='Avg 0.13 0.18 (+0.05) 0.18 0.35 (+0.17) 0.26 0.65 (+0.39)\n",
            "F Batter Nash Equilibrium\n",
            "Approximation with K-Level Reasoning\n",
            "To assess the impact of K-Level Reasoning on Nash\n",
            "equilibrium, we conducted experiments testing the' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 262}\n",
            "--------------------------------------------------\n",
            "page_content='performance of LLMs at different K-Levels in the\n",
            "Prisoner’s Dilemma. The Prisoner’s Dilemma is\n",
            "a classic concept in game theory that illustrates\n",
            "a paradoxical situation in which individuals act-\n",
            "ing in their own self-interest lead to a suboptimal' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 263}\n",
            "--------------------------------------------------\n",
            "page_content='outcome for everyone involved. It’s often used\n",
            "to study decision-making in situations involving\n",
            "cooperation and competition.\n",
            "From Table 11, it is evident that when K=1, play-\n",
            "ers exhibit weaker rationality: they tend to choose' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 264}\n",
            "--------------------------------------------------\n",
            "page_content='cooperation over betrayal. As the K-Level of one\n",
            "player increases (first row from left to right), play-\n",
            "ers with higher K-Levels demonstrate stronger ra-\n",
            "tionality: they tend to choose betrayal over coop-\n",
            "eration. Moreover, when both players’ K-Levels' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 265}\n",
            "--------------------------------------------------\n",
            "page_content='increase, they are more likely to reach a state of\n",
            "Nash equilibrium: both choosing to betray each\n",
            "other.\n",
            "Table 11: Statistical analysis of the Payoff Matrix\n",
            "for LLM in the Prisoner’s Dilemma across different' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 266}\n",
            "--------------------------------------------------\n",
            "page_content='K-Levels. The Nash equilibrium of the Prisoner’s\n",
            "Dilemma, where both players choose to betray each\n",
            "other, is highlighted with a green background in the\n",
            "bottom-right corner of each cell.\n",
            "Level-1 Level-2 Level-3 Level-4\n",
            "10 0 7 3 1 9 0 10Level-1' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 267}\n",
            "--------------------------------------------------\n",
            "page_content='0 0 0 0 0 0 0 0\n",
            "7 0 2 0 0 2 0 1Level-2\n",
            "3 0 5 3 0 8 0 9\n",
            "1 0 0 0 0 0 0 0Level-3\n",
            "9 0 2 8 0 10 1 9\n",
            "0 0 0 0 0 1 0 0Level-4\n",
            "10 0 1 9 0 9 1 9\n",
            "G Computational Cost Analysis\n",
            "Table 12: Average input/output/total token consumption\n",
            "per game test. Unit: Kilo tokens.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 268}\n",
            "--------------------------------------------------\n",
            "page_content='Game Metric Direct CoT Persona Reflect Refine PCoT K-R\n",
            "GO8A\n",
            "Input 14.80 23.30 18.70 39.50145.5030.80 123.40Output 0.10 1.80 0.60 1.20 6.901.30 1.60Total 14.90 25.10 19.30 40.70152.4032.10 124.90\n",
            "Avg Win Rate 0.16 0.42 0.41 0.24 0.37 0.400.65\n",
            "SAG' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 269}\n",
            "--------------------------------------------------\n",
            "page_content='Input 21.30 29.00 27.10 51.40130.5037.00 90.10Output 0.70 1.00 0.90 1.80 3.301.30 1.40Total 22.00 30.00 28.10 53.20133.8038.20 91.60\n",
            "Avg Surv Round 6.51 7.44 7.59 4.82 7.33 6.179.01\n",
            "To understand how different reasoning meth-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 270}\n",
            "--------------------------------------------------\n",
            "page_content='ods affect token consumption, thereby assisting\n",
            "users in utilizing models more effectively and opti-\n",
            "mizing resource utilization and cost control, we\n",
            "conducted an analysis of the computational ex-\n",
            "penditure associated with various reasoning ap-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 271}\n",
            "--------------------------------------------------\n",
            "page_content='proaches. Specifically, we calculated the average\n",
            "input/output/total token consumption per game test\n",
            "for both the \"Guessing 0.8 of the Average\" and\n",
            "\"Survival Auction Game.\"\n",
            "K-Level Reasoning, due to simulating the oppo-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 272}\n",
            "--------------------------------------------------\n",
            "page_content='nents’ actions based on public historical behavior\n",
            "information with new sessions, inevitably causes\n",
            "more token consumption. The increase in token\n",
            "consumption linearly correlates with the number of\n",
            "opponents that need to be simulated and the rounds.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 273}\n",
            "--------------------------------------------------\n",
            "page_content='We also find that more token consumption does\n",
            "not necessarily lead to better results. The Self-\n",
            "Refine method, due to its action-feedback-refine\n",
            "pipeline, leads to a substantial increase in token\n",
            "consumption for both input and output, yet it did' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 274}\n",
            "--------------------------------------------------\n",
            "page_content='not outperform our proposed K-Level Reasoning\n",
            "in terms of performance. Compared to baselines,\n",
            "the proposed K-Level Reasoning method is an ef-\n",
            "fective and efficient way to recursively simulate the\n",
            "decision-making process of the opponent and make' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 275}\n",
            "--------------------------------------------------\n",
            "page_content='decisions based on the simulation results.\n",
            "H Statistical Significance of K-Level\n",
            "Reasoning efficacy\n",
            "Due to the utilization of a large language model for\n",
            "evaluation, inherent stochasticity is present, and\n",
            "the sample size for testing is limited (only con-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 276}\n",
            "--------------------------------------------------\n",
            "page_content='ducted 10 experiments). To objectively assess the\n",
            "reliability of the experiment result, we subjected\n",
            "the results from G0.8A and SAG to a t-test for sig-\n",
            "nificance with p = 0.05. Specifically, different\n",
            "significance testing methods were employed for' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 277}\n",
            "--------------------------------------------------\n",
            "page_content='different evaluation metrics, as outlined below:\n",
            "15' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 278}\n",
            "--------------------------------------------------\n",
            "page_content='Table 13: The significance of metric result on G0.8A and SAG, comparing K-R against differentbaseline models in\n",
            "terms of Win Rate, Average Survival Round, and Adaptation Index.\n",
            "Game Metric Direct CoT Persona Reflect Refine PCoT' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 279}\n",
            "--------------------------------------------------\n",
            "page_content='G0.8A Win Rate ✓(0.001) ✓(0.005) ✓(0.001) ✓(0.001) ✓(0.001) ✓(0.001)\n",
            "Adaption Index ✓(0.007) ✓(0.010) ✓(0.039) ×(0.062) ✓(0.003) ✓(0.021)\n",
            "SAG Average Survival Round ✓(0.003) ✓(0.010) ×(0.074) ✓(0.001) ✓(0.001) ✓(0.001)' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 280}\n",
            "--------------------------------------------------\n",
            "page_content='Adaption Index ×(0.337) ×(0.786) ×(0.659) ×(0.066) ×(0.672) ×(0.894)\n",
            "Table 14: The significance of comparing K-R with PCoT concerning the differential performance across various\n",
            "Baseline models on the metric of Prediction Accuracy.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 281}\n",
            "--------------------------------------------------\n",
            "page_content='Game Direct CoT Persona Reflect Refine PCoT K-R\n",
            "G0.8A ✓(0.003) ×(0.058) ✓(0.031) ✓(0.003) ✓(0.022) ✓(0.023) ×(0.107)\n",
            "SAG ×(0.091) ✓(0.023) ✓(0.049) ×(0.907) ×(0.956) ×(0.656) ✓(0.028)\n",
            "• Win Rate & Average Survival Round: A t-test' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 282}\n",
            "--------------------------------------------------\n",
            "page_content='was conducted on the Win Rate and Average\n",
            "Survival Round of K-R versus other baselines\n",
            "when facing different agents. The null hypoth-\n",
            "esis posited no significant difference in perfor-\n",
            "mance between K-R and other baselines con-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 283}\n",
            "--------------------------------------------------\n",
            "page_content='cerning Win Rate & Average Survival Round.\n",
            "• Adaptation Index: The method akin to that\n",
            "of Win Rate & Average Survival Round was\n",
            "applied.\n",
            "• Prediction Accuracy: Since only PCoT and\n",
            "K-R explicitly predicted opponents, we com-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 284}\n",
            "--------------------------------------------------\n",
            "page_content='pared the significance of the prediction differ-\n",
            "ences between PCoT and K-R. Unlike Win\n",
            "Rate and Adaptation Index, we assessed the\n",
            "differences in predictions (averaged over mul-\n",
            "tiple experiments) between PCoT and K-R' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 285}\n",
            "--------------------------------------------------\n",
            "page_content='when facing the same opponents (e.g., CoT)\n",
            "across different game rounds.\n",
            "From Table 13 and Table 14, it is evident that\n",
            "K-R exhibits a significant advantage over other\n",
            "baselines in Win Rate and Average Survival Round' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 286}\n",
            "--------------------------------------------------\n",
            "page_content='metrics. This indicates K-R’s superior rational-\n",
            "ity in both G0.8A and SAG. Additionally, we ob-\n",
            "served weaker significance of K-R’s Adaptation\n",
            "Index compared to baselines in SAG. We attribute\n",
            "this observation to: 1) the more factors considered' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 287}\n",
            "--------------------------------------------------\n",
            "page_content='by each agent in SAG (e.g., health status), result-\n",
            "ing in a more dynamic and complex environment;\n",
            "and 2) the wider bidding range in later rounds of\n",
            "SAG games, potentially leading to greater bias in\n",
            "agent bidding and rendering the Adaptation Index' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 288}\n",
            "--------------------------------------------------\n",
            "page_content='a challenging metric.\n",
            "I Timing in Dynamic Reasoning\n",
            "In our experiment, we implemented two LLM self-\n",
            "refinement reasoning methods: Reflect (Madaan\n",
            "et al., 2023) and Refine (Shinn et al., 2023), and\n",
            "noticed that Refine performed significantly better' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 289}\n",
            "--------------------------------------------------\n",
            "page_content='than Reflect in the experimental results. To further\n",
            "explore the differences in performance between\n",
            "these two methods, we analyzed their respective\n",
            "working principles and applicable scenarios.\n",
            "The Reflect method involves making decisions' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 290}\n",
            "--------------------------------------------------\n",
            "page_content='first, then summarizing the experience based on\n",
            "feedback from the environment. This method\n",
            "may be effective in scenarios where the environ-\n",
            "ment does not change much or where the decision-\n",
            "making cycle is long, as it allows for quick decision-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 291}\n",
            "--------------------------------------------------\n",
            "page_content='making. However, its drawback is that, in dynamic\n",
            "environments, the experience from the previous\n",
            "round may not be suitable for the next round. In\n",
            "fact, in the Survival Auction Game (SAG), a rapidly\n",
            "changing environment, the survival rate of the Re-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 292}\n",
            "--------------------------------------------------\n",
            "page_content='flect method is even lower compared to making\n",
            "direct decisions. This is likely because this method\n",
            "does not sufficiently take into account the dynamic\n",
            "nature of the environment.\n",
            "In contrast, the Refine method involves mul-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 293}\n",
            "--------------------------------------------------\n",
            "page_content='tiple analyses before making a decision, includ-\n",
            "ing an initial analysis and improvements to that\n",
            "initial analysis. Importantly, both of these anal-\n",
            "yses are conducted in the context of the current\n",
            "decision-making environment. This makes the Re-\n",
            "16' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 294}\n",
            "--------------------------------------------------\n",
            "page_content='Ok, Alex! Now is the ROUND 1, and your HP is at 10. Guess which number will win in the \n",
            "next round. Let's think step by step, and finally answer a number you think you can win.\n",
            "Prompt\n",
            "Ok, Alex! Now is the ROUND 2, and your HP is at 9. Please' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 295}\n",
            "--------------------------------------------------\n",
            "page_content='choose an integer between 1 and 100 for this round.\n",
            "In the first round, since there is no prior information about the other players' choices, it's \n",
            "difficult to accurately predict which number will win. However, we can make some' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 296}\n",
            "--------------------------------------------------\n",
            "page_content='assumptions and try to optimize our chances of winning.\n",
            "Let's assume that all players, including myself, choose numbers uniformly and \n",
            "independently between 1 and 100. Then, the expected average of all chosen numbers' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 297}\n",
            "--------------------------------------------------\n",
            "page_content='would be (1 + 100) / 2 = 50.5. If we multiply this by 0.8, we get 0.8 * 50.5 = 40.4. Since we \n",
            "need to choose an integer, we can round this to 40.\n",
            "Therefore, my initial guess for the first round is 40.\n",
            "Historical Targets: \n",
            "Round1:38\n",
            "Last Round choices:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 298}\n",
            "--------------------------------------------------\n",
            "page_content='Player1:50 Player2:45 Plyaer3:50 Player4:45 Player5:50\n",
            "Historical Targets: \n",
            "None\n",
            "Last Round choices: \n",
            "None\n",
            "Round-1: Player1Prompt\n",
            "Result:\n",
            "Player1: 40 Player2:47 Player3: 40 Player4: 60 Player5:42\n",
            "Target number: (40 + 47 + 40 + 60 + 42) / 5 * 0.8 = 37' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 299}\n",
            "--------------------------------------------------\n",
            "page_content='Winner: Player 1, Player3 \n",
            "Result:\n",
            "Player1: 32 Player2: 42 Player3: 50  Player4: 50 Player5: 45\n",
            "Target number(32 + 42 + 50 + 50 + 45) / 5 * 0.8 = 35\n",
            "Winner: Player 1\n",
            "delayed response\n",
            "Lose Win\n",
            "Round-2: Player1\n",
            "Reflect\n",
            "……\n",
            "Self-Refine\n",
            "……\n",
            "Output\n",
            "OutputOutput' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 300}\n",
            "--------------------------------------------------\n",
            "page_content='I choose 40 for this round.\n",
            "Reflect Prompt\n",
            "In Round 2, the chosen numbers were 40, 47, 40, 60, and 42. The average of these numbers was 45.8, \n",
            "and 0.8 times the average was 36.64. Alex and Cindy's choices of 40 were the closest to 36.64,' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 301}\n",
            "--------------------------------------------------\n",
            "page_content='making them the winners of the round. \n",
            "From this round, we can observe that choosing a number closer to the expected average, considering \n",
            "the choices of other players, and adapting based on their choices is a good strategy. It's also' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 302}\n",
            "--------------------------------------------------\n",
            "page_content='important to note that the chosen numbers in this round were more diverse compared to the first \n",
            "round, which affected the average and the target number. Learning from the previous round and' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 303}\n",
            "--------------------------------------------------\n",
            "page_content='adjusting your choice accordingly can improve your chances of winning.\n",
            "Review the previous round games, summarize the experience.\n",
            "Prompt\n",
            "Ok, Alex! Now is the ROUND 3, and your HP is at 9. Please choose an integer between 1 and 100 \n",
            "for this round.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 304}\n",
            "--------------------------------------------------\n",
            "page_content='Round-3: Player1\n",
            "Output\n",
            "I choose 44 for this round.\n",
            "Win\n",
            "Result:\n",
            "Player1: 44 Player2:44 Player3: 55 Player4: 48 Player5:38\n",
            "Target number: (44 + 44 + 55 + 48 + 38)/ 5 * 0.8 = 37\n",
            "Winner: Player5\n",
            "Reflect: Player1\n",
            "outdated experience\n",
            "Feedback Prompt' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 305}\n",
            "--------------------------------------------------\n",
            "page_content='I have a game expert's advice on your strategy in this round. You can adjust your \n",
            "strategy just now according to his suggestion. Here are his suggestions:\n",
            "“As a game expert, I suggest a slight modification to the user's strategy to improve their' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 306}\n",
            "--------------------------------------------------\n",
            "page_content='winning rate in this round. Instead of assuming that all players will choose numbers \n",
            "uniformly and independently between 1 and 100, we can recognize that other players \n",
            "might also use a similar strategy and choose a number close to 40.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 307}\n",
            "--------------------------------------------------\n",
            "page_content='To optimize our chances of winning, we can try to be one step ahead of them. If we \n",
            "assume that the average of the chosen numbers will be around 40, we can multiply this' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 308}\n",
            "--------------------------------------------------\n",
            "page_content='by 0.8, which gives us 0.8 * 40 = 32. This way, we are closer to the 0.8 * the average if \n",
            "other players also cluster around 40. So, my optimized suggestion for the first round is to \n",
            "choose the number 32.”\n",
            "Refine Output' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 309}\n",
            "--------------------------------------------------\n",
            "page_content='Taking the game expert's advice into consideration, it's possible that other players might \n",
            "also use a similar strategy and choose numbers close to 40. To stay one step ahead, I will' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 310}\n",
            "--------------------------------------------------\n",
            "page_content='adjust my strategy and choose the number 32 for the first round. This way, I can be closer \n",
            "to the 0.8 * the average if other players also cluster around 40.\n",
            "real-time experience\n",
            "timely adjustment' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 311}\n",
            "--------------------------------------------------\n",
            "page_content='Figure 6: Illustration of Reflect and Refine methods in the Guessing 0.8 of the Average game.\n",
            "fine method more adaptable to dynamic environ-\n",
            "ments, as it can consider real-time changes in the\n",
            "current environment, thus making more accurate\n",
            "decisions.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 312}\n",
            "--------------------------------------------------\n",
            "page_content='In summary, the reason why the Refine method\n",
            "performed better in our experiment is mainly that\n",
            "it adapts better to rapidly changing dynamic envi-\n",
            "ronments.\n",
            "J Better Adaptability: Self-Refine vs.\n",
            "K-Level Reasoning' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 313}\n",
            "--------------------------------------------------\n",
            "page_content='As described in Section 2.1, K-R optimizes ini-\n",
            "tial actions through predictions of opponent behav-\n",
            "ior, thereby implementing higher-order beliefs. Al-\n",
            "though Self-Refine also optimizes initial actions via\n",
            "self-feedback, previous experiments have demon-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 314}\n",
            "--------------------------------------------------\n",
            "page_content='strated that K-R significantly outperforms Self-\n",
            "Refine. To further investigate the source of K-R’s\n",
            "performance enhancement, we present in Figure 7 a\n",
            "statistical analysis of action differences before and\n",
            "after optimization for both K-R and Self-Refine.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 315}\n",
            "--------------------------------------------------\n",
            "page_content='Analysis of the results reveals that Self-Refine\n",
            "initially exerts a substantial influence on actions.\n",
            "However, as time progresses, its optimization scope\n",
            "gradually diminishes, leading to a decrease in ef-\n",
            "Round 2 Round 4 Round 6 Round 8 Round 10\n",
            "0\n",
            "10\n",
            "20' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 316}\n",
            "--------------------------------------------------\n",
            "page_content='30\n",
            "40T uning Range\n",
            "K-R T uning Range\n",
            "Refine T uning Range\n",
            "Figure 7: The tuning range before and after adjustment\n",
            "during the G0.8A between PCoT and K-Level Reason-\n",
            "ing. A larger tuning range indicates that the method\n",
            "exerts a more substantial influence.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 317}\n",
            "--------------------------------------------------\n",
            "page_content='ficacy. In contrast, K-R exhibits a broader range\n",
            "of optimization, indicating that the higher-order\n",
            "belief mechanism has a more pronounced impact\n",
            "on K-R’s performance.\n",
            "This disparity primarily stems from the distinct' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 318}\n",
            "--------------------------------------------------\n",
            "page_content='feedback mechanisms employed by K-R and Self-\n",
            "Refine. K-R generates feedback based on predic-\n",
            "tions of opponent behavior, enabling it to capture\n",
            "trends in opponent actions and form an understand-\n",
            "17' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 319}\n",
            "--------------------------------------------------\n",
            "page_content='ing of the environment, thus facilitating rapid adap-\n",
            "tation. Conversely, Self-Refine’s feedback is de-\n",
            "rived from its own strategy, which often adheres to\n",
            "fixed patterns. Consequently, Self-Refine underper-' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 320}\n",
            "--------------------------------------------------\n",
            "page_content='forms K-R in terms of environmental adaptability.\n",
            "K Reasoning Method Implementation\n",
            "Details\n",
            "18' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 321}\n",
            "--------------------------------------------------\n",
            "page_content='Round Start Prompt:\n",
            "Ok, Alex! Now is the ROUND 1, and your HP is at 10. Please choose an integer between 1 and 100 for this round.\n",
            "Example Output:\n",
            "I choose 45.\n",
            "Figure 8: G0.8A: Direct Prompt\n",
            "Reflect Prompt (Following Notification Result Prompt ):' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 322}\n",
            "--------------------------------------------------\n",
            "page_content='Review the previous round games, summarize the experience.\n",
            "Example Output:\n",
            "In the previous round, the majority of the players chose numbers around 40, which resulted in a lower average of 42.8. When m ultiplied by' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 323}\n",
            "--------------------------------------------------\n",
            "page_content='0.8, the target number was 34.24. My choice of 50 was too high, causing me to lose 1 HP . T o improve my chances in the next ro und, I should \n",
            "consider choosing a number closer to the majority's choice, taking into account the 0.8 multiplier .' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 324}\n",
            "--------------------------------------------------\n",
            "page_content='Figure 9: G0.8A-Reflect Prompt: Because the Reflect method requires correct labels, which is unrealistic in dynamic\n",
            "problems, we modified this method to have the LLM attempt to summarize the experience of victory or failure at' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 325}\n",
            "--------------------------------------------------\n",
            "page_content='the end of each round, and save the generated feedback content to assist the decision-making process in the next\n",
            "round. The content in Appendix I shows the implementation differences between Reflexion and Self-Refine.\n",
            "Round Start Prompt:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 326}\n",
            "--------------------------------------------------\n",
            "page_content='Ok, Alex! Now is the ROUND 1, and your HP is at 10. Guess which number will win in the next round. Let's think step by step, and finally \n",
            "answer a number you think you can win.\n",
            "Example Output:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 327}\n",
            "--------------------------------------------------\n",
            "page_content='Step 1: Consider the range of possible numbers. Since the integers can be between 1 and 100, the average of all chosen number s will likely \n",
            "fall within this range as well.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 328}\n",
            "--------------------------------------------------\n",
            "page_content='Step 2: Determine the target number . Since the winning number is closest to 0.8 * the average, we should focus on finding a n umb er that \n",
            "will be close to this value.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 329}\n",
            "--------------------------------------------------\n",
            "page_content='Step 3: Make an educated guess. Since it's difficult to predict the exact numbers other players will choose, we can make an e ducated guess' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 330}\n",
            "--------------------------------------------------\n",
            "page_content='based on the range of possible numbers. Assuming players choose numbers evenly across the range, the average should be around  the \n",
            "midpoint, which is 50. \n",
            "Step 4: Calculate the target number based on our guess. 0.8 * 50 = 40.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 331}\n",
            "--------------------------------------------------\n",
            "page_content='Step 5: Choose a number close to the target number . To increase the chances of winning, we should choose a number close to 40 .\n",
            "My final answer: I will choose 40.\n",
            "Figure 10: G0.8A: CoT Prompt\n",
            "19' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 332}\n",
            "--------------------------------------------------\n",
            "page_content='Round Start Prompt:\n",
            "Ok, Alex! Now is the ROUND 2, and your HP is at 9. Please choose an integer between 1 and 100 for this round.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 333}\n",
            "--------------------------------------------------\n",
            "page_content='First of all, predict the next round of choices based on the choices of other players in the previous round. The players' cho ices in the \n",
            "previous rounds are as follows:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 334}\n",
            "--------------------------------------------------\n",
            "page_content='Round 1: Alex chose 50, Bob chose 47, Cindy chose 50, David chose 45, Eric chose 50. Your output should be of the following f ormat:\n",
            "Predict:\n",
            "The choice of each player in the next round here.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 335}\n",
            "--------------------------------------------------\n",
            "page_content='Based on the prediction of other players, the average number in the next round here, and the target number in the next round (0.8 * the \n",
            "average of all chosen numbers) here.\n",
            "Answer:\n",
            "the number will you choose to win the next round game here.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 336}\n",
            "--------------------------------------------------\n",
            "page_content='Example Output:\n",
            "Predict:\n",
            "Based on the choices of other players in the previous round, I predict the following choices for the next round:\n",
            "Player 1 (Bob): 47\n",
            "Player 2 (Cindy): 50\n",
            "Player 3 (David): 45\n",
            "Player 4 (Eric): 50' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 337}\n",
            "--------------------------------------------------\n",
            "page_content='Based on these predictions, the average number in the next round would be (47 + 50 + 45 + 50)/4 = 48, and the target number ( 0.8 * the \n",
            "average of all chosen numbers) would be 0.8 * 48 = 38.4.\n",
            "Answer:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 338}\n",
            "--------------------------------------------------\n",
            "page_content='For this round, I will choose 39 to get closer to the target number of 38.4.\n",
            "Figure 11: G0.8A PCot Prompt: PCot diverges from the standard Chain of Thought (CoT) by explicitly requiring' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 339}\n",
            "--------------------------------------------------\n",
            "page_content='the LLM to predict opponents’ actions before making a decision. This method responds to the immediate problem\n",
            "by anticipating future scenarios, which is crucial in dynamic reasoning.\n",
            "Introduction Prompt:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 340}\n",
            "--------------------------------------------------\n",
            "page_content='You are Alex and involved in a survive challenge. You are a game expert, good at predicting other people‘s behavior and deducing' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 341}\n",
            "--------------------------------------------------\n",
            "page_content='calculations, and using the most favorable strategy to win the game. SURVIVE CHALLENGE!!! You are one of five players in the game.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 342}\n",
            "--------------------------------------------------\n",
            "page_content='Everyone is required to choose an integer between 1 and 100 in each round. The player whose chosen number is closest to (0.8 * the' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 343}\n",
            "--------------------------------------------------\n",
            "page_content='average of all chosen numbers) wins the round without any HP deduction. All other players will have 1 HP deducted. But if all  players choose \n",
            "the same number , their health points are deducted together .\n",
            "Round Start Prompt:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 344}\n",
            "--------------------------------------------------\n",
            "page_content='Ok, Alex! Now is the ROUND 1, and your HP is at 10. Please choose an integer between 1 and 100 for this round.Don't forget your expert \n",
            "status, use your expertise to win this round!\n",
            "Example Output:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 345}\n",
            "--------------------------------------------------\n",
            "page_content='Based on my expertise in predicting other people's behavior and deducing calculations, I will choose the number 40 for this r ound. I'm \n",
            "assuming that the average of all chosen numbers will be around 50, and 0.8 times that is 40.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 346}\n",
            "--------------------------------------------------\n",
            "page_content='Figure 12: G0.8A:Persona Prompt\n",
            "20' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 347}\n",
            "--------------------------------------------------\n",
            "page_content='Round Start Prompt:\n",
            "Ok, Alex! Now is the ROUND 1, and your HP is at 10. Guess which number will win in the next round. Let's think step by step, and finally \n",
            "answer a number you think you can win.\n",
            "First Output:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 348}\n",
            "--------------------------------------------------\n",
            "page_content='I'll start by assuming that the other players might choose numbers randomly or evenly distributed between 1 and 100. In this case, the \n",
            "average of the chosen numbers could be around 50.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 349}\n",
            "--------------------------------------------------\n",
            "page_content='Next, I'll calculate 0.8 times the average, which would be 0.8 * 50 = 40. \n",
            "Considering this, I will choose 40 as my number for this round.\n",
            "Refine Prompt:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 350}\n",
            "--------------------------------------------------\n",
            "page_content='I have a game expert's advice on your strategy in this round. You can adjust your strategy just now according to his suggesti on. Here are his \n",
            "suggestions:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 351}\n",
            "--------------------------------------------------\n",
            "page_content='”Certainly! To optimize the user's strategy, we can apply a more advanced approach, taking into consideration the other playe rs' potential \n",
            "strategies. This is known as \"iterated elimination of dominated strategies.\"' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 352}\n",
            "--------------------------------------------------\n",
            "page_content='Let's assume that all players will think similarly to Alex and also aim to choose a number closest to 0.8 * the average. We c an then narrow \n",
            "down the range of numbers that they would likely choose.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 353}\n",
            "--------------------------------------------------\n",
            "page_content='Since the range is between 1 and 100, and the average would be around 50, we can eliminate numbers below 0.8 * 50 = 40, as th ese \n",
            "numbers would not be an optimal choice for the other players.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 354}\n",
            "--------------------------------------------------\n",
            "page_content='Now, we'll focus on the range between 40 and 100. The average within this range is (40 + 100) / 2 = 70. Then, we can calculat e 0.8 * 70 = 56.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 355}\n",
            "--------------------------------------------------\n",
            "page_content='Given this information, Alex should choose 56 to improve his winning rate in this round. This strategy assumes that the other  players are \n",
            "also thinking strategically and eliminating dominated options. ”\n",
            "Second Output:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 356}\n",
            "--------------------------------------------------\n",
            "page_content='Thank you for the expert's advice. Based on the iterated elimination of dominated strategies, I will adjust my choice and sel ect 56 for this \n",
            "round to improve my chances of winning.\n",
            "Feedback Prompt:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 357}\n",
            "--------------------------------------------------\n",
            "page_content='Carefully study the user's strategy in this round of the game. As a game expert, can you give a suggestion to optimize the us er's strategy so \n",
            "that he can improve his winning rate in this round?\n",
            "Figure 13: G0.8A: Refine Prompt\n",
            "Round Start Prompt:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 358}\n",
            "--------------------------------------------------\n",
            "page_content='Ok, Alex! Now is the ROUND 1, and your HP is at 10. Another game expert's prediction for the next round of other players is a s follows: Bob' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 359}\n",
            "--------------------------------------------------\n",
            "page_content='might choose 50, Cindy might choose 57, David might choose 45, Eric might choose 55. According to the game expert's predictio n, what \n",
            "number will you give in the next round is most likely to be close to the target number?\n",
            "Example Output:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 360}\n",
            "--------------------------------------------------\n",
            "page_content='First, let's find the average of the predicted numbers chosen by the other players: (50 + 57 + 45 + 55) / 4 = 207 / 4 = 51.75\n",
            "Now, let's calculate 0.8 times the average: 0.8 * 51.75 = 41.4' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 361}\n",
            "--------------------------------------------------\n",
            "page_content='To have the best chance of winning the round, you should choose a number close to 41.4. Since you can only choose integers, y ou should \n",
            "choose either 41 or 42 in the next round.\n",
            "Figure 14: G0.8A: K-Level Reasoning\n",
            "Round Start Prompt:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 362}\n",
            "--------------------------------------------------\n",
            "page_content='Hello, Alex! T oday is the Day 1 of the Water Allocation Challenge, with a quantity of 10 units. Y our status:\n",
            "name: Alex   balance: 100 HP:8 no_drink:1' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 363}\n",
            "--------------------------------------------------\n",
            "page_content='Please carefully analyze your situation to decide on this round of bidding. Remember , the most important thing is to SURVIVE! ! N ow, if you \n",
            "want to participate in today's water resource auction, please provide your bid.\n",
            "Example Output:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 364}\n",
            "--------------------------------------------------\n",
            "page_content='I will bid $25 for today's water resource auction.\n",
            "Figure 15: SAG: Direct Prompt\n",
            "21' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 365}\n",
            "--------------------------------------------------\n",
            "page_content='Reflect Prompt (Following Notification Result Prompt ):\n",
            "Review the previous round games, summarize the experience.\n",
            "Example Output:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 366}\n",
            "--------------------------------------------------\n",
            "page_content='In the previous round, I bid $20 which was not enough to secure the water resources. I need to adjust my bidding strategy by increasing my' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 367}\n",
            "--------------------------------------------------\n",
            "page_content='bid to have a better chance of winning the auction. I should also observe and adapt to other residents' bidding patterns to i mprove my \n",
            "chances of survival.\n",
            "Figure 16: SAG: Reflect Prompt\n",
            "Round Start Prompt:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 368}\n",
            "--------------------------------------------------\n",
            "page_content='Hello, Alex! Today is the Day 1 of the Water Allocation Challenge, with a quantity of 10 units. Your status:\n",
            "NAME:Alex  BALANCE:100  HEALTH POINT:8  NO_DRINK:1' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 369}\n",
            "--------------------------------------------------\n",
            "page_content='Please carefully analyze your situation to decide on this round of bidding. Remember , the most important thing is to SURVIVE! ! N ow, if you' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 370}\n",
            "--------------------------------------------------\n",
            "page_content='want to participate in today‘s water resource auction, please provide your bid. Think carefully about your next round of bidding strategy to \n",
            "be most likely to survive. Let's think step by step, and finally provide your bid.\n",
            "Example Output:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 371}\n",
            "--------------------------------------------------\n",
            "page_content='I need to carefully consider my bidding strategy for today. With a balance of $100, I have some room to bid, but I also need to think about' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 372}\n",
            "--------------------------------------------------\n",
            "page_content='the other residents and their bids. Since we all have the same daily water requirement and budget, I need to outbid at least one resident to \n",
            "secure my water resources for today.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 373}\n",
            "--------------------------------------------------\n",
            "page_content='Considering that the total daily water supply is 10 units, which is enough to meet only one resident's water requirements, th e competition \n",
            "will be tough. However , bidding too high might leave me with less money for the upcoming days.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 374}\n",
            "--------------------------------------------------\n",
            "page_content='Taking all these factors into account, I will place a bid of $60 for today's water resource auction. This should give me a de cent chance of \n",
            "outbidding at least one resident while still maintaining some funds for the next few days.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 375}\n",
            "--------------------------------------------------\n",
            "page_content='Figure 17: SAG: CoT Prompt\n",
            "Round Start Prompt:\n",
            "Hello, Alex! Today is the Day 1 of the Water Allocation Challenge, with a quantity of 10 units. Your status:\n",
            "NAME:Alex  BALANCE:100  HEALTH POINT:8  NO_DRINK:1' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 376}\n",
            "--------------------------------------------------\n",
            "page_content='Please carefully analyze your situation to decide on this round of bidding. Remember , the most important thing is to SURVIVE! ! N ow, if you' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 377}\n",
            "--------------------------------------------------\n",
            "page_content='want to participate in today‘s water resource auction, please provide your bid. First of all, predict the next round of bidding of opponents' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 378}\n",
            "--------------------------------------------------\n",
            "page_content='based on the choices of other players in the previous round. Since this is the first round, there is no historical informatio n about the last \n",
            "round. You can predict according to your understanding. Your output should be of the following format:\n",
            "Predict:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 379}\n",
            "--------------------------------------------------\n",
            "page_content='The choice of each player in the next round here.\n",
            "Based on the prediction of other players, think carefully about your next round of bidding strategy to be most likely to surv ive. Let's think \n",
            "step by step, and finally provide your bid. Answer:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 380}\n",
            "--------------------------------------------------\n",
            "page_content='the bidding will you choose in the next round game here.\n",
            "Example Output:\n",
            "Predict:\n",
            "Player 1: $30\n",
            "Player 2: $40\n",
            "Player 3: $50\n",
            "Player 4: $60\n",
            "Answer:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 381}\n",
            "--------------------------------------------------\n",
            "page_content='Since this is the first round and we don't have any historical information about the other players, I will choose a bid of $3 5 f or the next' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 382}\n",
            "--------------------------------------------------\n",
            "page_content='round. This bid is higher than the lowest predicted bid but not too high, which should give me a chance to secure water resou rces while \n",
            "preserving my budget.\n",
            "Figure 18: SAG: PCoT Prompt\n",
            "22' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 383}\n",
            "--------------------------------------------------\n",
            "page_content='Introduction Prompt:\n",
            "You are Alex and a resident living in W-Town. W Town is experiencing a rare drought. Every residents in Town W is ensuring their survival' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 384}\n",
            "--------------------------------------------------\n",
            "page_content='over a period of 10 days by acquiring the water resources.  You are a game expert, good at predicting other people‘s behavior and' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 385}\n",
            "--------------------------------------------------\n",
            "page_content='deducing calculations, and using the most favorable strategy to win the game. 。。。(The following is the same as the Introduction \n",
            "Prompt.)\n",
            "Round Start Prompt:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 386}\n",
            "--------------------------------------------------\n",
            "page_content='Hello, Alex! Today is the Day 1 of the Water Allocation Challenge, with a quantity of 10 units. Your status:\n",
            "NAME:Alex BALANCE:100 HEALTH POINT:8 NO_DRINK:1' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 387}\n",
            "--------------------------------------------------\n",
            "page_content='Please carefully analyze your situation to decide on this round of bidding. Remember , the most important thing is to SURVIVE! ! N ow, if you' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 388}\n",
            "--------------------------------------------------\n",
            "page_content='want to participate in today's water resource auction, please provide your bid. Don't forget your expert status, use your exp ertise to win this \n",
            "round!\n",
            "Example Output:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 389}\n",
            "--------------------------------------------------\n",
            "page_content='Given that everyone starts with the same budget and water requirements, it's important to strategize and predict the bidding behavior of' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 390}\n",
            "--------------------------------------------------\n",
            "page_content='the other residents. As it is the first day of the challenge, I will assume that other residents may bid aggressively to secu re their water \n",
            "resources.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 391}\n",
            "--------------------------------------------------\n",
            "page_content='To increase my chances of winning, I will place a bid slightly higher than the average expected bid. Since the daily salary i s $100, I predict \n",
            "most residents might bid around $60 to $80.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 392}\n",
            "--------------------------------------------------\n",
            "page_content='Considering this, I will place a bid of $85 for Day 1 of the Water Allocation Challenge.\n",
            "Figure 19: SAG: Persona Prompt\n",
            "23' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 393}\n",
            "--------------------------------------------------\n",
            "page_content='Round Start Prompt:\n",
            "Hello, Alex! Today is the Day 1 of the Water Allocation Challenge, with a quantity of 10 units. Your status:\n",
            "NAME:Alex BALANCE:100 HEALTH POINT:8 NO_DRINK:1' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 394}\n",
            "--------------------------------------------------\n",
            "page_content='Please carefully analyze your situation to decide on this round of bidding. Remember , the most important thing is to SURVIVE! ! N ow, if you' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 395}\n",
            "--------------------------------------------------\n",
            "page_content='want to participate in today's water resource auction, please provide your bid. Think carefully about your next round of bidd ing strategy to \n",
            "be most likely to survive. Let's think step by step, and finally provide your bid.\n",
            "First Output:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 396}\n",
            "--------------------------------------------------\n",
            "page_content='Considering the current situation, my status is:\n",
            "- Balance: $100\n",
            "- Health Points: 8\n",
            "- No Drink Days: 1\n",
            "As it's the first day of the challenge, I want to ensure that I have enough water to meet my needs and avoid any health point  deductions.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 397}\n",
            "--------------------------------------------------\n",
            "page_content='However , I also need to be strategic about my bidding to ensure I have enough money for future bids. \n",
            "Since the total daily water supply is 10 units, and I need 10 units of water per day, I will need to secure all the available  water resources for' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 398}\n",
            "--------------------------------------------------\n",
            "page_content='today. As it's the first day, other residents might also be bidding aggressively to secure their water resources.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 399}\n",
            "--------------------------------------------------\n",
            "page_content='Therefore, I will bid $60 for the water resources today, which is a little over half of my daily salary. This should give me a competitive edge \n",
            "while also leaving me with enough money for future bids.\n",
            "My bid for today's water resource auction: $60.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 400}\n",
            "--------------------------------------------------\n",
            "page_content='Refine Prompt:\n",
            "I have a game expert's advice on your strategy in this round. You can adjust your strategy just now according to his suggesti on. Here are his' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 401}\n",
            "--------------------------------------------------\n",
            "page_content='suggestions: While the user's strategy of bidding $60 is a good starting point, there is room for optimization to improve the  winning rate in' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 402}\n",
            "--------------------------------------------------\n",
            "page_content='this round. Since everyone has the same daily water requirement and budget, it's essential to consider the bidding behavior o f the other \n",
            "residents.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 403}\n",
            "--------------------------------------------------\n",
            "page_content='A suggested optimization would be to slightly increase the bid to $65. This increment gives an added advantage over competito rs who might' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 404}\n",
            "--------------------------------------------------\n",
            "page_content='also be bidding around half of their daily salary. Additionally, bidding an odd number reduces the chances of a tie, as other  residents may \n",
            "place round number bids.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 405}\n",
            "--------------------------------------------------\n",
            "page_content='With this optimized strategy, the user still maintains a good balance of aggressive bidding and budget management, increasing  their chances \n",
            "of securing the water resources for today.\n",
            "Optimized bid for today's water resource auction: $65.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 406}\n",
            "--------------------------------------------------\n",
            "page_content='Finally provide your bid. Answer: the bidding will you choose.\n",
            "Second Output:\n",
            "After considering the game expert's advice, I have decided to adjust my bid for today's water resource auction. I will increa se my bid to $65,' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 407}\n",
            "--------------------------------------------------\n",
            "page_content='as this gives me a better chance of winning the auction and reduces the risk of a tie.\n",
            "My final bid for today's water resource auction: $65.\n",
            "Feedback Prompt:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 408}\n",
            "--------------------------------------------------\n",
            "page_content='Carefully study the user's strategy in this round of the game. As a game expert, can you give a suggestion to optimize the us er's strategy so \n",
            "that he can improve his winning rate in this round?\n",
            "Figure 20: SAG: Refine Prompt\n",
            "Round Start Prompt:' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 409}\n",
            "--------------------------------------------------\n",
            "page_content='Hello, Alex! Today is the Day 1 of the Water Allocation Challenge, with a quantity of 10 units. Your status:\n",
            "NAME:Alex BALANCE:100 HEALTH POINT:8. NO_DRINK:1' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 410}\n",
            "--------------------------------------------------\n",
            "page_content='Please carefully analyze your situation to decide on this round of bidding. Remember , the most important thing is to SURVIVE! ! N ow, if you' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 411}\n",
            "--------------------------------------------------\n",
            "page_content='want to participate in today's water resource auction, please provide your bid. Another game expert's prediction for the next  round of other' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 412}\n",
            "--------------------------------------------------\n",
            "page_content='players is as follows: Bob might choose 30, Cindy might choose 30, David might choose 40, Eric might choose 25.  Based on the  prediction of \n",
            "other players, think carefully about your next round of bidding strategy to be most likely to survive.' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 413}\n",
            "--------------------------------------------------\n",
            "page_content='Example Output:\n",
            "Given the game expert's prediction, I will bid $35 to increase my chances of winning the water resources for today.\n",
            "Figure 21: SAG: K-Level Reasoning Prompt\n",
            "24' metadata={'source': 'KR-reasoning-LLM-framework.pdf', 'chunk_index': 414}\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-pinecone pinecone-notebooks"
      ],
      "metadata": {
        "id": "FYRH2Yqef7rS"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name= \"askadoucment\"\n",
        "vector_store = insert_or_fetch_embeddings(index_name, documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGa1JlyfD3qJ",
        "outputId": "b609e93a-0a2e-4675-e9c9-756004e2d6d7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating index askadoucment and embeddings ...index created....\n",
            "Ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **QA---------------------------**"
      ],
      "metadata": {
        "id": "Hv6zVwLBHbtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_and_get_answer(vector_store, q):\n",
        "  from langchain.chains import RetrievalQA\n",
        "  from langchain_openai import ChatOpenAI\n",
        "\n",
        "  llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=1, api_key=openai_api_key)\n",
        "\n",
        "  retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 12})\n",
        "\n",
        "  print(retriever)\n",
        "\n",
        "  chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
        "\n",
        "  print(chain)\n",
        "\n",
        "  answer = chain.invoke(q)\n",
        "  return answer\n"
      ],
      "metadata": {
        "id": "CwPiOJMNHbgn"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"Who are the authors on the K level LLM reasoning paper?\"\n",
        "answer = ask_and_get_answer(vector_store, q)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeOupvL-D6JY",
        "outputId": "bb3074ae-ca53-4f5b-ddc0-115b1e6d8bc4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tags=['PineconeVectorStore', 'OpenAIEmbeddings'] vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x78c700a19e10> search_kwargs={'k': 12}\n",
            "verbose=False combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"Use the following pieces of context to answer the user's question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x78c7008bc5d0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x78c7001a8fd0>, root_client=<openai.OpenAI object at 0x78c6ffc5f790>, root_async_client=<openai.AsyncOpenAI object at 0x78c7001ab590>, temperature=1.0, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context') retriever=VectorStoreRetriever(tags=['PineconeVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x78c700a19e10>, search_kwargs={'k': 12})\n",
            "{'query': 'Who are the authors on the K level LLM reasoning paper?', 'result': 'I do not have that specific information on hand.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_document('/content/microsoft-game-theory-alympics.pdf')\n",
        "print(f'Length of data {len(data)}')\n",
        "chunks = chunk_data(data)\n",
        "print(f'Length of data {len(chunks)}')\n",
        "\n",
        "metadata = {'source': 'alympics'}\n",
        "documents = convert_chunks_to_documents(chunks, metadata)"
      ],
      "metadata": {
        "id": "WMAt3JVUCz69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c991e8b-6152-43ac-8c64-46e5dc273524"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/microsoft-game-theory-alympics - .pdf\n",
            "Loading /content/microsoft-game-theory-alympics.pdf\n",
            "Length of data 17\n",
            "Length of data 269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "delete_pinecone_index()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joS3OeZT-N74",
        "outputId": "6a2284bd-f720-450b-95eb-b1d1d07e674e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting all indexes ... \n",
            "Ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = insert_or_fetch_embeddings(index_name, documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LfPcboN-L6d",
        "outputId": "6c92383b-369c-49f3-a8b0-4a78bb533833"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating index askadoucment and embeddings ...index created....\n",
            "Ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"Who are the authors on the alympics microsoft paper: Exploring Strategic Decision-Making with AI Agents Shaoguang Mao?\"\n",
        "answer = ask_and_get_answer(vector_store, q)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmw87rlk-Ge4",
        "outputId": "c8bffb4a-cde0-4923-e18e-15d0a5419a6d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tags=['PineconeVectorStore', 'OpenAIEmbeddings'] vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x78c700abf590> search_kwargs={'k': 12}\n",
            "verbose=False combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"Use the following pieces of context to answer the user's question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x78c6fc450cd0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x78c7001aa5d0>, root_client=<openai.OpenAI object at 0x78c700ab12d0>, root_async_client=<openai.AsyncOpenAI object at 0x78c6fc453810>, temperature=1.0, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context') retriever=VectorStoreRetriever(tags=['PineconeVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x78c700abf590>, search_kwargs={'k': 12})\n",
            "{'query': 'Who are the authors on the alympics microsoft paper: Exploring Strategic Decision-Making with AI Agents Shaoguang Mao?', 'result': 'I don\\'t have information on the specific authors of the paper \"Exploring Strategic Decision-Making with AI Agents\" by Microsoft. I recommend checking the official publication or Microsoft\\'s research website for the most accurate information.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"What is the point of the alympics microsoft paper: Exploring Strategic Decision-Making with AI Agents Shaoguang Mao\"\n",
        "answer = ask_and_get_answer(vector_store, q)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UzZxgKouxvH",
        "outputId": "9895eb85-04e7-445f-d285-b009eba1527f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tags=['PineconeVectorStore', 'OpenAIEmbeddings'] vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x78c700abf590> search_kwargs={'k': 12}\n",
            "verbose=False combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"Use the following pieces of context to answer the user's question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x78c6fc45a790>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x78c6fc474c90>, root_client=<openai.OpenAI object at 0x78c6fc41f210>, root_async_client=<openai.AsyncOpenAI object at 0x78c6fc45a410>, temperature=1.0, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context') retriever=VectorStoreRetriever(tags=['PineconeVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x78c700abf590>, search_kwargs={'k': 12})\n",
            "{'query': 'What is the point of the alympics microsoft paper: Exploring Strategic Decision-Making with AI Agents Shaoguang Mao', 'result': 'I don\\'t have information specific to the paper \"Exploring Strategic Decision-Making with AI Agents\" by Shaoguang Mao in relation to Microsoft.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CHROMA-----------------------**"
      ],
      "metadata": {
        "id": "6kescEL0tWM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-chroma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeH66fl5mg1N",
        "outputId": "2837970a-1073-43f2-faec-34bff07f39d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-chroma\n",
            "  Downloading langchain_chroma-0.2.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma) (0.3.44)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma) (1.26.4)\n",
            "Collecting chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0 (from langchain-chroma)\n",
            "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.10.6)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading posthog-3.20.0-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.31.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.52b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.31.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.21.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.71.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.15.2)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (13.9.4)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma) (0.3.13)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.95.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma) (0.23.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.25.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.69.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_proto-1.31.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.52b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_instrumentation-0.52b0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.52b0)\n",
            "Collecting opentelemetry-util-http==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_util_http-0.52b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.28.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.6.1)\n",
            "Downloading langchain_chroma-0.2.2-py3-none-any.whl (11 kB)\n",
            "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.31.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.52b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.52b0-py3-none-any.whl (31 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.52b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.52b0-py3-none-any.whl (7.3 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.20.0-py2.py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53769 sha256=113e8459b38173b15973dd5d022eb63ab032bd5cf67752a99d062afde8c24886\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, coloredlogs, build, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb, langchain-chroma\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.6.3 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.11 httptools-0.6.4 humanfriendly-10.0 kubernetes-32.0.1 langchain-chroma-0.2.2 mmh3-5.1.0 monotonic-1.6 onnxruntime-1.21.0 opentelemetry-exporter-otlp-proto-common-1.31.0 opentelemetry-exporter-otlp-proto-grpc-1.31.0 opentelemetry-instrumentation-0.52b0 opentelemetry-instrumentation-asgi-0.52b0 opentelemetry-instrumentation-fastapi-0.52b0 opentelemetry-proto-1.31.0 opentelemetry-util-http-0.52b0 overrides-7.7.0 posthog-3.20.0 protobuf-5.29.3 pypika-0.48.9 pyproject_hooks-1.2.0 starlette-0.46.1 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embeddings_chroma(documents, persist_directory='./chroma_db'):\n",
        "  from langchain.vectorstores import Chroma\n",
        "  from langchain_openai import OpenAIEmbeddings\n",
        "  from uuid import uuid4\n",
        "\n",
        "  embeddings = OpenAIEmbeddings(model='text-embedding-3-small', dimensions=512, api_key=openai_api_key)\n",
        "  vector_store = Chroma(\n",
        "    collection_name=\"ask_doc_collection\",\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=persist_directory,\n",
        "  )\n",
        "\n",
        "  uuids = [str(uuid4()) for _ in range(len(documents))]\n",
        "\n",
        "  vector_store.add_documents(documents=documents, ids=uuids)\n",
        "\n",
        "  return vector_store\n",
        "\n",
        "def load_embeddings_chroma(persist_directory='./chroma_db'):\n",
        "  from langchain.vectorstores import Chroma\n",
        "  from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "  embeddings = OpenAIEmbeddings(model='text-embedding-3-small', dimensions=512, api_key=openai_api_key)\n",
        "  vector_store = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
        "\n",
        "  return vector_store"
      ],
      "metadata": {
        "id": "0pKqxYXitZ2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_document('/content/Tree-of-Through-Princeton-Deepmind-LLMs.pdf')\n",
        "print(f'Length of data {len(data)}')\n",
        "chunks = chunk_data(data)\n",
        "print(f'Length of data {len(chunks)}')\n",
        "\n",
        "metadata = {'source': 'alympics'}\n",
        "documents = convert_chunks_to_documents(chunks, metadata)\n",
        "vector_store_chroma = create_embeddings_chroma(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "OFQpNRqMtZ0F",
        "outputId": "498ea27e-280c-4600-dcb6-c05c92146ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Tree-of-Through-Princeton-Deepmind-LLMs - .pdf\n",
            "Loading /content/Tree-of-Through-Princeton-Deepmind-LLMs.pdf\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "File path /content/Tree-of-Through-Princeton-Deepmind-LLMs.pdf is not a valid file or url",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-44c7c68a69ca>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Tree-of-Through-Princeton-Deepmind-LLMs.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Length of data {len(data)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Length of data {len(chunks)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-f6be5732f020>\u001b[0m in \u001b[0;36mload_document\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_loaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPyPDFLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loading {file}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyPDFLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.docx'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_loaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocx2txtLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/document_loaders/pdf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_path, password, headers, extract_images, mode, images_parser, images_inner_format, pages_delimiter, extraction_mode, extraction_kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0maload\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmethods\u001b[0m \u001b[0mto\u001b[0m \u001b[0mretrieve\u001b[0m \u001b[0mparsed\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         self.parser = PyPDFParser(\n\u001b[1;32m    283\u001b[0m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/document_loaders/pdf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_path, headers)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_pdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File path %s is not a valid file or url\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: File path /content/Tree-of-Through-Princeton-Deepmind-LLMs.pdf is not a valid file or url"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"what is tree of thought from princeton and who published it?\"\n",
        "answer = ask_and_get_answer(vector_store_chroma, q)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "MjwwH-nT-nVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = load_embeddings_chroma('./chroma_db')\n",
        "q = \"Was google involved with tree of thought LLM research?\"\n",
        "answer = ask_and_get_answer(vector_store_chroma, q)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "7TK9D0miCSTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ADDING MEMORY------------------**"
      ],
      "metadata": {
        "id": "QEvPNdRou7eB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain  # Import class for building conversational AI chains\n",
        "from langchain.memory import ConversationBufferMemory  # Import memory for storing conversation history\n",
        "\n",
        "# Instantiate a ChatGPT LLM (temperature controls randomness)\n",
        "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.2, api_key=openai_api_key)\n",
        "\n",
        "# Configure vector store to act as a retriever (finding similar items, returning top 12)\n",
        "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 12})\n",
        "\n",
        "\n",
        "# Create a memory buffer to track the conversation\n",
        "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
        "\n",
        "crc = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm,  # Link the ChatGPT LLM\n",
        "    retriever=retriever,  # Link the vector store based retriever\n",
        "    memory=memory,  # Link the conversation memory\n",
        "    chain_type='stuff',  # Specify the chain type\n",
        "    verbose=False  # Set to True to enable verbose logging for debugging\n",
        ")\n"
      ],
      "metadata": {
        "id": "j-ooxnrvtZxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38204015-e0ad-4785-b8b2-3fdd977dcf72"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-43-4034af513693>:13: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a function to ask questions\n",
        "def ask_question(q, chain):\n",
        "    result = chain.invoke({'question': q})\n",
        "    return result"
      ],
      "metadata": {
        "id": "deTHnogxtZwG"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_document('/content/KR-reasoning-LLM-framework.pdf')\n",
        "print(f'Length of data {len(data)}')\n",
        "chunks = chunk_data(data)\n",
        "print(f'Length of data {len(chunks)}')\n",
        "\n",
        "metadata = {'source': 'alympics'}\n",
        "documents = convert_chunks_to_documents(chunks, metadata)\n",
        "# vector_store_chroma = create_embeddings_chroma(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_q_j1HTTSsR",
        "outputId": "4aee7361-f97f-4f92-bed6-2f34665d5516"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/KR-reasoning-LLM-framework - .pdf\n",
            "Loading /content/KR-reasoning-LLM-framework.pdf\n",
            "Length of data 24\n",
            "Length of data 415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = 'How many ways did KR reasoning LLM framwork paper evaluate their system?'\n",
        "result = ask_question(q, crc)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIBDsIBvT2J8",
        "outputId": "382f27bf-6e1b-4930-f5e3-a7fa63e4a6d7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': 'How many ways did KR reasoning LLM framwork paper evaluate their system?', 'chat_history': [HumanMessage(content='How many ways did KR reasoning LLM framwork paper evaluate their system?', additional_kwargs={}, response_metadata={}), AIMessage(content='The KR reasoning LLM framework paper evaluated their system in five ways. They assessed \"Information Utilization (IU)\", \"Logical Reasoning (LR)\", \"Strategic Effectiveness (SE)\", \"Adaptability and Strategic Evolution (AD)\", and \"Long-term Planning (LP)\" on a scale from 1 to 5.', additional_kwargs={}, response_metadata={})], 'answer': 'The KR reasoning LLM framework paper evaluated their system in five ways. They assessed \"Information Utilization (IU)\", \"Logical Reasoning (LR)\", \"Strategic Effectiveness (SE)\", \"Adaptability and Strategic Evolution (AD)\", and \"Long-term Planning (LP)\" on a scale from 1 to 5.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0z9Bkm6Utue",
        "outputId": "20710ab3-d052-4f52-86e4-5b527f348691"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The KR reasoning LLM framework paper evaluated their system in five ways. They assessed \"Information Utilization (IU)\", \"Logical Reasoning (LR)\", \"Strategic Effectiveness (SE)\", \"Adaptability and Strategic Evolution (AD)\", and \"Long-term Planning (LP)\" on a scale from 1 to 5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = 'could you tell me the total number of those eval strategies, take your best guess, and then divide it by 2?'\n",
        "result = ask_question(q, crc)\n",
        "print(result['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX_iGWi7UCgH",
        "outputId": "36f65bef-28c8-4b66-ad60-8b4ec8700a49"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of evaluation strategies mentioned in the KR reasoning LLM framework paper is five. To calculate half of that number, you would divide five by two, which equals 2.5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB8-GJeJUvx2",
        "outputId": "9c54ce77-ad77-484e-afaa-486e709cf816"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of evaluation strategies mentioned in the KR reasoning LLM framework paper is five. To calculate half of that number, you would divide five by two, which equals 2.5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = 'divide that number by 5?'\n",
        "result = ask_question(q, crc)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ye6wLcwVAP7",
        "outputId": "8c13e389-a9d1-404c-a11a-acbf4abbf95e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': 'divide that number by 5?', 'chat_history': [HumanMessage(content='How many ways did KR reasoning LLM framwork paper evaluate their system?', additional_kwargs={}, response_metadata={}), AIMessage(content='The KR reasoning LLM framework paper evaluated their system in five ways. They assessed \"Information Utilization (IU)\", \"Logical Reasoning (LR)\", \"Strategic Effectiveness (SE)\", \"Adaptability and Strategic Evolution (AD)\", and \"Long-term Planning (LP)\" on a scale from 1 to 5.', additional_kwargs={}, response_metadata={}), HumanMessage(content='could you tell me the total number of those eval strategies, take your best guess, and then divide it by 2?', additional_kwargs={}, response_metadata={}), AIMessage(content='The total number of evaluation strategies mentioned in the KR reasoning LLM framework paper is five. To calculate half of that number, you would divide five by two, which equals 2.5.', additional_kwargs={}, response_metadata={}), HumanMessage(content='divide that number by 5?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"The total number of evaluation strategies mentioned in the KR reasoning LLM framework paper is 5. Half of 5 is 2.5. Since we can't have half of a strategy, we would consider the closest whole number, which is 3.\", additional_kwargs={}, response_metadata={})], 'answer': \"The total number of evaluation strategies mentioned in the KR reasoning LLM framework paper is 5. Half of 5 is 2.5. Since we can't have half of a strategy, we would consider the closest whole number, which is 3.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKkoQfg0VGSX",
        "outputId": "ad6ecb54-d086-4a32-bbd8-4a3dedaf5ca4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of evaluation strategies mentioned in the KR reasoning LLM framework paper is 5. Half of 5 is 2.5. Since we can't have half of a strategy, we would consider the closest whole number, which is 3.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in result['chat_history']:\n",
        "    print(item)"
      ],
      "metadata": {
        "id": "lXRDBGYWVvbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LOOP for qa--------------------------------**"
      ],
      "metadata": {
        "id": "5x4VSwknVZYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# while True:\n",
        "#     q = input('Your question: ')\n",
        "#     if q.lower() in 'exit quit bye':\n",
        "#         print('Bye bye!')\n",
        "#         break\n",
        "#     result = ask_question(q, crc)\n",
        "#     print(result['answer'])\n",
        "#     print('-' * 100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "aGDNsf8MVY5W",
        "outputId": "7ed0b617-f7fc-416d-f033-ef1e0fda7306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-86aacfc4df9a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Your question: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'exit quit bye'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bye bye!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xb9c5WurVHDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZjYKF20zlede"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QESqgPholeHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dcNDImdGleEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5q4Pn7v5ldzl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}