{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjywZ6Cz3q0mV2Fy/21AX0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanvircr7/meh/blob/master/07_Experiment_Tracking_CODE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. **Installation**"
      ],
      "metadata": {
        "id": "NJaj2CjUXfap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
        "# try:\n",
        "#     import torch\n",
        "#     import torchvision\n",
        "#     assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
        "#     assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
        "#     print(f\"torch version: {torch.__version__}\")\n",
        "#     print(f\"torchvision version: {torchvision.__version__}\")\n",
        "# except:\n",
        "#     print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
        "#     !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "#     import torch\n",
        "#     import torchvision\n",
        "#     print(f\"torch version: {torch.__version__}\")\n",
        "#     print(f\"torchvision version: {torchvision.__version__}\")"
      ],
      "metadata": {
        "id": "2glgKjCcXxan"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note:** If you're using Google Colab, you may have to restart your runtime after running the above cell. After restarting, you can run the cell again and verify you've got the right versions of `torch` (0.12+) and `torchvision` (0.13+)."
      ],
      "metadata": {
        "id": "-zdLsJ5PX5so"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9M_WXSZHS22",
        "outputId": "dd4ef4c6-3525-4143-8afa-2bc63b8bba8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.0+cu121\n",
            "0.19.0+cu121\n"
          ]
        }
      ],
      "source": [
        "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
        "import torch\n",
        "import torchvision\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue with regular imports\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGYIJCzOaHYS",
        "outputId": "f80db09f-1e97-4304-a1cd-014d84f09ff7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n",
            "[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 4356, done.\u001b[K\n",
            "remote: Counting objects: 100% (321/321), done.\u001b[K\n",
            "remote: Compressing objects: 100% (143/143), done.\u001b[K\n",
            "remote: Total 4356 (delta 213), reused 253 (delta 177), pack-reused 4035 (from 1)\u001b[K\n",
            "Receiving objects: 100% (4356/4356), 654.51 MiB | 26.81 MiB/s, done.\n",
            "Resolving deltas: 100% (2584/2584), done.\n",
            "Updating files: 100% (248/248), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "43H_mweyaOyP",
        "outputId": "a99afa90-b562-42a3-ce77-912df4ce3c21"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seeds\n",
        "def set_seeds(seed: int=42):\n",
        "    \"\"\"Sets random sets for torch operations.\n",
        "\n",
        "    Args:\n",
        "        seed (int, optional): Random seed to set. Defaults to 42.\n",
        "    \"\"\"\n",
        "    # Set the seed for general torch operations\n",
        "    torch.manual_seed(seed)\n",
        "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
        "    torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "kJk6_UYhabqU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Get **DATA**"
      ],
      "metadata": {
        "id": "yZRETbLwXumH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf data"
      ],
      "metadata": {
        "id": "ONKk-viId0Th"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import requests\n",
        "\n",
        "def download_data(source: str,\n",
        "                  destination: str,\n",
        "                  remove_source: bool = True) -> Path:\n",
        "    \"\"\"Downloads a zipped dataset from source and unzips to destination.\n",
        "\n",
        "    Args:\n",
        "        source (str): A link to a zipped file containing data.\n",
        "        destination (str): A target directory to unzip data to.\n",
        "        remove_source (bool): Whether to remove the source after downloading and extracting.\n",
        "\n",
        "    Returns:\n",
        "        pathlib.Path to downloaded data.\n",
        "\n",
        "    Example usage:\n",
        "        download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "                      destination=\"pizza_steak_sushi\")\n",
        "    \"\"\"\n",
        "    # Setup path to data folder\n",
        "    data_path = Path(\"data/\")\n",
        "    image_path = data_path / destination\n",
        "\n",
        "    # If the image folder doesn't exist, download it and prepare it...\n",
        "    if image_path.is_dir():\n",
        "        print(f\"[INFO] {image_path} directory exists, skipping download.\")\n",
        "    else:\n",
        "        print(f\"[INFO] Did not find {image_path} directory, creating one...\")\n",
        "        image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Download pizza, steak, sushi data\n",
        "        target_file = Path(source).name\n",
        "        with open(data_path / target_file, \"wb\") as f:\n",
        "            request = requests.get(source)\n",
        "            print(f\"[INFO] Downloading {target_file} from {source}...\")\n",
        "            f.write(request.content)\n",
        "\n",
        "        # Unzip pizza, steak, sushi data\n",
        "        with zipfile.ZipFile(data_path / target_file, \"r\") as zip_ref:\n",
        "            print(f\"[INFO] Unzipping {target_file} data...\")\n",
        "            zip_ref.extractall(image_path)\n",
        "\n",
        "        # Remove .zip file\n",
        "        if remove_source:\n",
        "            os.remove(data_path / target_file)\n",
        "\n",
        "    return image_path\n",
        "\n",
        "image_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "                           destination=\"pizza_steak_sushi\")\n",
        "image_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnkdDLrdXo81",
        "outputId": "21d8353c-a13a-46b6-fb3b-7c6d1a45086e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Did not find data/pizza_steak_sushi directory, creating one...\n",
            "[INFO] Downloading pizza_steak_sushi.zip from https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip...\n",
            "[INFO] Unzipping pizza_steak_sushi.zip data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('data/pizza_steak_sushi')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. **Dataloaders**"
      ],
      "metadata": {
        "id": "4EI-N1TewEWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = image_path / 'train'\n",
        "test_dir = image_path / 'test'"
      ],
      "metadata": {
        "id": "cUmRoD6sadYX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manual"
      ],
      "metadata": {
        "id": "YTSz0uFZrdD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# manual\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "manual_transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umM1u-RiadU_",
        "outputId": "925551b1-a083-456c-9cf3-5502c09fcba7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Compose(\n",
              "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
              "    ToTensor()\n",
              "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=manual_transforms,\n",
        "                                                                               batch_size=32)\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsSOMGoEadQ5",
        "outputId": "25e8ca6c-a892-4585-b091-45c6749c9655"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7dfe751e8e20>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7dfda941a920>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Auto"
      ],
      "metadata": {
        "id": "isYMq1-KrfIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a set of pretrained model weights\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # .DEFAULT = best available weights from pretraining on ImageNet\n",
        "\n",
        "\n",
        "automatic_transforms = weights.transforms()\n",
        "print(automatic_transforms)\n",
        "\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=automatic_transforms,\n",
        "                                                                               batch_size=32)\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A91Pv7IYadHX",
        "outputId": "55918ee6-b06f-47af-a7e4-5ffd74821124"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ImageClassification(\n",
            "    crop_size=[224]\n",
            "    resize_size=[256]\n",
            "    mean=[0.485, 0.456, 0.406]\n",
            "    std=[0.229, 0.224, 0.225]\n",
            "    interpolation=InterpolationMode.BICUBIC\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7dfda9419e10>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7dfda941b580>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Get a pretrained model, freeze the base layers and change classifier head**"
      ],
      "metadata": {
        "id": "tGRbd98o3T5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: This is how a pretrained model would be created in torchvision > 0.13, it will be deprecated in future versions.\n",
        "# model = torchvision.models.efficientnet_b0(pretrained=True).to(device) # OLD\n",
        "\n",
        "# Download the pretrained weights for EfficientNet_B0\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # NEW in torchvision 0.13, \"DEFAULT\" means \"best weights available\"\n",
        "\n",
        "# Setup the model with the pretrained weights and send it to the target device\n",
        "model = torchvision.models.efficientnet_b0(weights=weights).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0mSVaBy3TwA",
        "outputId": "925e7f88-e731-4ebb-f03e-373b8276ac9c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 61.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all base layers by setting requires_grad attribute to False\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Since we're creating a new layer with random weights (torch.nn.Linear),\n",
        "# let's set the seeds\n",
        "set_seeds()\n",
        "\n",
        "# Update the classifier head to suit our problem\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    nn.Dropout(p=0.2, inplace=True),\n",
        "    nn.Linear(in_features=1280,\n",
        "              out_features=len(class_names),\n",
        "              bias=True).to(device))"
      ],
      "metadata": {
        "id": "jErSPGId3Ts4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "# # Get a summary of the model (uncomment for full output)\n",
        "# summary(model,\n",
        "#         input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\" (batch_size, color_channels, height, width)\n",
        "#         verbose=0,\n",
        "#         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "#         col_width=20,\n",
        "#         row_settings=[\"var_names\"]\n",
        "# )"
      ],
      "metadata": {
        "id": "DrNMxJQa3Tp8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Train Model + Track Results**"
      ],
      "metadata": {
        "id": "OENpBOS09nMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "3x3S3Jyi9wph"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use PyTorch's [`torch.utils.tensorboard.SummaryWriter()`](https://pytorch.org/docs/stable/tensorboard.html) class to save various parts of our model's training progress to file.\n",
        "\n",
        "By default, the `SummaryWriter()` class saves various information about our model to a file set by the `log_dir` parameter.\n",
        "\n",
        "The default location for `log_dir` is under `runs/CURRENT_DATETIME_HOSTNAME`, where the `HOSTNAME` is the name of your computer.\n",
        "\n",
        "But of course, you can change where your experiments are tracked (the filename is as customisable as you'd like).\n",
        "\n",
        "The outputs of the `SummaryWriter()` are saved in [TensorBoard format](https://www.tensorflow.org/tensorboard/).\n",
        "\n",
        "TensorBoard is a part of the TensorFlow deep learning library and is an excellent way to visualize different parts of your model.\n",
        "\n",
        "To start tracking our modelling experiments, let's create a default `SummaryWriter()` instance."
      ],
      "metadata": {
        "id": "vyoY6e8tfrn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find tensorboard... installing it.\")\n",
        "    !pip install -q tensorboard\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "# Create a writer with all default settings\n",
        "writer = SummaryWriter()"
      ],
      "metadata": {
        "id": "2HUyVL6P9wg9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to use the writer, we could write a new training loop or we could adjust the existing `train()` function we created in [05. PyTorch Going Modular section 4](https://www.learnpytorch.io/05_pytorch_going_modular/#4-creating-train_step-and-test_step-functions-and-train-to-combine-them).\n",
        "\n",
        "Let's take the latter option.\n",
        "\n",
        "We'll get the `train()` function from [`engine.py`](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/going_modular/engine.py) and adjust it to use `writer`.\n",
        "\n",
        "Specifically, we'll add the ability for our `train()` function to log our model's training and test loss and accuracy values.\n",
        "\n",
        "We can do this with [`writer.add_scalars(main_tag, tag_scalar_dict)`](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalars), where:\n",
        "* `main_tag` (string) - the name for the scalars being tracked (e.g. \"Accuracy\")\n",
        "* `tag_scalar_dict` (dict) - a dictionary of the values being tracked (e.g. `{\"train_loss\": 0.3454}`)\n",
        "    * > **Note:** The method is called `add_scalars()` because our loss and accuracy values are generally scalars (single values).\n",
        "\n",
        "Once we've finished tracking values, we'll call `writer.close()` to tell the `writer` to stop looking for values to track.\n",
        "\n",
        "To start modifying `train()` we'll also import `train_step()` and `test_step()` from [`engine.py`](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/going_modular/engine.py).\n",
        "\n",
        "> **Note:** You can track information about your model almost anywhere in your code. But quite often experiments will be tracked *while* a model is training (inside a training/testing loop).\n",
        ">\n",
        "> The `torch.utils.tensorboard.SummaryWriter()` class also has many different methods to track different things about your model/data, such as [`add_graph()`](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_graph) which tracks the computation graph of your model. For more options, [check the `SummaryWriter()` documentation](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter)."
      ],
      "metadata": {
        "id": "ZUV9tnU3jW1F"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aR5GaU0xrgbI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S0uSfVYErgXX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XvH8fJZyrgUH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "069eZAdzrgOa"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}