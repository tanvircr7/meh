{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanvircr7/meh/blob/master/Langgraph_Tutorial_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebG3iUVkxwBW",
        "outputId": "623c596c-34fc-41b8-8113-f6f71fabc817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.3.34)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.55)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.25)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.8)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.63)\n",
            "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (0.3.33)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (4.13.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (2.11.3)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.9.1)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.16)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.8)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "pip install -U langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cplYxc1x43j",
        "outputId": "8709a0bf-bebd-4503-8730-8c7c7e584673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.11/dist-packages (0.3.55)\n",
            "Requirement already satisfied: langchain-anthropic in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.3.34)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (0.3.33)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (4.13.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (2.11.3)\n",
            "Requirement already satisfied: anthropic<1,>=0.49.0 in /usr/local/lib/python3.11/dist-packages (from langchain-anthropic) (0.50.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.25)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.8)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.63)\n",
            "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.75.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.9.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.16)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (0.23.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain_core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain_core) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain_core) (0.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.49.0->langchain-anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic<1,>=0.49.0->langchain-anthropic) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic<1,>=0.49.0->langchain-anthropic) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic<1,>=0.49.0->langchain-anthropic) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain_core) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain_core) (2.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install langchain_core langchain-anthropic langgraph langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xyCF0nTOLXf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eefcc5a4-2618-48a7-c9bd-056150a1faf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY: ··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "29yP546-3n4z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xuXtb2FEWlPF"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    # Messages have the type \"list\". The `add_messages` function\n",
        "    # in the annotation defines how this state key should be updated\n",
        "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gkvit1hcX5xH",
        "outputId": "7d85eb3a-b912-4808-a2b2-15ab2f15c317"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x79aacd955ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "llm = init_chat_model(\"openai:gpt-3.5-turbo-0125\", max_tokens=50)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "# The first argument is the unique node name\n",
        "# The second argument is the function or object that will be called whenever\n",
        "# the node is used.\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShMEGBZI3guh",
        "outputId": "fad21c60-ad8d-4522-f764-c9ac143e3212"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x79aacd955ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "graph_builder.add_edge(START, \"chatbot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkXVvXUf_Pso",
        "outputId": "5e5ee3a2-8600-4e66-c198-b07dbde8600a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x79aacd955ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "graph_builder.add_edge(\"chatbot\", END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tGi6zLcY_o9L"
      },
      "outputs": [],
      "source": [
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "QBkvCjlX_RS4",
        "outputId": "2d9c5ed4-ab2e-41cd-860a-9b18dd636449"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeh85PZX_VAz",
        "outputId": "97a24553-ce15-4e07-b002-af275b536c48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'chatbot': {'messages': [AIMessage(content='John Cena is a professional wrestler, actor, and television host. He gained fame as a WWE wrestler and has become one of the most popular and recognizable wrestlers in the world. Cena has also appeared in several movies and TV shows, and has hosted various', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 9, 'total_tokens': 59, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BRFpJOo1LrIichoHAy4Q9l7V7fFxD', 'finish_reason': 'length', 'logprobs': None}, id='run-479d94eb-a382-43a8-91ef-6e38d1564dab-0', usage_metadata={'input_tokens': 9, 'output_tokens': 50, 'total_tokens': 59, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "--------------\n",
            "{'messages': [AIMessage(content='John Cena is a professional wrestler, actor, and television host. He gained fame as a WWE wrestler and has become one of the most popular and recognizable wrestlers in the world. Cena has also appeared in several movies and TV shows, and has hosted various', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 9, 'total_tokens': 59, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BRFpJOo1LrIichoHAy4Q9l7V7fFxD', 'finish_reason': 'length', 'logprobs': None}, id='run-479d94eb-a382-43a8-91ef-6e38d1564dab-0', usage_metadata={'input_tokens': 9, 'output_tokens': 50, 'total_tokens': 59, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
            "--------------\n",
            "Assistant: John Cena is a professional wrestler, actor, and television host. He gained fame as a WWE wrestler and has become one of the most popular and recognizable wrestlers in the world. Cena has also appeared in several movies and TV shows, and has hosted various\n",
            "{'chatbot': {'messages': [AIMessage(content='Randy Orton is a professional wrestler who is currently signed to WWE. He is a third-generation wrestler and is known for his athleticism and agility in the ring. Orton has won multiple championships in WWE, including the WWE Championship and the World Heavy', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 11, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BRFpixeykctFtKf6Ab8DsBBwThONs', 'finish_reason': 'length', 'logprobs': None}, id='run-fb3c36ad-f555-4a5e-aa9b-3d68799e2421-0', usage_metadata={'input_tokens': 11, 'output_tokens': 50, 'total_tokens': 61, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "--------------\n",
            "{'messages': [AIMessage(content='Randy Orton is a professional wrestler who is currently signed to WWE. He is a third-generation wrestler and is known for his athleticism and agility in the ring. Orton has won multiple championships in WWE, including the WWE Championship and the World Heavy', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 11, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BRFpixeykctFtKf6Ab8DsBBwThONs', 'finish_reason': 'length', 'logprobs': None}, id='run-fb3c36ad-f555-4a5e-aa9b-3d68799e2421-0', usage_metadata={'input_tokens': 11, 'output_tokens': 50, 'total_tokens': 61, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
            "--------------\n",
            "Assistant: Randy Orton is a professional wrestler who is currently signed to WWE. He is a third-generation wrestler and is known for his athleticism and agility in the ring. Orton has won multiple championships in WWE, including the WWE Championship and the World Heavy\n",
            "User: What do you know about LangGraph?\n",
            "{'chatbot': {'messages': [AIMessage(content=\"LangGraph is a free online tool that allows users to generate language learning graphs to track their progress in mastering a new language. The tool works by inputting words or phrases in the target language, along with their corresponding translations or meanings in the user's\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 15, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BRI084aUEJEwvsqxinhqaNGKovnfB', 'finish_reason': 'length', 'logprobs': None}, id='run-2096e8a0-89c2-4cce-b418-47458ffd6cad-0', usage_metadata={'input_tokens': 15, 'output_tokens': 50, 'total_tokens': 65, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "--------------\n",
            "{'messages': [AIMessage(content=\"LangGraph is a free online tool that allows users to generate language learning graphs to track their progress in mastering a new language. The tool works by inputting words or phrases in the target language, along with their corresponding translations or meanings in the user's\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 15, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BRI084aUEJEwvsqxinhqaNGKovnfB', 'finish_reason': 'length', 'logprobs': None}, id='run-2096e8a0-89c2-4cce-b418-47458ffd6cad-0', usage_metadata={'input_tokens': 15, 'output_tokens': 50, 'total_tokens': 65, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
            "--------------\n",
            "Assistant: LangGraph is a free online tool that allows users to generate language learning graphs to track their progress in mastering a new language. The tool works by inputting words or phrases in the target language, along with their corresponding translations or meanings in the user's\n"
          ]
        }
      ],
      "source": [
        "def stream_graph_updates(user_input: str):\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
        "        print(event)\n",
        "        print(\"--------------\")\n",
        "        for value in event.values():\n",
        "            print(value)\n",
        "            print(\"--------------\")\n",
        "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
        "\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SEARCH**"
      ],
      "metadata": {
        "id": "jkabbW9dfqFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-tavily"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoXvY4XFfp5l",
        "outputId": "83d2597f-8027-42e8-fe27-5fb7904542d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-tavily in /usr/local/lib/python3.11/dist-packages (0.1.5)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.11.14 in /usr/local/lib/python3.11/dist-packages (from langchain-tavily) (3.11.15)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.20 in /usr/local/lib/python3.11/dist-packages (from langchain-tavily) (0.3.24)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain-tavily) (0.3.55)\n",
            "Requirement already satisfied: mypy<2.0.0,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from langchain-tavily) (1.15.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.20.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (0.3.33)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (4.13.2)\n",
            "Requirement already satisfied: mypy_extensions>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from mypy<2.0.0,>=1.15.0->langchain-tavily) (1.1.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-tavily) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain<0.4.0,>=0.3.20->langchain-tavily) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain<0.4.0,>=0.3.20->langchain-tavily) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain<0.4.0,>=0.3.20->langchain-tavily) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain<0.4.0,>=0.3.20->langchain-tavily) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (3.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HcDqqnOD_bEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a08f28-adaf-4997-d467-996bdc4ed499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TAVILY_API_KEY: ··········\n"
          ]
        }
      ],
      "source": [
        "_set_env(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_tavily import TavilySearch\n",
        "\n",
        "tool = TavilySearch(max_results=2)\n",
        "tools = [tool]\n",
        "tool.invoke(\"What's a 'node' in LangGraph?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDyom2O5fv4B",
        "outputId": "92b58ce5-24cf-4f81-9153-e7b25d43a7fa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': \"What's a 'node' in LangGraph?\",\n",
              " 'follow_up_questions': None,\n",
              " 'answer': None,\n",
              " 'images': [],\n",
              " 'results': [{'title': \"Introduction to LangGraph: A Beginner's Guide - Medium\",\n",
              "   'url': 'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141',\n",
              "   'content': 'Stateful Graph: LangGraph revolves around the concept of a stateful graph, where each node in the graph represents a step in your computation, and the graph maintains a state that is passed around and updated as the computation progresses. LangGraph supports conditional edges, allowing you to dynamically determine the next node to execute based on the current state of the graph. We define nodes for classifying the input, handling greetings, and handling search queries. def classify_input_node(state): LangGraph is a versatile tool for building complex, stateful applications with LLMs. By understanding its core concepts and working through simple examples, beginners can start to leverage its power for their projects. Remember to pay attention to state management, conditional edges, and ensuring there are no dead-end nodes in your graph.',\n",
              "   'score': 0.7065353,\n",
              "   'raw_content': None},\n",
              "  {'title': 'LangGraph Tutorial: What Is LangGraph and How to Use It?',\n",
              "   'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
              "   'content': 'LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.',\n",
              "   'score': 0.5008063,\n",
              "   'raw_content': None}],\n",
              " 'response_time': 1.49}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "llm = init_chat_model(\"openai:gpt-3.5-turbo-0125\", max_tokens=50)\n",
        "# Modification: tell the LLM which tools it can call\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak9MeQ2lf57z",
        "outputId": "9fa061f8-df40-4966-e996-611e545e6ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7ea461a59e50>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "\n",
        "class BasicToolNode:\n",
        "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
        "\n",
        "    def __init__(self, tools: list) -> None:\n",
        "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
        "\n",
        "    def __call__(self, inputs: dict):\n",
        "        if messages := inputs.get(\"messages\", []):\n",
        "            message = messages[-1]\n",
        "        else:\n",
        "            raise ValueError(\"No message found in input\")\n",
        "        outputs = []\n",
        "        for tool_call in message.tool_calls:\n",
        "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
        "                tool_call[\"args\"]\n",
        "            )\n",
        "            outputs.append(\n",
        "                ToolMessage(\n",
        "                    content=json.dumps(tool_result),\n",
        "                    name=tool_call[\"name\"],\n",
        "                    tool_call_id=tool_call[\"id\"],\n",
        "                )\n",
        "            )\n",
        "        return {\"messages\": outputs}\n",
        "\n",
        "\n",
        "tool_node = BasicToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xvSCtjsgUip",
        "outputId": "1f1eabe5-15df-4f3e-fb9c-aaad9371c73d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7ea461a59e50>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def route_tools(\n",
        "    state: State,\n",
        "):\n",
        "    \"\"\"\n",
        "    Use in the conditional_edge to route to the ToolNode if the last message\n",
        "    has tool calls. Otherwise, route to the end.\n",
        "    \"\"\"\n",
        "    if isinstance(state, list):\n",
        "        ai_message = state[-1]\n",
        "    elif messages := state.get(\"messages\", []):\n",
        "        ai_message = messages[-1]\n",
        "    else:\n",
        "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
        "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
        "        return \"tools\"\n",
        "    return END\n",
        "\n",
        "\n",
        "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
        "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    route_tools,\n",
        "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
        "    # It defaults to the identity function, but if you\n",
        "    # want to use a node named something else apart from \"tools\",\n",
        "    # You can update the value of the dictionary to something else\n",
        "    # e.g., \"tools\": \"my_tools\"\n",
        "    {\"tools\": \"tools\", END: END},\n",
        ")\n",
        "# Any time a tool is called, we return to the chatbot to decide the next step\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "MW5ejD7MgX7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "dqoMwG28xVVk",
        "outputId": "d4012e57-d616-4f40-a76e-fb871fb1e219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asYaHKZKxYRG",
        "outputId": "17819b65-ca23-4151-84df-1017b396945c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: \n",
            "Assistant: Hello! How can I assist you today?\n",
            "User: What do you know about LangGraph?\n",
            "Assistant: \n",
            "Assistant: {\"query\": \"LangGraph\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\", \"title\": \"LangGraph Quickstart - GitHub Pages\", \"content\": \"[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-1)Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It's particularly useful for developing more complex, [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-6)   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It's particularly useful for creating agent and multi-agent workflows.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-8)2. Developer: [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-19)LangGraph is likely a framework or library designed specifically for creating AI agents with advanced capabilities. Here are a few points to consider based on this recommendation:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-20)\", \"score\": 0.9328032, \"raw_content\": null}, {\"url\": \"https://github.com/langchain-ai/langgraph\", \"title\": \"langchain-ai/langgraph: Build resilient language agents as graphs.\", \"content\": \"LangGraph \\u2014 used by Replit, Uber, LinkedIn, GitLab and more \\u2014 is a low-level orchestration framework for building controllable agents. While langchain provides integrations and composable components to streamline LLM application development, the LangGraph library enables agent orchestration \\u2014 offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.\\n\\n```\\npip install -U langgraph\\n```\", \"score\": 0.8884594, \"raw_content\": null}], \"response_time\": 1.5}\n",
            "Assistant: LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is used by companies like\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Memory**"
      ],
      "metadata": {
        "id": "QzbUu0CCxfLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()"
      ],
      "metadata": {
        "id": "pJtYptINxdCJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_tavily import TavilySearch\n",
        "from langchain_core.messages import BaseMessage\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "tool = TavilySearch(max_results=2)\n",
        "tools = [tool]\n",
        "llm = init_chat_model(\"openai:gpt-3.5-turbo-0125\", max_tokens=50)\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "tool_node = ToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        ")\n",
        "# Any time a tool is called, we return to the chatbot to decide the next step\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6tihKnuf08Y",
        "outputId": "58736dfe-239a-498a-caa3-188b1a765033"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7eb03bc80e90>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph = graph_builder.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "JXvG_akv4L3c"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "G8OVKnlvk0GP",
        "outputId": "14cf2693-8286-4f38-ad4b-5e25a45d8a6e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAANgAAAD5CAIAAADKsmwpAAAQAElEQVR4nOydB1gUV9uwz/ZGWZo0QRAEQcDeQCM2Xo0VExON+VP8jMYSNdg11mj01UQTDRoVNTFYiHkVEjX2rjHGKCiKgCLSOyxsb/wPrMGSBTEyy9mdc19c4+zM7Aq79z7nnOeUYVdXVyMCoblhIwIBA4iIBCwgIhKwgIhIwAIiIgELiIgELDBLEVUKXWmeWl6lk1dptdpqrdoMMlA8AZPNZQit2UIblrMHHxGexZxElFVq0m/IMpKllaUaa3uO0JoFn6uNPQeZQypUr0OFmSp5lYzDY2bdk3sHiVoHw48VItTCMIuEtl5XfeXX0pI8lYMbt3WQlbuvAJkzSrnuYbIsJ12el6EMHerQpqM1oj1mIOKdq5JzB4pDhzl0DLdDlgWE9iuHS1VyXcT/cxFYsRCNwV3EcweK+EJmjyGOyHIpyVfFR+cOet+lZRshoitYi3gyttDFmx8cZotowKHo3N6Rjo5uPERL8BUxfnOubweroFBaWGjgUHROcJgY/mpEP5gISy7GF3sFimhlIRA5teXV30rLC9WIfuAoYuqNKjaH2SFcjOjHuPmeZw8U0XBsHo4inj9Q3KkfHS0EGAwGFAWQq0I0AzsR/zpVHhRmwxPQN5fRqZ/d3T8qlTIdohN4iQhFUlaqPHSoJSdrGsNro5wSz1cgOoGXiBm3ZdAni2iPp78w+YoE0Qm8PnXo+IJOWGRa5s2b9+uvv6KXZ8CAAXl5eYgCoJdF7MjNz1Qg2oCXiBXFmtbBphYxJSUFvTwFBQUVFRSWnn5drLLT5Ig2YCQiVM/Li9TUNVPi4+PfeuutsLCw/v37z5kzp7CwEA526dIFotry5cvDw8PhoU6n++6770aOHBkaGjp48OA1a9YoFI/DEsS/vXv3Tp8+vWfPnhcvXhw6dCgcHD58+KxZsxAFiGzYJTk0SihiJKKsUgvvPqKGmzdvrly5cuzYsXFxcd988w0Es/nz58Pxo0ePwha8TEhIgB1Q7fvvv58yZcr+/fuXLl16/vz56Ohowyuw2eyDBw/6+vpu3bq1a9euq1evhoOxsbErVqxAFABvBbwhiDZgNB5RVqkT2VAVDh88eMDj8YYNGwY+tWzZEkJdfn4+HLe1rem8EQqFhh2IghDwwDbY9/T0jIiIuHz5suEVIMPH5/MhIhoeikQ1VQgbGxvDTpMjsmXJJDTK4GAkYrW+mktZkxmKYDBpwoQJI0aM6N69u5ubm4ODwz8vE4vFR44cgdhZVFSk1Wrlcjk4Wnc2JCQEmQoWm8Hl0yiBgNGfKrRhS4o1iBq8vLx27doFsXDTpk1Qsfvggw+Sk5P/edm6detiYmKgKrl9+3YopiMjI58+a2VluuEI0gotuIhoA0YiQrkMpTOijDZt2kCoO3nyJFTyWCzWzJkz1epnWgPQUoGa4vvvv//666+7u7s7OjpKpVLUTFBaUcEQnCKiNdvehaPXU9LfD/Hv1q1bsAMKdu7cefLkydBeKS193KVrGGSg1+vBRUNlEZDJZBcuXGh4/AF1oxNUcp2TB43GJuJVC+ELWdC5gijgypUrUVFRp0+fzsnJSU1NhUaxq6uri4sLr5YbN27AQahE+vv7Hz58GK5JT0+HkAm5nsrKyszMTKgvPveC0EyB7aVLlzIyMhAFpP5V5epl3lNzXgq8RPRqJ8q8Q4mI48ePhwrf119//eabb06dOhUi2caNG8E8OAX1xVOnTkHKBlKGS5YsgaAIdcQFCxaMGTMGrgRZ33vvPWi7PPeCAQEBkGvcsGHD2rVrUVOj01bn3ld4tqXRzAG8RmgrpNoTsYUjPnZH9ObhHWl2muK1SCdEG/CKiAIrtp0zN4lmA0/+yZVfSuk2Oh27CfZhwxy3zn/Qvo/xgbFQbkIHndFT0ATmcrlGT3l7e0PuBlHD97UYPQXpnvra3VCyb9myxeipe9crW3jw7Z2N/y2WCo6TpxLPVzAY1e1fMz6LuaqqyuhxlUoFIhqqfc/BZDIp6v8w/L/PpYHq0Gg0HA7H6ClovD+dKn+awzF5fd50shYbf6KlguksPvgw2vWwNf2QsGaHtn84pp1IQye4XThYXFqgQnTiTFyRixefhhYinOc1Q9dz3FfZr41ycvOhRTrt7E9FLdsIaLsODr7d6gwmY8wcz9+PlqZcq0QWjV5XfSg6196FS+fVmMxgEaYrh0uyUuShwxwtMsH754my1OtV4aOd6LzwDTKXZemKc1VXfi0R2bChmIYqlEBk9qMBirKVWany6yfKO4SLuw2yZzJpNNDGKOYhooGcdDkEj4fJMicPnq0jB7yEH6ENS69H+MNiIEmZRibRVaPqe39WwW/u214U8pqYwyWzFmswJxHryH+oKMlVyyq18MNkMOTSphw8JpfLHz16BAln1KRY23HgrRbZsqztOS19BCJbsnr5M5iliJSSkpKyatWq2NhYRDAh5HtJwAIiIgELiIgELCAiErCAiEjAAiIiAQuIiAQsICISsICISMACIiIBC4iIBCwgIhKwgIhIwAIiIgELiIgELCAiErCAiEjAAiIiAQuIiAQsICISsICISMACIiIBC4iIBCwgIj4Pg8FwcqLR4tWYQER8nurq6uLiYkQwLUREAhYQEQlYQEQkYAERkYAFREQCFhARCVhARCRgARGRgAVERAIWEBEJWEBEJGABEZGABUREAhYQEQlYQEQkYAG54c9jxo4dK5VKGQyGWq2WSCSOjo6wr1Kpjh8/jgjUQ24E95jBgwcXFRXl5eWVlJRoNJr8/HzYt7am731rTQwR8TFjxozx8PB4+ghExD59+iCCSSAiPobL5Y4cOZLFenIDXk9PzzfffBMRTAIR8QlvvfWWu7u7YR/CYd++fV1dXRHBJBARnwBB8Y033jAERQiHo0ePRgRTQUR8BgiKbm5uhnDo7OyMCKbCDPKIGpW+rFAtl+iqGcgEjBg48dy5c706vZGRLEPUw2QiO2eurQMH0Rvc84hXDpfeT5Ry+UwrMUevs8CUp5UdO/uezNaJ23WgnbuvANEVrEU8HVfE47PahzsgS0el1J3cndd3tJOLFx/REnzriOcPFvOFbDpYCMD3behEj5N7CssL1YiWYCpiRbG6vEAd8po9ohM9hrX482Q5oiWYNlbKCtRMFu1a9LaOnKx7ckRLMP2wpRVacQsuohkCEVtkw1Yp9Yh+YBoRoQWlUdNxWFBlqZrJMEmaCjPIeEQCFhARCVhARCRgARGRgAVERAIWEBEJWEBEJGABEZGABUREAhYQEQlYQEQkYIHlj3AZ/fbgHTs3o1dg6bK5s2ZPRgQqIZOnjLNs+bxjx39Fr8Ch+J/WrF2GCI2DiGictLQU9Gq8+ivQCsupI2o0mu9/2Hri5BGptMrX13/SR9ODgtobTjGZzB92b0/45QCc6tix6/y5y+zsasZ+l5eXbdn69Y0b16qqKp2cnEeNfHvUqDFwvG//LrD979rl0Zu/+jXhHKqdb3/0t4Qff4wpLStp7e0bFbXIr01bw4sfORr/04HYvLwcgUDYvVvo5I8/tbd3mBk1MSnpBpw9fvzwqRN/PL2ABMEolhMRt3y3AZyYMjnq6w3b3d095s6flpefazh19txJiaR89RfffLZo1d27t8BXw/G1X664e+fW4kVfxGzb987YD6K3rL90+Rwc/2n/Udh+Mm1O7I8JhisfZT08ffrYgvkr1v03Wq1Rf7Y4CryH4ydOHPnyq5URA4fsjIlbsWxdWvq9BQtnVFdXr1yxHkzt1zci/uApYmFjsJCIKJfLwcJJE2f0DR8ID2d9ukghl+fmZru51iwhIhJZTf9kLuz4+wVcvHQ2JSXZ8KypU2ZBsDRc4+HRKiHhwPXrV3uFhdvY2MIRoVBoW7sDVFSU74iJs7G2gX2IeXPnTUtM+qtrlx4Hft4TFtZn3DsfGl4B3J0zd2pyclJwcAcWm83hcm1txYjQCCxERIhYarU6oG07w0MOh7N82dq6s+0CQ+r27cT2d+W3DfsCvmDv/u8TE69LJBV6vR4KaAilRl8fimODhUBgQDBss7IyO3bo8iAjvW/fiLrL/P0DYXv/QRqIiAgvg4WICJU/2PJ4xicFCwRPJq5Dbc8wEl+r1ULxrdPppk2d7enhBQXoZ0tm1ff6EFOfezWVSqlQKqAUFgpFdaeEAiFsFQqaToB6FSxEREMJKJe/xCIhUEBnZNz/ZsP2kJCOhiOSinJXFzejF4NzdftQDYAtny+AgAol+9P/qax2/2lrCY3EQhor7m4efD4/6dYNw0MoZ2d8+hG0WBt4ikqtgq3N37XAO3du5RfkPb3uxdP7mZkPpFKpYT817S5svbxas9lsXx+/28mJdZdB0wf9XUA/9wqEhrEQEUUi0eBBw/fs3QnN2NS0lPUbvoA0XlCDFTVwiMvlHjy0v7S05M/rVzduWguNj+ycR5DT4dUCWqffT4USHNU0XETrvlyRmZkBQTRmR7SLs2tIcE0cHT363atXL0H6pqAg/2bi9U3RX7Zv36ltrYjWVtb376fCKxAdG4Pl5BGhycxgMr/b9g1U0by9fVev+sbdrWUD14vFdnPnLI2J+RZSj35+AfPmLisuKfp85YKo2R/v2vHT2DEf7I/74fffL8b+GK/VaaG507lz9/kLp4O1bdq0Xfn5egiH8CID+g+CyiKIuD3mWyiRocU9adIMw+tHRo5ZvWbJ9Bn/B5lIw8WEBsB0EaakCxUl+dpugxwRzdj7xYPxK1pzeLSb2ky+qQQsICISsICISMACIiIBC4iIBCwgIhKwgIhIwAIiIgELiIgELCAiErCAiEjAAiIiAQuIiAQswFRELp/BFdBxzrWDO49By0l/mH7Y4hbcvPu0m/lRXqRSyfVsNh1vb4GpiC6efBYLadT0uvVNUZbSryNN57tgKiKDyQgd5nAqNg/Rhqx70geJlV3/Q6/bD9aB9W1yi3JU8dG5nSMcbB251mKOpc79KM1XVpVrMpOlb0e1hG8goiW43zhcKdf9dao8/6FSKdNpNY9/VbVazaoFUYBep1NrNHy+ie6brGGU24pt2nZ0COlN6zUhcBfxn2RlZR06dGjGjBmIGpYvX37hwoVVq1b16NEDUY9UKl29ejX8d4jemJOIEomkoKDAxcXF1tYWUcPdu3c/++wzcD00NHTjxo3IhMTFxYWEhAQEBCBaYja5upKSksjISG9vb+osBPbt2wcWoprVDdMuX76MTMiQIUMgLlZUVCBaYh4iKhQK8OPMmTNcLoU3cU5JSblx4/FaEeD93r17kQmxsrKKjY1FNatKZObk5CCaYQYizpo1C+oPnTp1QhSzZ8+ewsLCuodQTJs4KKKaaf9iV1fXqVOnwv+O6ATuIu7fv3/YsGFCoRBRDHzwdeHQAFRJDSHKxPB4vISEBCgEUM26jHQpqfEV8dKlS7AFC8PDwxH17N69G8KhXq+v/hs4eO/ePdRMdO7cGbYQGs+fP49oAKatZnj3jx8//sUXXyCTF5+LtwAAD8lJREFUAzVFaDQ0Syw0CnxD3nvvPa1Wa9kL6GAaEZlMZrNYiCFgIWzXr18P30xkueAlYllZ2cSJE2Gnd+/eiPAUc+fOhVJCqVQiCwWvaA/f+3Xr1iGCMaCIgALa0JAPCwtDlgUuEfHIkSOwXblyJaX5anMHqok9e/aEPpjk5GRkWWAh4sKFC0UiESI0Aqg9Q98jpBthPzExEVkKzSxieXk5bMeOHWuaHI3F0LJlzWK4W7Zs+e2335BF0JwiHjt2LD4+HnaCg4MR4eXZunUrdAzCTl6e2Y8gbk4RL168+OGHHyLCK2BIL+zbt2/Xrl3InGkeEU+fPg1bMgivqTB0x6O/7wFjjphaRI1G07179w4dyB3Cmpjx48ej2n7RPXv2IDPEpCJCZ25paSlkwhwcHBCBAiIiIuBNhl5Ksxt4bzoRV69eXVlZ6eLiQm46QilRUVEeHh6QjkhISEDmg4mcgARsm1oQgXoMTemkpCSIiyNHjkTmAOUiQjHB5XK9vb2DgoIQwYQsWbIkIyMDdq5du9atWzeEN9QWzfBGQNPYx8eHdJw0C61bt4bt9evXv/rqK4Q3FIoIPfTNNcj5FTHcCNJimDJlCmQqUO3UVYQrVIl44MCBv/76q2PHjsjcuH379vDhw5Fl0atXL1TbE4PttCyqRISmMfTgIXPDMLDlnXfeQZYIfMcMnfsYQtVUAUhcQ8oQkjXIfNi5c2dJScncuXORhQJ/nY2NDaVTcv815rfkCEVs3LiRxWJNnToVEZoDChsrkFltxllwLwUk221tbS3ewtmzZ2P7iVAooqurq1mM3Fy8eDFk2t9//31k6UDRDFUmhCUUFs3aWky2vtu/A8L2gAEDXn/9dUQDSB0RUyZNmgQN5D59+iBCc0Ntz0p4eLharUZYMm7cuIkTJ9LKQprWEQE/Pz/oa0b4ERkZCVVDw7Ie9IGmdURsiYiIiImJ8fT0RDSDvnVEaKzo9Xp8/nL4faAs/uWXX8jIXNygtmjOysqCqhjCA4lEEhYWdvr0adpaSN86YuvWrVUqFQ4rtuTn50O98I8//sA8nUQppI7YzNy/f3/mzJmHDx9G9IbWecTKykomk2kYvN4sQO8O9ODFxcUhAsZQPnnq8uXLa9asQc0E/O+bNm0iFhqgbx0RCAkJOXPmzNChQ6G5aoIF2Z/m5MmToOCOHTsQoRY61hGh0+LWrVvPjbm3t7eH6GgaHePj469evdqMwRhDcK4jUhURt23b5ubm9txBaLFCgETUs2fPntu3bxMLn8PR0RFPCxGlRfO0adPs7OzqHkLobdeunQlm12/durWwsBB68BDhWWhaR+zXr9+QIUM4HI7hIShomEtGKevXr2cwGFFRUYjwD2idR5w8efK1a9dADujP2Lx5s4+PD6KMzz//HFLo+PTl4AYd64h1bNy40dPTE3qcxWIxpRbOnz8/ODiYWNgAONcRG1Vj02r0Cqke/UsYi+atXLp0aef2varKqZq4vnTJ0sHD+w8cOBAR6gfqiBMmTGjbti3CjxcUzSnXKm9dlJQVqAVWlNwuvkmAP4Er0pfnVXsHiTr1E7t6CxDhKSBfBlUjeJdgazgC+35+fvv370fY0FBEvHairCRP03uUi7U9B2EPvLmSYs25/xWGDnFoFUD5TSTNCH9//9TUVOhorTsCPa4fffQRwol664h/HCuTFGt7RzqbhYUAfN3FLbhDP/KA3/xRirmu4EsFY8aMEQieKSVatWrVv39/hBPGRSwvUpfkqnoMbYHMkP7jXG+exXRhjWZhxIgR7u7udQ+FQiGGa+gbFxEshBoFMk+4PFZFsaayDNOEWbMAyYS69jJkuPr27Ysww7iIUonOycOMB5B6+IvKi4iIT4CgaLhHkEgk+uCDDxB+GBdRo9JrlP86X9P8SCs01Tqyps8zQFCEXi4Ih3je5Iusq44jj+7JIOcqr9SpFXqlQoeaAhHqEd7uE+juP7WvEDUFIhu2XlcNW5ENy8Wbb233So1aIiJGpF6vTLspe3RX5uZno9FUs9gsFoeNmE2WtejWcwhsq5oooyBTMrRqjT5LXa2vrjxYIhCxfDuI2oXaWNn+m1+YiIgF6TerLsaX2rmJWDxRu4FOdZlnc6FFG6SoUmU/lN+9lucdKOw10oHNebneYyJiM6PTVR/ZUSCrQi3bu3IFZvxxCKx58OPobVeWLdm24GH4aKfA7jaNfzoRsTkpylYe+DrHp7ubjQcPWQr2Hrbwc/v34uJcVZ9RTo18Fi53sKchklL10V1F7QZAPd9yLKzD2d+ptIQJ9Y1GXk9EbB4KHinjNxd4dXVHlou9h7ioAP32Q0FjLiYiNgNajf7gptxWXSzZQgMOrcRyGfP6qRf3uBIRm4EjOwt9eli+hQYcvB0epaqy02UNX0ZENDV3fpfIZAyeyDzGNDUJQkeb8/97QWWRiGhqLv9a1qK1PaITAhsek82GXGkD12Ak4tJlc2fNnowsmuQrEodW1mwepsPdk5JPz17cXSarQE2Ng7f9nasN3QmwyUQ8FP/TmrXLEKFB7l2X8kR0XBePJ+SUFajLC+tdUL3JRExLw3GtbKzQqPTF2UorB5pOqRE5CjNu1xsUm6ZnZWbUxKSkG7Bz/PjhbVv3tPH1v307cfuOb8FO6DYNaBv00UefBLRtZ7j4yNH4nw7E5uXlCATC7t1CJ3/8qb3980u4wjU//29vfn4uj8dvH9Jp2tTZLVo4IzMnM0Xm6G2NKOPmrRPnL+8tLH7I4wk7BkcMHjCZy62Jvrv3L4S+a/82Pc9e2C2pKm7h2Cpy6OxWHsGopoNRm3B0w41bx6r1+kD/Xr6tuyDKsHYSFmTVW01smoi4csV6vzZt+/WNiD94qrW3b3b2o9lzpzg5toje9P23G3cJhMLZcyYXFdWMPjpx4siXX62MGDhkZ0zcimXr0tLvLVg447mZhLdu3YRr3hg1dkdM3OovvpFUViz/fD4yfyTFWp2GqtEMyXfP7zmw2M+326ypsW9HLr5158zPv6w2nGKx2A8fJWVl35k5ZfeyeceEQtu4gysNp85c+OGP6/HDB8/8dMpub68Op87vRJTB4bHzMxT1nW0aEa2srFhsNofLtbUVs1ishF9+hmi3YP4KH5828LNowUqtVnv8RM2CrQd+3hMW1mfcOx96eLTq0KHzJ9PmgIvJyUlPv9rDzAc8Hm/Qf4a5u7UMDAhaunjN1CmzkPkjrdBS10w5c3F3a69Orw+c4ujgEeAXOiRi6o2kYxWSx0MP1WoF2MbjCiBGdgoZVFSSqVbXrCf9V9JvQYF9unUaBs8K7faGnw+Fa8Jw+GylrN6xlZS0mtPSUyBA1q23JBQKQbsHD9JAxwcZ6YEBwXVX+vsHwvb+g7Snn96xQxco0KfPnHD4yKH8gjwouEFHZP7IpTqKRNTr9Tl5KRAO646AlLDNL7hveAieGYppQCioGRQjV1RqtZqS0mwP98C6Z3m2bIeohCdiySqNT+GgZPSNXC5zsHd8+ohQKIKDCqUCSmHYf3JcUDMBWaF4Zqymp6cXFOj74n7Ytn1T1fpVAQFBUEe0ABepW2VIo1Hq9boTZ7afPPvMqqSVVSWGHTb7n+MqqiFMwj+cp05B5RJRSbWuur6hlpSIKBJZyWTPtI/gIagp4AuYTCYY+eR47T5c/9wrQIH+2cKVOp0OGj07dm1euGjmT/uPYrtuSyOxsmUVFzfNuP/n4HD4UBHs1ePt7p2HP/M/ihrKnHNqY6RC9eSTUigayjm/IhCD1Eq90Nq4ck1ZNNe1Ofz9AlPTUupWQKuSVmVlZbZtW7M4oq+P3+3kJ/fOvXvnFvq7gK4jJSX5Tu1xqG5CPXL8h5MlkoqyssYOKMIWKzFbq6ZERPh6u7u2La/Ib+HkZfixt3NnMtlCYUNDUzlsrp3YNb8gve5I2oNriDK0Kh1fVG/NpMlEtLayvn8/Nf1+KkgzYsRolUq59ssV0HzOyLi/ctUiiHn/iRgKl40e/e7Vq5cgfVNQkH8z8fqm6C/bt+/U9lkR/7h2ZdHiqPMXTufm5cALHjy438XZ1dnZBZk5YicOm0XV3MjwXu/evnsWWsFFxY9y81L3/rw0OmaiUvmCoQaQ5YHm9tXr8VCbPH95T15+GqIMtULr2rreHGqTFc2RkWNWr1kyfcb/LV+2rlvXnuv+G70tZtOEiWMhqgUHddjw1VaxuGb12AH9B4GjIOL2mG/Bzl5h4ZMmzXjupd4dNx7q0d9993VJaTFcExTUfs3qjWY3jeOfeLUTHfuhwLG1I6KAkHZ9x76x/OzF3cdPb+Pzrbw8QyaP38znixp+1sB+E2TyisPHNuqr9QF+YUMipu2OWwD7iAJkJbI2IfUOATa+Gti142XQum8fbq5982f25bXvbQsfPMKMQ9F5bBtra0c6rhH14Er2mzPdbR2MDzsio29MSttuViqpCtEPpVTt2JJXn4WITJ4yMQFdbX4/nGnjbMUVGP9IklMu7D+43OgpkcBWppAYPdWj88ihgz5BTcTDR4k7Yo33IECSiMlgImPVpJ5dR0EWHdVDSUZZr2FiVD9ERFPTe6TDn6fL3doZX2nNz6db1JQfjZ6CvpC6pPRz8HhNWQlp6RZQ3++g0ahYLM7TSy025neQlSs5nGqvwIZ+SSKiqWnT0To9UaasUhmdvAeq2XPdULPC4fDs7Zryd1CWV/Ud/YImGqkjNgOvf+iScS1Pr6fFMlGFacX+HQUtXrS4HBGxeRg71zPjag6ydArTS51cmUGhti+8kojYPNi14L4zzz39UpZOa8bL/zVM8YNSn0BOv7cate4wEbHZEFpx3p7VElyUlSuQZaHX6nOTC7z82F0G2DXyKUTE5sTGnvPxf304ellOUr6i0kLyi8UPy1MvZPUaIu4a8RIdIqTV3PxEvOucnSa/cKiEZ8Vjcrk2TiJsp/k1gLRUIS2RVxZJ278mHj3lpW8xRkTEAg8/4bh5no/uytISZRnXcu1cBWqlns1ls7hsBhPTTnYmi6lRqHUaHarWl+croF0c2FkU2MPrZVdGNEBExIhWgaJWtVnfwixl7dLFWqVcr5JTMnLs1RFYVTOYbJENT2jDdvV24XBfqZpHRMQRZ0++syeiFcZF5PIZemTGw65EYg6TZfbDxmiF8XBqbccpfmTGOYWsFKm9i3nPK6AbxkVs4cEz33GoCqnW0Z1nJSa1DnOi3ojo7su/8L9GrfWJG6di87oObGwelYAJDd2v+c7vkvREafs+DnbOXBYb99S3Uq6rLFFfTiga9J5zC086LnRk1rzgxuEP78gSz1cUPFSy2FgX1baOnMoyjVegqMtAO+jGRQRz4wUi1qFSYN03X61HfBHprjRjGisigUAppGlJwAIiIgELiIgELCAiErCAiEjAAiIiAQv+PwAAAP//63VnaQAAAAZJREFUAwCU50Ycms9vdAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"2\"}}"
      ],
      "metadata": {
        "id": "aAgwi88uk8u1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"Hi there! My name is Will.\"\n",
        "\n",
        "# The config is the **second positional argument** to stream() or invoke()!\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFVUorBmlt7e",
        "outputId": "53635a73-b437-4e02-aa86-d3123bd5cad2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hi there! My name is Will.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello Will! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"Remember my name? Say it\"\n",
        "\n",
        "# The config is the **second positional argument** to stream() or invoke()!\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lw59z4y6lwzn",
        "outputId": "2170a389-6447-423c-c7a6-ea3355613943"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Remember my name? Say it\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hi Will! I remember your name. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The only difference is we change the `thread_id` here to \"2\" instead of \"1\"\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
        "    {\"configurable\": {\"thread_id\": \"3\"}},\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "id": "WGVMI9sPl86k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6e12363-7109-43e1-fd62-bd926c208b20"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Remember my name? Say it\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Of course! Your name is important to me. Please tell me your name again so I can remember and address you correctly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snapshot = graph.get_state(config)\n",
        "snapshot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_VXGb9w4fwd",
        "outputId": "5266523d-1f04-4270-dd71-8deaee9b2fad"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StateSnapshot(values={'messages': [HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='9b8948c6-0548-414c-990b-2987cb97e973'), AIMessage(content='Hello Will! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 815, 'total_tokens': 827, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BRBNeagIHN4CUy5r8X0R6hHaZwIgl', 'finish_reason': 'stop', 'logprobs': None}, id='run-c3e75275-4e17-4f85-b663-8c2a22c99db1-0', usage_metadata={'input_tokens': 815, 'output_tokens': 12, 'total_tokens': 827, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='Remember my name? Say it', additional_kwargs={}, response_metadata={}, id='4bf9aaa9-b0fa-42e6-a10a-a9d346a6c1de'), AIMessage(content='Hi Will! I remember your name. How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 839, 'total_tokens': 856, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BRBNgM0Sn3R9iunDQeL1iImJDox30', 'finish_reason': 'stop', 'logprobs': None}, id='run-76d2a5a2-3718-47e2-b192-cea60ce6dccb-0', usage_metadata={'input_tokens': 839, 'output_tokens': 17, 'total_tokens': 856, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}, next=(), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f023f21-249e-66f2-8004-3bca56bbd69a'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': [AIMessage(content='Hi Will! I remember your name. How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 839, 'total_tokens': 856, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BRBNgM0Sn3R9iunDQeL1iImJDox30', 'finish_reason': 'stop', 'logprobs': None}, id='run-76d2a5a2-3718-47e2-b192-cea60ce6dccb-0', usage_metadata={'input_tokens': 839, 'output_tokens': 17, 'total_tokens': 856, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}, 'step': 4, 'parents': {}, 'thread_id': '2'}, created_at='2025-04-28T05:31:44.437594+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f023f21-202f-6224-8003-041df458bc81'}}, tasks=())"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snapshot.next  # (since the graph ended this turn, `next` is empty. If you fetch a state from within a graph invocation, next tells which node will execute next)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmPKXxqW4lcY",
        "outputId": "51a5f2c5-9fab-4919-9528-7efe10c6f895"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 4: Human-in-the-loop**"
      ],
      "metadata": {
        "id": "I7aVwh-N5D3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_tavily import TavilySearch\n",
        "from langchain_core.tools import tool\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "from langgraph.types import Command, interrupt\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "@tool\n",
        "def human_assistance(query: str) -> str:\n",
        "    \"\"\"Request assistance from a human.\"\"\"\n",
        "    human_response = interrupt({\"query\": query})\n",
        "    return human_response[\"data\"]\n",
        "\n",
        "\n",
        "tool = TavilySearch(max_results=2)\n",
        "tools = [tool, human_assistance]\n",
        "llm = init_chat_model(\"openai:gpt-3.5-turbo-0125\", max_tokens=50)\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    message = llm_with_tools.invoke(state[\"messages\"])\n",
        "    # Because we will be interrupting during tool execution,\n",
        "    # we disable parallel tool calling to avoid repeating any\n",
        "    # tool invocations when we resume.\n",
        "    assert len(message.tool_calls) <= 1\n",
        "    return {\"messages\": [message]}\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "tool_node = ToolNode(tools=tools)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        ")\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fO2hWflN5Dfp",
        "outputId": "9767139a-8e0e-402b-ec8f-43a4abaabef4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7eb03a9c66d0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory = MemorySaver()\n",
        "\n",
        "graph = graph_builder.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "zQWFwfDk42XU"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "5TyZX8_V894z",
        "outputId": "5ae8f394-a959-4c9a-d365-09c7eaf37f31"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"I need some expert guidance for building an AI agent. Could you request assistance for me?\"\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DzuQDnK9CQa",
        "outputId": "ee622dd8-6ff7-4a86-aa4b-2e9635b94ece"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I need some expert guidance for building an AI agent. Could you request assistance for me?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  human_assistance (call_TRDTH63aSLcRutFjdAcEGmMq)\n",
            " Call ID: call_TRDTH63aSLcRutFjdAcEGmMq\n",
            "  Args:\n",
            "    query: I need expert guidance for building an AI agent. Can you provide assistance?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snapshot = graph.get_state(config)\n",
        "snapshot.next"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuPzM3Av9FHU",
        "outputId": "bcd38056-87d8-4713-958d-058727fc0207"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tools',)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "human_response = (\n",
        "    \"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.\"\n",
        "    \" It's much more reliable and extensible than simple autonomous agents.\"\n",
        ")\n",
        "\n",
        "human_command = Command(resume={\"data\": human_response})\n",
        "\n",
        "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--6uNkzG_hWk",
        "outputId": "4fcfe6d8-97d2-46d4-efda-c554f425d906"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  human_assistance (call_TRDTH63aSLcRutFjdAcEGmMq)\n",
            " Call ID: call_TRDTH63aSLcRutFjdAcEGmMq\n",
            "  Args:\n",
            "    query: I need expert guidance for building an AI agent. Can you provide assistance?\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: human_assistance\n",
            "\n",
            "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The experts recommend checking out LangGraph as a reliable and extensible platform for building your AI agent. It is a great tool for developing sophisticated AI agents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 5: Customizing State**"
      ],
      "metadata": {
        "id": "o3M7kDNIBoZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "    name: str\n",
        "    birthday: str"
      ],
      "metadata": {
        "id": "ExNN-FAPBYlv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import ToolMessage\n",
        "from langchain_core.tools import InjectedToolCallId, tool\n",
        "\n",
        "from langgraph.types import Command, interrupt\n",
        "\n",
        "\n",
        "@tool\n",
        "# Note that because we are generating a ToolMessage for a state update, we\n",
        "# generally require the ID of the corresponding tool call. We can use\n",
        "# LangChain's InjectedToolCallId to signal that this argument should not\n",
        "# be revealed to the model in the tool's schema.\n",
        "def human_assistance(\n",
        "    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\n",
        ") -> str:\n",
        "    \"\"\"Request assistance from a human.\"\"\"\n",
        "    human_response = interrupt(\n",
        "        {\n",
        "            \"question\": \"Is this correct?\",\n",
        "            \"name\": name,\n",
        "            \"birthday\": birthday,\n",
        "        },\n",
        "    )\n",
        "    # If the information is correct, update the state as-is.\n",
        "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
        "        verified_name = name\n",
        "        verified_birthday = birthday\n",
        "        response = \"Correct\"\n",
        "    # Otherwise, receive information from the human reviewer.\n",
        "    else:\n",
        "        verified_name = human_response.get(\"name\", name)\n",
        "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
        "        response = f\"Made a correction: {human_response}\"\n",
        "\n",
        "    # This time we explicitly update the state with a ToolMessage inside\n",
        "    # the tool.\n",
        "    state_update = {\n",
        "        \"name\": verified_name,\n",
        "        \"birthday\": verified_birthday,\n",
        "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
        "    }\n",
        "    # We return a Command object in the tool to update our state.\n",
        "    return Command(update=state_update)"
      ],
      "metadata": {
        "id": "beCDbx-JQdFl"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_tavily import TavilySearch\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "\n",
        "tool = TavilySearch(max_results=2)\n",
        "tools = [tool, human_assistance]\n",
        "llm = init_chat_model(\"openai:gpt-3.5-turbo-0125\", max_tokens=50)\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    message = llm_with_tools.invoke(state[\"messages\"])\n",
        "    assert len(message.tool_calls) <= 1\n",
        "    return {\"messages\": [message]}\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "tool_node = ToolNode(tools=tools)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        ")\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "un6BaGvqQt6C"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = (\n",
        "    \"Can you look up when LangGraph was released? \"\n",
        "    \"When you have the answer, use the human_assistance tool for review.\"\n",
        ")\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t2cR_jbQ1eI",
        "outputId": "f86ecfbe-99f1-4acb-d749-5a60899b6e43"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search (call_H6hy4vYfdyEdmWPL0mOwDwMb)\n",
            " Call ID: call_H6hy4vYfdyEdmWPL0mOwDwMb\n",
            "  Args:\n",
            "    query: LangGraph release date\n",
            "    search_depth: advanced\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search\n",
            "\n",
            "{\"query\": \"LangGraph release date\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\", \"title\": \"LangGraph Quickstart - GitHub Pages\", \"content\": \"[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-20)To summarize:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-21)1. LangGraph's original release date: January 17, 2024\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-22)2. LangGraph Cloud announcement: June 27, 2024\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-23) [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-18)LangGraph was initially released on January 17, 2024. This information comes from the human assistance correction, which is more accurate than the search results I initially found.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-19) [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-24)It's worth noting that LangGraph had been in development and use for some time before the LangGraph Cloud announcement, but the official initial release of LangGraph itself was on January 17, 2024.\\nNote that these fields are now reflected in the state:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-57-1)snapshot = graph.get_state(config)\", \"score\": 0.92715925, \"raw_content\": null}, {\"url\": \"https://pypi.org/project/langgraph/\", \"title\": \"langgraph - PyPI\", \"content\": \"langgraph · PyPI\\nSkip to main content Switch to mobile version\\n\\nSearch PyPI  Search\\n\\nHelp\\nSponsors\\nLog in\\nRegister\\n\\nMenu\\n\\nHelp\\nSponsors\\nLog in\\nRegister\\n\\nSearch PyPI  Search\\nlanggraph 0.2.70\\npip install langgraph Copy PIP instructions\\nLatest versionReleased: Feb 6, 2025\\nBuilding stateful, multi-actor applications with LLMs\\nNavigation\\n\\nProject description\\nRelease history\\nDownload files\", \"score\": 0.81875163, \"raw_content\": null}], \"response_time\": 1.81}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  human_assistance (call_JB2i279d3LPR5PyDQRzErObY)\n",
            " Call ID: call_JB2i279d3LPR5PyDQRzErObY\n",
            "  Args:\n",
            "    name: LangGraph\n",
            "    birthday: January 17, 2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "human_command = Command(\n",
        "    resume={\n",
        "        \"name\": \"LangGraph\",\n",
        "        \"birthday\": \"Jan 17, 2024\",\n",
        "    },\n",
        ")\n",
        "\n",
        "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaI_8kwxQ38b",
        "outputId": "91f2d3da-8710-4ba5-ab80-7300ba6f460b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  human_assistance (call_JB2i279d3LPR5PyDQRzErObY)\n",
            " Call ID: call_JB2i279d3LPR5PyDQRzErObY\n",
            "  Args:\n",
            "    name: LangGraph\n",
            "    birthday: January 17, 2024\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: human_assistance\n",
            "\n",
            "Made a correction: {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I have reviewed the information, and the correct release date of LangGraph is January 17, 2024.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snapshot = graph.get_state(config)\n",
        "\n",
        "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV1YtCtRRHSa",
        "outputId": "499a4914-02b6-4715-845e-97d5a8be27c8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph.update_state(config, {\"name\": \"LangGraph (library)\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcrInq43RLug",
        "outputId": "f1a4aa1d-874d-414f-80f2-08adebbc6c3a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'configurable': {'thread_id': '1',\n",
              "  'checkpoint_ns': '',\n",
              "  'checkpoint_id': '1f024014-521c-6a2d-8006-9d444164f76f'}}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snapshot = graph.get_state(config)\n",
        "\n",
        "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66DjpIbeRNtK",
        "outputId": "44103452-73df-4538-adb9-5c9d8f6a234a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'LangGraph (library)', 'birthday': 'Jan 17, 2024'}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 6: Time Travel**"
      ],
      "metadata": {
        "id": "lCciiLkJRSVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_tavily import TavilySearch\n",
        "from langchain_core.messages import BaseMessage\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "tool = TavilySearch(max_results=2)\n",
        "tools = [tool]\n",
        "llm = init_chat_model(\"openai:gpt-3.5-turbo-0125\", max_tokens=50)\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "tool_node = ToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        ")\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "NAL124qTRQaG"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "events = graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": (\n",
        "                    \"I'm learning LangGraph. \"\n",
        "                    \"Could you do some research on it for me?\"\n",
        "                ),\n",
        "            },\n",
        "        ],\n",
        "    },\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8Gi1XL9YqCa",
        "outputId": "fab0e241-e199-459d-b310-c18fd6f7ff13"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I'm learning LangGraph. Could you do some research on it for me?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search (call_IaiJwAHhJEgzy0j3In5dFfut)\n",
            " Call ID: call_IaiJwAHhJEgzy0j3In5dFfut\n",
            "  Args:\n",
            "    query: LangGraph\n",
            "    search_depth: advanced\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search\n",
            "\n",
            "{\"query\": \"LangGraph\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\", \"title\": \"LangGraph Quickstart - GitHub Pages\", \"content\": \"[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-1)Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It's particularly useful for developing more complex, [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-6)   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It's particularly useful for creating agent and multi-agent workflows.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-8)2. Developer: [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-19)LangGraph is likely a framework or library designed specifically for creating AI agents with advanced capabilities. Here are a few points to consider based on this recommendation:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-20)\", \"score\": 0.9328032, \"raw_content\": null}, {\"url\": \"https://github.com/langchain-ai/langgraph\", \"title\": \"langchain-ai/langgraph: Build resilient language agents as graphs.\", \"content\": \"LangGraph — used by Replit, Uber, LinkedIn, GitLab and more — is a low-level orchestration framework for building controllable agents. While langchain provides integrations and composable components to streamline LLM application development, the LangGraph library enables agent orchestration — offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.\\n\\n```\\npip install -U langgraph\\n```\", \"score\": 0.8884594, \"raw_content\": null}], \"response_time\": 1.8}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "events = graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": (\n",
        "                    \"Ya that's helpful. Maybe I'll \"\n",
        "                    \"build an autonomous agent with it!\"\n",
        "                ),\n",
        "            },\n",
        "        ],\n",
        "    },\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwfb46SLYsOu",
        "outputId": "24dc0aa9-7690-4f58-8a6b-7bf324b04b3f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Ya that's helpful. Maybe I'll build an autonomous agent with it!\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "That sounds like a fascinating project! LangGraph can definitely help you in building an autonomous agent with advanced capabilities. If you have any more questions or need assistance as you work on your project, feel free to ask!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to_replay = None\n",
        "for state in graph.get_state_history(config):\n",
        "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
        "    print(\"-\" * 80)\n",
        "    if len(state.values[\"messages\"]) == 6:\n",
        "        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\n",
        "        to_replay = state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jypGXll0YwBI",
        "outputId": "1e8933db-f225-4476-d194-da2914aa9a5f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Messages:  6 Next:  ()\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages:  5 Next:  ('chatbot',)\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages:  4 Next:  ('__start__',)\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages:  4 Next:  ()\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages:  3 Next:  ('chatbot',)\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages:  2 Next:  ('tools',)\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages:  1 Next:  ('chatbot',)\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages:  0 Next:  ('__start__',)\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(to_replay.next)\n",
        "print(to_replay.config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjS9uCzmY33P",
        "outputId": "430f42a7-c367-4e45-a85f-1a7e6b98976d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "()\n",
            "{'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f02405d-f2d3-6a26-8006-53490a881006'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The `checkpoint_id` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
        "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFOvfxJqY_l9",
        "outputId": "c3606c98-61f7-4fab-d822-a27e1b619a5d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "That sounds like a fascinating project! LangGraph can definitely help you in building an autonomous agent with advanced capabilities. If you have any more questions or need assistance as you work on your project, feel free to ask!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TsjpJkTxZDco"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeaD58ecOoUC6MRF7bxJRl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}