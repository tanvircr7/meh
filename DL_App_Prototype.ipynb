{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyPsxEAS9dX8QO1VkEBWsJvf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanvircr7/meh/blob/master/DL_App_Prototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkjPCAJR0qbd",
        "outputId": "dd27b478-1cc5-4b4a-d4f9-36a0a12cfcb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Segment 1:\n",
            "\n",
            "Artificial intelligence has revolutionized many fields. From healthcare to transportation, \n",
            "AI systems are making our lives easier. Machine learning algorithms can now recognize patterns\n",
            "that humans might miss.\n",
            "\n",
            "Segment 2:\n",
            "This has led to breakthrough discoveries in medicine. The ethics of AI is another important consideration. We must ensure AI systems are fair\n",
            "and unbiased. Privacy concerns have also emerged as AI systems collect more data.\n",
            "\n",
            "Segment 3:\n",
            "These challenges require careful thought and regulation. Looking to the future, AI will continue to evolve. New architectures and algorithms\n",
            "are being developed.\n",
            "\n",
            "Segment 4:\n",
            "The potential applications seem limitless. However, we must\n",
            "proceed with caution and wisdom.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import nltk\n",
        "\n",
        "def segment_script(text, min_segment_size=3):\n",
        "    \"\"\"\n",
        "    Segments a script into coherent sections using topic similarity\n",
        "\n",
        "    Args:\n",
        "        text (str): The input script text\n",
        "        min_segment_size (int): Minimum number of sentences per segment\n",
        "\n",
        "    Returns:\n",
        "        list: List of text segments\n",
        "    \"\"\"\n",
        "    # Download required NLTK data\n",
        "    nltk.download('punkt')\n",
        "    nltk.download('punkt_tab')\n",
        "\n",
        "    # Split into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # Create TF-IDF vectors for each sentence\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
        "\n",
        "    # Calculate similarity between adjacent sentences\n",
        "    similarity_scores = []\n",
        "    for i in range(len(sentences)-1):\n",
        "        similarity = (tfidf_matrix[i] * tfidf_matrix[i+1].T).toarray()[0][0]\n",
        "        similarity_scores.append(similarity)\n",
        "\n",
        "    # Find segment boundaries where similarity is low\n",
        "    threshold = np.mean(similarity_scores) - (0.01)*np.std(similarity_scores)\n",
        "    boundaries = [0]\n",
        "    current_size = 0\n",
        "\n",
        "    for i, score in enumerate(similarity_scores):\n",
        "        current_size += 1\n",
        "        if score < threshold and current_size >= min_segment_size:\n",
        "            boundaries.append(i + 1)\n",
        "            current_size = 0\n",
        "\n",
        "    boundaries.append(len(sentences))\n",
        "\n",
        "    # Create segments\n",
        "    segments = []\n",
        "    for i in range(len(boundaries)-1):\n",
        "        segment = ' '.join(sentences[boundaries[i]:boundaries[i+1]])\n",
        "        segments.append(segment)\n",
        "\n",
        "    return segments\n",
        "\n",
        "# Example usage\n",
        "sample_text = \"\"\"\n",
        "Artificial intelligence has revolutionized many fields. From healthcare to transportation,\n",
        "AI systems are making our lives easier. Machine learning algorithms can now recognize patterns\n",
        "that humans might miss. This has led to breakthrough discoveries in medicine.\n",
        "\n",
        "The ethics of AI is another important consideration. We must ensure AI systems are fair\n",
        "and unbiased. Privacy concerns have also emerged as AI systems collect more data.\n",
        "These challenges require careful thought and regulation.\n",
        "\n",
        "Looking to the future, AI will continue to evolve. New architectures and algorithms\n",
        "are being developed. The potential applications seem limitless. However, we must\n",
        "proceed with caution and wisdom.\n",
        "\"\"\"\n",
        "\n",
        "segments = segment_script(sample_text)\n",
        "\n",
        "for i, segment in enumerate(segments):\n",
        "    print(f\"\\nSegment {i+1}:\")\n",
        "    print(segment)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(segments)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rnbnKsT-SqT",
        "outputId": "f1d53878-6b4f-4941-8b1f-b0ad9f577775"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2NQorHHw-mJn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}