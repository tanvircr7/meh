{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyaSPedU0dLD+juV4Y383w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanvircr7/meh/blob/master/GNN_Grouping_Research_Papers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lM_P9cxphUaU"
      },
      "outputs": [],
      "source": [
        "!pip install ogb\n",
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The idea of using those two libraries together is that one can more easily propose an architecture and does not have to worry about the data obtention and the evaluation mechanism.\n",
        "The PyG is an extension for the Pytorch library which allows us to quickly implement new GNNs architectures using already established layers from research.\n",
        "\n",
        "The OGB [2] was developed as a way of improving the quality of the research on the area since it provides curated graphs to be used and also a standard way of evaluating the results from a given architecture, making so that the comparison between proposals is fairer."
      ],
      "metadata": {
        "id": "fb_F1MMyhYJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5MgTtvxPhu1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch_geometric.nn import MessagePassing, SAGEConv\n",
        "from ogb.nodeproppred import Evaluator, PygNodePropPredDataset"
      ],
      "metadata": {
        "id": "qdiL3AT7hvGl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# downloading the dataset from the OGB"
      ],
      "metadata": {
        "id": "iqZBd-fPhvrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_dataset = 'ogbn-arxiv'\n",
        "# This will download the ogbn-arxiv to the 'networks' folder\n",
        "dataset = PygNodePropPredDataset(name=target_dataset, root='networks')"
      ],
      "metadata": {
        "id": "Ulz8_zzChvzU"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# the number of nodes, the adjacency list, the feature vector for the network, the year for each node, and the target label."
      ],
      "metadata": {
        "id": "WNKuMDjshv6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataset[0]\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A-THnvthwCC",
        "outputId": "5663f482-e0e4-49bd-dd93-65e06eedd623"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(num_nodes=169343, edge_index=[2, 1166243], x=[169343, 128], node_year=[169343, 1], y=[169343, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This network already comes with a split set for training, validation, and testing. This is provided by the OGB as a way of improving reproducibility and the quality of research on this network."
      ],
      "metadata": {
        "id": "PjQKLegRhwJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_idx = dataset.get_idx_split()\n",
        "\n",
        "train_idx = split_idx['train']\n",
        "valid_idx = split_idx['valid']\n",
        "test_idx = split_idx['test']"
      ],
      "metadata": {
        "id": "CinaxMZ-hwRW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nTROLDxMhwZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = NeighborLoader(data, input_nodes=train_idx,\n",
        "                              shuffle=True, num_workers=os.cpu_count() - 2,\n",
        "                              batch_size=1024, num_neighbors=[30] * 2)\n",
        "total_loader = NeighborLoader(data, input_nodes=None, num_neighbors=[-1],\n",
        "                               batch_size=4096, shuffle=False,\n",
        "                               num_workers=os.cpu_count() - 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D1l7xtUhwhh",
        "outputId": "e273ae18-6fa0-4aa8-aba3-aa45f851ba5f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
            "  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Break Down\n",
        "We must define the number of in_channels of the network, this will be the number of features in our dataset. The out_channels is going to be the number of classes we are trying to predict. The hidden channels parameter is a value we can define ourselves that represents the number of hidden units.\n",
        "\n",
        "We can set the number of layers of the network. For each hidden layer, we add a Batch Normalization layer and then we reset the parameters for every layer.\n",
        "\n",
        "The forward method runs a single iteration of a forward pass. It will get the feature vector and the adjacency list and pass it to the SAGE Layer and then pass the result to the Batch Normalization layer. We also apply a ReLU non-linearity and a dropout layer for regularization purposes.\n",
        "\n",
        "Finally, the inference method will generate a prediction for every node in the dataset. We will use it for validation purposes.\n",
        "\n"
      ],
      "metadata": {
        "id": "VKNqLHg1hwqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels,\n",
        "                 hidden_channels, out_channels,\n",
        "                 n_layers=2):\n",
        "\n",
        "        super(SAGE, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.layers = torch.nn.ModuleList()\n",
        "        self.layers_bn = torch.nn.ModuleList()\n",
        "\n",
        "        if n_layers == 1:\n",
        "            self.layers.append(SAGEConv(in_channels, out_channels,   normalize=False))\n",
        "\n",
        "        elif n_layers == 2:\n",
        "            self.layers.append(SAGEConv(in_channels, hidden_channels, normalize=False))\n",
        "            self.layers_bn.append(torch.nn.BatchNorm1d(hidden_channels))\n",
        "            self.layers.append(SAGEConv(hidden_channels, out_channels, normalize=False))\n",
        "\n",
        "        else:\n",
        "            self.layers.append(SAGEConv(in_channels, hidden_channels, normalize=False))\n",
        "\n",
        "            self.layers_bn.append(torch.nn.BatchNorm1d(hidden_channels))\n",
        "            self.layers.append(SAGEConv(hidden_channels, out_channels, normalize=False))\n",
        "\n",
        "        for layer in self.layers:\n",
        "            layer.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        if len(self.layers) > 1:\n",
        "            looper = self.layers[:-1]\n",
        "        else:\n",
        "            looper = self.layers\n",
        "\n",
        "        for i, layer in enumerate(looper):\n",
        "            x = layer(x, edge_index)\n",
        "            try:\n",
        "                x = self.layers_bn[i](x)\n",
        "            except Exception as e:\n",
        "                abs(1)\n",
        "            finally:\n",
        "                x = F.relu(x)\n",
        "                x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        if len(self.layers) > 1:\n",
        "            x = self.layers[-1](x, edge_index)\n",
        "        return F.log_softmax(x, dim=-1), torch.var(x)\n",
        "\n",
        "    def inference(self, total_loader, device):\n",
        "        xs = []\n",
        "        var_ = []\n",
        "        for batch in total_loader:\n",
        "            out, var = self.forward(batch.x.to(device), batch.edge_index.to(device))\n",
        "            out = out[:batch.batch_size]\n",
        "            xs.append(out.cpu())\n",
        "            var_.append(var.item())\n",
        "        out_all = torch.cat(xs, dim=0)\n",
        "\n",
        "        return out_all, var_\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "oqI_0nIHhwx5"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dx11g8Xunm8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters for the model"
      ],
      "metadata": {
        "id": "xjhz_ZOonnHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = SAGE(data.x.shape[1], 256, dataset.num_classes, n_layers=2)\n",
        "model.to(device)\n",
        "epochs = 100\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.03)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'max', patience=7)"
      ],
      "metadata": {
        "id": "UYtNtMrlnnNx"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Function"
      ],
      "metadata": {
        "id": "XoeJqR0RnnUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device):\n",
        "    evaluator = Evaluator(name=target_dataset)\n",
        "    model.eval()\n",
        "    out, var = model.inference(total_loader, device)\n",
        "    y_true = data.y.cpu()\n",
        "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "    train_acc = evaluator.eval({\n",
        "        'y_true': y_true[split_idx['train']],\n",
        "        'y_pred': y_pred[split_idx['train']],\n",
        "    })['acc']\n",
        "    val_acc = evaluator.eval({\n",
        "        'y_true': y_true[split_idx['valid']],\n",
        "        'y_pred': y_pred[split_idx['valid']],\n",
        "    })['acc']\n",
        "    test_acc = evaluator.eval({\n",
        "        'y_true': y_true[split_idx['test']],\n",
        "        'y_pred': y_pred[split_idx['test']],\n",
        "    })['acc']\n",
        "\n",
        "    return train_acc, val_acc, test_acc, torch.mean(torch.Tensor(var))"
      ],
      "metadata": {
        "id": "C3nkyR3ynnag"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "p9M2TrK9nngZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PpdOJCtoogLu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, epochs):\n",
        "    model.train()\n",
        "    pbar = tqdm(total=train_idx.size(0))\n",
        "    pbar.set_description(f'Epoch {epoch:02d}')\n",
        "    total_loss = total_correct = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        batch_size = batch.batch_size\n",
        "        optimizer.zero_grad()\n",
        "        out, _ = model(batch.x.to(device), batch.edge_index.to(device))\n",
        "        out = out[:batch_size]\n",
        "        batch_y = batch.y[:batch_size].to(device)\n",
        "        batch_y = torch.reshape(batch_y, (-1,))\n",
        "        loss = F.nll_loss(out, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss)\n",
        "        total_correct += int(out.argmax(dim=-1).eq(batch_y).sum())\n",
        "        pbar.update(batch.batch_size)\n",
        "\n",
        "    pbar.close()\n",
        "    loss = total_loss / len(train_loader)\n",
        "    approx_acc = total_correct / train_idx.size(0)\n",
        "    train_acc, val_acc, test_acc, var = test(model, device)\n",
        "\n",
        "    print(f'Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}, Var: {var:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "VDAmNVpynnnF",
        "outputId": "70f1806b-49be-4888-fcac-8a7fcb2520be"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 01:   0%|          | 0/90941 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-fd47f330ff40>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/loader/node_loader.py\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNodeSamplerInput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_sampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_from_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_per_worker\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Execute `filter_fn` in the worker process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/sampler/neighbor_sampler.py\u001b[0m in \u001b[0;36msample_from_nodes\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNodeSamplerInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     ) -> Union[SamplerOutput, HeteroSamplerOutput]:\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubgraph_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSubgraphType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_bidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/sampler/neighbor_sampler.py\u001b[0m in \u001b[0;36mnode_sample\u001b[0;34m(inputs, sample_fn)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mseed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/sampler/neighbor_sampler.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, seed, seed_time, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m                 raise ImportError(f\"'{self.__class__.__name__}' requires \"\n\u001b[0m\u001b[1;32m    509\u001b[0m                                   f\"either 'pyg-lib' or 'torch-sparse'\")\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: 'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QrgwAIVtnntA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9Gf-XBVrhw5V"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KMEogd7mhxBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vs4pqTwNhxJW"
      }
    }
  ]
}